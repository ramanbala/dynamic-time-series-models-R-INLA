<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Details of R-INLA for Time Series | Dynamic Time Series Models using R-INLA: An Applied Perspective</title>
  <meta name="description" content="This book provides examples of modeling time series data using R-INLA." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Details of R-INLA for Time Series | Dynamic Time Series Models using R-INLA: An Applied Perspective" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://ramanbala.github.io/dynamic-time-series-models-R-INLA/" />
  <meta property="og:image" content="https://ramanbala.github.io/dynamic-time-series-models-R-INLA//book_cover_image.png" />
  <meta property="og:description" content="This book provides examples of modeling time series data using R-INLA." />
  <meta name="github-repo" content="ramanbala/dynamic-time-series-models-R-INLA" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Details of R-INLA for Time Series | Dynamic Time Series Models using R-INLA: An Applied Perspective" />
  
  <meta name="twitter:description" content="This book provides examples of modeling time series data using R-INLA." />
  <meta name="twitter:image" content="https://ramanbala.github.io/dynamic-time-series-models-R-INLA//book_cover_image.png" />

<meta name="author" content="Nalini Ravishanker, Balaji Raman, and Refik Soyer" />


<meta name="date" content="2022-10-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chapter2.html"/>
<link rel="next" href="chapter4.html"/>
<script src="libs/header-attrs/header-attrs.js"></script>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>
<script src="libs/kePrint/kePrint.js"></script>
<link href="libs/lightable/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Dynamic Time Series Models using R-INLA: An Applied Perspective</a></li>

<li class="divider"></li>
<li><a href="index.html#hello" id="toc-hello">Hello!<span></span></a></li>
<li><a href="preface.html#preface" id="toc-preface">Preface<span></span></a>
<ul>
<li><a href="preface.html#why-read-this-book" id="toc-why-read-this-book">Why read this book?<span></span></a></li>
<li><a href="preface.html#structure-of-the-book" id="toc-structure-of-the-book">Structure of the book<span></span></a></li>
<li><a href="preface.html#software-information-and-conventions" id="toc-software-information-and-conventions">Software information and conventions<span></span></a></li>
<li><a href="preface.html#acknowledgements" id="toc-acknowledgements">Acknowledgements<span></span></a></li>
</ul></li>
<li><a href="chapter1.html#chapter1" id="toc-chapter1"><span class="toc-section-number">1</span> Bayesian Analysis<span></span></a>
<ul>
<li><a href="chapter1.html#intro-ch1" id="toc-intro-ch1"><span class="toc-section-number">1.1</span> Introduction<span></span></a></li>
<li><a href="chapter1.html#bayes-framework" id="toc-bayes-framework"><span class="toc-section-number">1.2</span> Bayesian framework<span></span></a>
<ul>
<li><a href="chapter1.html#bayesian-model-comparison" id="toc-bayesian-model-comparison"><span class="toc-section-number">1.2.1</span> Bayesian model comparison<span></span></a></li>
</ul></li>
<li><a href="chapter1.html#bayes-ts" id="toc-bayes-ts"><span class="toc-section-number">1.3</span> Bayesian analysis of time series<span></span></a></li>
<li><a href="chapter1.html#dlms" id="toc-dlms"><span class="toc-section-number">1.4</span> Gaussian dynamic linear models (DLMs)<span></span></a>
<ul>
<li><a href="chapter1.html#constant-level-plus-noise-model" id="toc-constant-level-plus-noise-model"><span class="toc-section-number">1.4.1</span> Constant level plus noise model<span></span></a></li>
<li><a href="chapter1.html#local-level-model" id="toc-local-level-model"><span class="toc-section-number">1.4.2</span> Local level model<span></span></a></li>
<li><a href="chapter1.html#gaussian-dlm-framework-for-univariate-time-series" id="toc-gaussian-dlm-framework-for-univariate-time-series"><span class="toc-section-number">1.4.3</span> Gaussian DLM framework for univariate time series<span></span></a></li>
<li><a href="chapter1.html#ar1-plus-noise-model" id="toc-ar1-plus-noise-model"><span class="toc-section-number">1.4.4</span> AR(1) plus noise model<span></span></a></li>
<li><a href="chapter1.html#dlm-for-vector-valued-time-series" id="toc-dlm-for-vector-valued-time-series"><span class="toc-section-number">1.4.5</span> DLM for vector-valued time series<span></span></a></li>
<li><a href="chapter1.html#kalman-filtering-and-smoothing" id="toc-kalman-filtering-and-smoothing"><span class="toc-section-number">1.4.6</span> Kalman filtering and smoothing<span></span></a></li>
</ul></li>
<li><a href="chapter1.html#beyonddlm" id="toc-beyonddlm"><span class="toc-section-number">1.5</span> Beyond basic Gaussian DLMs<span></span></a></li>
<li><a href="chapter1.html#chapter-1-appendix" id="toc-chapter-1-appendix">Chapter 1 – Appendix<span></span></a>
<ul>
<li><a href="chapter1.html#conditional-distributions" id="toc-conditional-distributions">Conditional distributions<span></span></a></li>
<li><a href="chapter1.html#exponential-family-of-distributions" id="toc-exponential-family-of-distributions">Exponential family of distributions<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="chapter2.html#chapter2" id="toc-chapter2"><span class="toc-section-number">2</span> A Review of INLA<span></span></a>
<ul>
<li><a href="chapter2.html#intro-ch2" id="toc-intro-ch2"><span class="toc-section-number">2.1</span> Introduction<span></span></a></li>
<li><a href="chapter2.html#laplace" id="toc-laplace"><span class="toc-section-number">2.2</span> Laplace approximation<span></span></a>
<ul>
<li><a href="chapter2.html#simplaplace" id="toc-simplaplace"><span class="toc-section-number">2.2.1</span> Simplified Laplace approximation<span></span></a></li>
</ul></li>
<li><a href="chapter2.html#inlats" id="toc-inlats"><span class="toc-section-number">2.3</span> INLA structure for time series<span></span></a>
<ul>
<li><a href="chapter2.html#inla-steps" id="toc-inla-steps"><span class="toc-section-number">2.3.1</span> INLA steps<span></span></a></li>
</ul></li>
<li><a href="chapter2.html#forecast" id="toc-forecast"><span class="toc-section-number">2.4</span> Forecasting in INLA<span></span></a></li>
<li><a href="chapter2.html#marglik" id="toc-marglik"><span class="toc-section-number">2.5</span> Marginal likelihood computation in INLA<span></span></a></li>
<li><a href="chapter2.html#rinlapkg" id="toc-rinlapkg"><span class="toc-section-number">2.6</span> <code>R-INLA</code> package – some basics<span></span></a></li>
<li><a href="chapter2.html#chapter-2-appendix" id="toc-chapter-2-appendix">Chapter 2 – Appendix<span></span></a>
<ul>
<li><a href="chapter2.html#gaussian-markov-random-field-gmrf" id="toc-gaussian-markov-random-field-gmrf">Gaussian Markov Random Field (GMRF)<span></span></a></li>
<li><a href="chapter2.html#kullback-leibler-divergence" id="toc-kullback-leibler-divergence">Kullback-Leibler divergence<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="chapter3.html#chapter3" id="toc-chapter3"><span class="toc-section-number">3</span> Details of R-INLA for Time Series<span></span></a>
<ul>
<li><a href="chapter3.html#intro-ch3" id="toc-intro-ch3"><span class="toc-section-number">3.1</span> Introduction<span></span></a></li>
<li><a href="chapter3.html#ch3-rw1noise" id="toc-ch3-rw1noise"><span class="toc-section-number">3.2</span> Random walk plus noise model<span></span></a>
<ul>
<li><a href="chapter3.html#inlaformula" id="toc-inlaformula"><span class="toc-section-number">3.2.1</span> <code>R-INLA</code> model formula<span></span></a></li>
<li><a href="chapter3.html#inlaexec" id="toc-inlaexec"><span class="toc-section-number">3.2.2</span> Model execution<span></span></a></li>
<li><a href="chapter3.html#inlaprior" id="toc-inlaprior"><span class="toc-section-number">3.2.3</span> Prior specifications for hyperparameters<span></span></a></li>
<li><a href="chapter3.html#inlaposterior" id="toc-inlaposterior"><span class="toc-section-number">3.2.4</span> Posterior distributions of hyperparameters<span></span></a></li>
<li><a href="chapter3.html#fittedvalues" id="toc-fittedvalues"><span class="toc-section-number">3.2.5</span> Fitted values for latent states and responses<span></span></a></li>
<li><a href="chapter3.html#filterestimate" id="toc-filterestimate"><span class="toc-section-number">3.2.6</span> Filtering and smoothing in DLM<span></span></a></li>
</ul></li>
<li><a href="chapter3.html#ch3-ar1levelnoise" id="toc-ch3-ar1levelnoise"><span class="toc-section-number">3.3</span> AR(1) with level plus noise model<span></span></a></li>
<li><a href="chapter3.html#ch3-high-lags" id="toc-ch3-high-lags"><span class="toc-section-number">3.4</span> Dynamic linear models with higher order AR lags<span></span></a>
<ul>
<li><a href="chapter3.html#arp-with-level-plus-noise-model" id="toc-arp-with-level-plus-noise-model">AR<span class="math inline">\((p)\)</span> with level plus noise model<span></span></a></li>
</ul></li>
<li><a href="chapter3.html#ch3-rwdrift" id="toc-ch3-rwdrift"><span class="toc-section-number">3.5</span> Random walk with drift plus noise model<span></span></a></li>
<li><a href="chapter3.html#ch3-rwtvdrift" id="toc-ch3-rwtvdrift"><span class="toc-section-number">3.6</span> Second-order polynomial model<span></span></a></li>
<li><a href="chapter3.html#forecasting" id="toc-forecasting"><span class="toc-section-number">3.7</span> Forecasting states and observations<span></span></a></li>
<li><a href="chapter3.html#modsel" id="toc-modsel"><span class="toc-section-number">3.8</span> Model comparisons<span></span></a>
<ul>
<li><a href="chapter3.html#modsel-insamp-ch3" id="toc-modsel-insamp-ch3"><span class="toc-section-number">3.8.1</span> In-sample model comparisons<span></span></a></li>
<li><a href="chapter3.html#modsel-outsamp-ch3" id="toc-modsel-outsamp-ch3"><span class="toc-section-number">3.8.2</span> Out-of-sample comparisons<span></span></a></li>
</ul></li>
<li><a href="chapter3.html#nondefault-priors" id="toc-nondefault-priors"><span class="toc-section-number">3.9</span> Non-default prior specifications<span></span></a>
<ul>
<li><a href="chapter3.html#custom-priors" id="toc-custom-priors"><span class="toc-section-number">3.9.1</span> Custom prior specifications<span></span></a></li>
<li><a href="chapter3.html#pc-priors" id="toc-pc-priors"><span class="toc-section-number">3.9.2</span> Penalized complexity (PC) priors<span></span></a></li>
</ul></li>
<li><a href="chapter3.html#post-sampling" id="toc-post-sampling"><span class="toc-section-number">3.10</span> Posterior sampling of latent effects and hyperparameters<span></span></a></li>
<li><a href="chapter3.html#postpred-samples" id="toc-postpred-samples"><span class="toc-section-number">3.11</span> Posterior predictive samples of unknown observations<span></span></a></li>
<li><a href="chapter3.html#chapter-3-appendix" id="toc-chapter-3-appendix">Chapter 3 – Appendix<span></span></a>
<ul>
<li><a href="chapter3.html#sampling-properties-of-time-series" id="toc-sampling-properties-of-time-series">Sampling properties of time series<span></span></a></li>
<li><a href="chapter3.html#autoregressive-models" id="toc-autoregressive-models">Autoregressive models<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="chapter4.html#chapter4" id="toc-chapter4"><span class="toc-section-number">4</span> Modeling Univariate Time Series<span></span></a>
<ul>
<li><a href="chapter4.html#intro-ch4" id="toc-intro-ch4"><span class="toc-section-number">4.1</span> Introduction<span></span></a></li>
<li><a href="chapter4.html#dat-analysis" id="toc-dat-analysis"><span class="toc-section-number">4.2</span> Example: A software engineering example – Musa data<span></span></a>
<ul>
<li><a href="chapter4.html#ch4-model1" id="toc-ch4-model1"><span class="toc-section-number">4.2.1</span> Model 1. AR(1) with level plus noise model<span></span></a></li>
<li><a href="chapter4.html#ch4-model2" id="toc-ch4-model2"><span class="toc-section-number">4.2.2</span> Model 2. Random walk plus noise model<span></span></a></li>
<li><a href="chapter4.html#ch4-model3" id="toc-ch4-model3"><span class="toc-section-number">4.2.3</span> Model 3. AR(1) with trend plus noise model<span></span></a></li>
<li><a href="chapter4.html#ch4-model4" id="toc-ch4-model4"><span class="toc-section-number">4.2.4</span> Model 4. AR(2) with level plus noise model<span></span></a></li>
</ul></li>
<li><a href="chapter4.html#forecasting-musa" id="toc-forecasting-musa"><span class="toc-section-number">4.3</span> Forecasting future states and responses<span></span></a></li>
<li><a href="chapter4.html#modsel-ch4" id="toc-modsel-ch4"><span class="toc-section-number">4.4</span> Model comparisons<span></span></a>
<ul>
<li><a href="chapter4.html#in-sample-comparisons" id="toc-in-sample-comparisons">In-sample comparisons<span></span></a></li>
<li><a href="chapter4.html#out-of-sample-comparisons" id="toc-out-of-sample-comparisons">Out-of-sample comparisons<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="chapter5.html#chapter5" id="toc-chapter5"><span class="toc-section-number">5</span> Time Series Regression Models<span></span></a>
<ul>
<li><a href="chapter5.html#intro-ch5" id="toc-intro-ch5"><span class="toc-section-number">5.1</span> Introduction<span></span></a></li>
<li><a href="chapter5.html#ch5-strdecomp" id="toc-ch5-strdecomp"><span class="toc-section-number">5.2</span> Structural models<span></span></a>
<ul>
<li><a href="chapter5.html#hotelcost" id="toc-hotelcost"><span class="toc-section-number">5.2.1</span> Example: Monthly average cost of nightly hotel stay<span></span></a></li>
</ul></li>
<li><a href="chapter5.html#ch5-exogpreds" id="toc-ch5-exogpreds"><span class="toc-section-number">5.3</span> Models with exogenous predictors<span></span></a>
<ul>
<li><a href="chapter5.html#hourly-traffic" id="toc-hourly-traffic"><span class="toc-section-number">5.3.1</span> Example: Hourly traffic volumes<span></span></a></li>
</ul></li>
<li><a href="chapter5.html#ar1c" id="toc-ar1c"><span class="toc-section-number">5.4</span> Latent AR(1) model with covariates plus noise<span></span></a></li>
</ul></li>
<li><a href="chapter6.html#chapter6" id="toc-chapter6"><span class="toc-section-number">6</span> Hierarchical Dynamic Models for Panel Time Series<span></span></a>
<ul>
<li><a href="chapter6.html#intro-ch6" id="toc-intro-ch6"><span class="toc-section-number">6.1</span> Introduction<span></span></a></li>
<li><a href="chapter6.html#homog-state" id="toc-homog-state"><span class="toc-section-number">6.2</span> Models with homogenous state evolution<span></span></a>
<ul>
<li><a href="chapter6.html#simul1-panelts" id="toc-simul1-panelts"><span class="toc-section-number">6.2.1</span> Example: Simulated homogeneous panel time series with the same level<span></span></a></li>
<li><a href="chapter6.html#simul2-panelts" id="toc-simul2-panelts"><span class="toc-section-number">6.2.2</span> Example: Simulated homogeneous panel time series with different levels<span></span></a></li>
</ul></li>
<li><a href="chapter6.html#ridesource-hdlm" id="toc-ridesource-hdlm"><span class="toc-section-number">6.3</span> Example: Ridesourcing in NYC<span></span></a>
<ul>
<li><a href="chapter6.html#description-of-variables" id="toc-description-of-variables">Description of variables<span></span></a></li>
<li><a href="chapter6.html#hmod.H1" id="toc-hmod.H1"><span class="toc-section-number">6.3.1</span> Model H1. Dynamic intercept and exogenous predictors<span></span></a></li>
<li><a href="chapter6.html#hmod.H2" id="toc-hmod.H2"><span class="toc-section-number">6.3.2</span> Model H2. Dynamic intercept and Taxi usage<span></span></a></li>
<li><a href="chapter6.html#hmod.H3" id="toc-hmod.H3"><span class="toc-section-number">6.3.3</span> Model H3. Taxi usage varies by time and zone<span></span></a></li>
<li><a href="chapter6.html#hmod.H4" id="toc-hmod.H4"><span class="toc-section-number">6.3.4</span> Model H4. Fixed intercept, Taxi usage varies over time and zones<span></span></a></li>
</ul></li>
<li><a href="chapter6.html#model-comparison" id="toc-model-comparison"><span class="toc-section-number">6.4</span> Model comparison<span></span></a></li>
</ul></li>
<li><a href="ch-nongaus.html#ch-nongaus" id="toc-ch-nongaus"><span class="toc-section-number">7</span> Non-Gaussian Continuous Responses<span></span></a>
<ul>
<li><a href="ch-nongaus.html#intro-nongaus" id="toc-intro-nongaus"><span class="toc-section-number">7.1</span> Introduction<span></span></a></li>
<li><a href="ch-nongaus.html#gamma-model" id="toc-gamma-model"><span class="toc-section-number">7.2</span> Gamma state space model<span></span></a>
<ul>
<li><a href="ch-nongaus.html#vix" id="toc-vix"><span class="toc-section-number">7.2.1</span> Example: Volatility index (VIX) time series<span></span></a></li>
</ul></li>
<li><a href="ch-nongaus.html#weibull-model" id="toc-weibull-model"><span class="toc-section-number">7.3</span> Weibull state space model<span></span></a>
<ul>
<li><a href="ch-nongaus.html#forecasting-from-weibull-models" id="toc-forecasting-from-weibull-models"><span class="toc-section-number">7.3.1</span> Forecasting from Weibull models<span></span></a></li>
</ul></li>
<li><a href="ch-nongaus.html#beta-model" id="toc-beta-model"><span class="toc-section-number">7.4</span> Beta state space model<span></span></a>
<ul>
<li><a href="ch-nongaus.html#crest" id="toc-crest"><span class="toc-section-number">7.4.1</span> Example: Crest market share<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="ch-binary.html#ch-binary" id="toc-ch-binary"><span class="toc-section-number">8</span> Modeling Categorical Time Series<span></span></a>
<ul>
<li><a href="ch-binary.html#intro-ch-binary" id="toc-intro-ch-binary"><span class="toc-section-number">8.1</span> Introduction<span></span></a></li>
<li><a href="ch-binary.html#bin-model" id="toc-bin-model"><span class="toc-section-number">8.2</span> Binomial response time series<span></span></a>
<ul>
<li><a href="ch-binary.html#simul-bin" id="toc-simul-bin"><span class="toc-section-number">8.2.1</span> Example: Simulated single binomial response series<span></span></a></li>
<li><a href="ch-binary.html#bin-weekly-shopping" id="toc-bin-weekly-shopping"><span class="toc-section-number">8.2.2</span> Example: Weekly shopping trips for a single household<span></span></a></li>
</ul></li>
<li><a href="ch-binary.html#hbin" id="toc-hbin"><span class="toc-section-number">8.3</span> Modeling multiple binomial response time series<span></span></a>
<ul>
<li><a href="ch-binary.html#simul-hbin" id="toc-simul-hbin"><span class="toc-section-number">8.3.1</span> Example: Dynamic aggregated model for multiple binomial response time series<span></span></a></li>
<li><a href="ch-binary.html#hbin-weekly-shopping" id="toc-hbin-weekly-shopping"><span class="toc-section-number">8.3.2</span> Example: Weekly shopping trips for multiple households<span></span></a></li>
</ul></li>
<li><a href="ch-binary.html#cat-models" id="toc-cat-models"><span class="toc-section-number">8.4</span> Multinomial time series<span></span></a>
<ul>
<li><a href="ch-binary.html#simul-mn-p" id="toc-simul-mn-p"><span class="toc-section-number">8.4.1</span> Example: Simulated categorical time series<span></span></a></li>
<li><a href="ch-binary.html#model-d4-dynamic-coefficient-for-c_jt" id="toc-model-d4-dynamic-coefficient-for-c_jt">Model D4: Dynamic coefficient for <span class="math inline">\(C_{j,t}\)</span><span></span></a></li>
</ul></li>
<li><a href="ch-binary.html#chapter-8-appendix" id="toc-chapter-8-appendix">Chapter 8 – Appendix<span></span></a>
<ul>
<li><a href="ch-binary.html#poisson-trick-for-multinomial-models" id="toc-poisson-trick-for-multinomial-models">Poisson-trick for multinomial models<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="ch-count.html#ch-count" id="toc-ch-count"><span class="toc-section-number">9</span> Modeling Count Time Series<span></span></a>
<ul>
<li><a href="ch-count.html#intro-ch-count" id="toc-intro-ch-count"><span class="toc-section-number">9.1</span> Introduction<span></span></a></li>
<li><a href="ch-count.html#uvcounts" id="toc-uvcounts"><span class="toc-section-number">9.2</span> Univariate time series of counts<span></span></a>
<ul>
<li><a href="ch-count.html#uvcounts-simpois" id="toc-uvcounts-simpois"><span class="toc-section-number">9.2.1</span> Example: Simulated univariate Poisson counts<span></span></a></li>
<li><a href="ch-count.html#uvcounts-crashct" id="toc-uvcounts-crashct"><span class="toc-section-number">9.2.2</span> Example: Modeling crash counts in CT<span></span></a></li>
<li><a href="ch-count.html#uvcounts-bikerental" id="toc-uvcounts-bikerental"><span class="toc-section-number">9.2.3</span> Example: Daily bike rentals in Washington D.C.<span></span></a></li>
</ul></li>
<li><a href="ch-count.html#hieruvcounts" id="toc-hieruvcounts"><span class="toc-section-number">9.3</span> Hierarchical modeling of univariate count time series<span></span></a>
<ul>
<li><a href="ch-count.html#simul1-hcount" id="toc-simul1-hcount"><span class="toc-section-number">9.3.1</span> Example: Simulated univariate Poisson counts<span></span></a></li>
<li><a href="ch-count.html#tnc-hcount" id="toc-tnc-hcount"><span class="toc-section-number">9.3.2</span> Example: Modeling daily TNC usage in NYC<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="ch-sv.html#ch-sv" id="toc-ch-sv"><span class="toc-section-number">10</span> Modeling Stochastic Volatility<span></span></a>
<ul>
<li><a href="ch-sv.html#ch-sv-intro" id="toc-ch-sv-intro"><span class="toc-section-number">10.1</span> Introduction<span></span></a></li>
<li><a href="ch-sv.html#sv-uv" id="toc-sv-uv"><span class="toc-section-number">10.2</span> Univariate SV models<span></span></a>
<ul>
<li><a href="ch-sv.html#simul-svnormal" id="toc-simul-svnormal"><span class="toc-section-number">10.2.1</span> Example: Simulated SV data with standard normal errors<span></span></a></li>
<li><a href="ch-sv.html#simul-svt5" id="toc-simul-svt5"><span class="toc-section-number">10.2.2</span> Example: Simulated SV data with Student-<span class="math inline">\(t_{\nu}\)</span> errors<span></span></a></li>
<li><a href="ch-sv.html#stockrets" id="toc-stockrets"><span class="toc-section-number">10.2.3</span> Example: IBM stock returns<span></span></a></li>
<li><a href="ch-sv.html#nysestockrets" id="toc-nysestockrets"><span class="toc-section-number">10.2.4</span> Example: NYSE returns<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="ch-st.html#ch-st" id="toc-ch-st"><span class="toc-section-number">11</span> Spatio-temporal Modeling<span></span></a>
<ul>
<li><a href="ch-st.html#ch-st-intro" id="toc-ch-st-intro"><span class="toc-section-number">11.1</span> Introduction<span></span></a></li>
<li><a href="ch-st.html#st-process" id="toc-st-process"><span class="toc-section-number">11.2</span> Spatio-temporal process<span></span></a></li>
<li><a href="ch-st.html#dyn-areal-model" id="toc-dyn-areal-model"><span class="toc-section-number">11.3</span> Dynamic spatial models for areal data<span></span></a></li>
<li><a href="ch-st.html#st-tnc-example" id="toc-st-tnc-example"><span class="toc-section-number">11.4</span> Example: Monthly TNC usage in NYC taxi zones<span></span></a>
<ul>
<li><a href="ch-st.html#data-preprocessing" id="toc-data-preprocessing">Data preprocessing<span></span></a></li>
<li><a href="ch-st.html#st-tnc-kh" id="toc-st-tnc-kh"><span class="toc-section-number">11.4.1</span> Model 1. Knorr-Held additive effects model<span></span></a></li>
<li><a href="ch-st.html#st-tnc-kh-inter" id="toc-st-tnc-kh-inter"><span class="toc-section-number">11.4.2</span> Knorr-Held models with space-time interactions<span></span></a></li>
<li><a href="ch-st.html#model-kh3.-knorr-held-model-with-interaction-between-epsilon_i-and-gamma_t" id="toc-model-kh3.-knorr-held-model-with-interaction-between-epsilon_i-and-gamma_t">Model KH3. Knorr-Held model with interaction between <span class="math inline">\(\epsilon_i\)</span> and <span class="math inline">\(\gamma_t\)</span><span></span></a></li>
<li><a href="ch-st.html#model-kh4.-knorr-held-model-with-interaction-between-nu_i-and-gamma_t" id="toc-model-kh4.-knorr-held-model-with-interaction-between-nu_i-and-gamma_t">Model KH4. Knorr-Held model with interaction between <span class="math inline">\(\nu_i\)</span> and <span class="math inline">\(\gamma_t\)</span><span></span></a></li>
</ul></li>
</ul></li>
<li><a href="chmvdlm.html#chmvdlm" id="toc-chmvdlm"><span class="toc-section-number">12</span> Multivariate Gaussian Dynamic Modeling<span></span></a>
<ul>
<li><a href="chmvdlm.html#intro-chmvdlm" id="toc-intro-chmvdlm"><span class="toc-section-number">12.1</span> Introduction<span></span></a></li>
<li><a href="chmvdlm.html#MVDiagWPhi" id="toc-MVDiagWPhi"><span class="toc-section-number">12.2</span> Model with diagonal <span class="math inline">\(\boldsymbol W\)</span> and <span class="math inline">\(\boldsymbol \Phi\)</span> matrices<span></span></a>
<ul>
<li><a href="chmvdlm.html#V-setup" id="toc-V-setup"><span class="toc-section-number">12.2.1</span> Description of the setup for <span class="math inline">\(\boldsymbol V\)</span><span></span></a></li>
<li><a href="chmvdlm.html#simbivar1" id="toc-simbivar1"><span class="toc-section-number">12.2.2</span> Example: Simulated bivariate AR(1) series<span></span></a></li>
<li><a href="chmvdlm.html#tnctaxi-onezone" id="toc-tnctaxi-onezone"><span class="toc-section-number">12.2.3</span> Example: Ridesourcing data in NYC for a single taxi zone<span></span></a></li>
</ul></li>
<li><a href="chmvdlm.html#MVICCWPhi" id="toc-MVICCWPhi"><span class="toc-section-number">12.3</span> Model with equicorrelated <span class="math inline">\(\boldsymbol{w}_t\)</span> and diagonal <span class="math inline">\(\boldsymbol \Phi\)</span><span></span></a>
<ul>
<li><a href="chmvdlm.html#simtrivar1" id="toc-simtrivar1"><span class="toc-section-number">12.3.1</span> Example: Simulated trivariate series<span></span></a></li>
</ul></li>
<li><a href="chmvdlm.html#rgenericmv" id="toc-rgenericmv"><span class="toc-section-number">12.4</span> Fitting multivariate models using <code>rgeneric</code><span></span></a>
<ul>
<li><a href="chmvdlm.html#simulgen" id="toc-simulgen"><span class="toc-section-number">12.4.1</span> Example: Simulated bivariate VAR(1) series<span></span></a></li>
</ul></li>
<li><a href="chmvdlm.html#chapter-12-appendix" id="toc-chapter-12-appendix">Chapter 12 – Appendix<span></span></a></li>
</ul></li>
<li><a href="ch-hmv.html#ch-hmv" id="toc-ch-hmv"><span class="toc-section-number">13</span> Hierarchical Multivariate Time Series<span></span></a>
<ul>
<li><a href="ch-hmv.html#intro-ch-hmv" id="toc-intro-ch-hmv"><span class="toc-section-number">13.1</span> Introduction<span></span></a></li>
<li><a href="ch-hmv.html#mvhdlm" id="toc-mvhdlm"><span class="toc-section-number">13.2</span> Multivariate hierarchical dynamic linear model<span></span></a>
<ul>
<li><a href="ch-hmv.html#response-and-predictor-variables" id="toc-response-and-predictor-variables">Response and predictor variables<span></span></a></li>
<li><a href="ch-hmv.html#model-setup" id="toc-model-setup">Model setup<span></span></a></li>
<li><a href="ch-hmv.html#tnc-taxi-hmv" id="toc-tnc-taxi-hmv"><span class="toc-section-number">13.2.1</span> Example: Analysis of TNC and Taxi as responses<span></span></a></li>
</ul></li>
<li><a href="ch-hmv.html#lcmcounts" id="toc-lcmcounts"><span class="toc-section-number">13.3</span> Level correlated models for multivariate time series of counts<span></span></a>
<ul>
<li><a href="ch-hmv.html#tnc-taxi-daily" id="toc-tnc-taxi-daily"><span class="toc-section-number">13.3.1</span> Example: TNC and Taxi counts based on daily data<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="resources.html#resources" id="toc-resources"><span class="toc-section-number">14</span> Resources for the User<span></span></a>
<ul>
<li><a href="resources.html#intro-resources" id="toc-intro-resources"><span class="toc-section-number">14.1</span> Introduction<span></span></a></li>
<li><a href="resources.html#package-list" id="toc-package-list"><span class="toc-section-number">14.2</span> Packages used in the book<span></span></a></li>
<li><a href="resources.html#custom-functions" id="toc-custom-functions"><span class="toc-section-number">14.3</span> Custom functions used in the book<span></span></a>
<ul>
<li><a href="resources.html#basic-plotting-functions" id="toc-basic-plotting-functions">Basic plotting functions<span></span></a></li>
<li><a href="resources.html#functions-for-forecast-evaluation" id="toc-functions-for-forecast-evaluation">Functions for forecast evaluation<span></span></a></li>
<li><a href="resources.html#function-for-model-comparison" id="toc-function-for-model-comparison">Function for model comparison<span></span></a></li>
<li><a href="resources.html#function-for-the-filtering-algorithm-in-dlm" id="toc-function-for-the-filtering-algorithm-in-dlm">Function for the filtering algorithm in DLM<span></span></a></li>
<li><a href="resources.html#rgeneric-fn" id="toc-rgeneric-fn"><span class="toc-section-number">14.3.1</span> <code>rgeneric()</code> function for DLM-VAR model<span></span></a></li>
</ul></li>
<li><a href="resources.html#items-often-used" id="toc-items-often-used"><span class="toc-section-number">14.4</span> Often used <code>R-INLA</code> items<span></span></a>
<ul>
<li><a href="resources.html#control-options" id="toc-control-options">Control options<span></span></a></li>
<li><a href="resources.html#options-for-computing-marginals" id="toc-options-for-computing-marginals">Options for computing marginals<span></span></a></li>
<li><a href="resources.html#random-effect-specifications" id="toc-random-effect-specifications">Random effect specifications<span></span></a></li>
<li><a href="resources.html#prior-specifications" id="toc-prior-specifications">Prior specifications<span></span></a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Dynamic Time Series Models using R-INLA: An Applied Perspective</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter3" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Chapter 3</span> Details of R-INLA for Time Series<a href="chapter3.html#chapter3" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="intro-ch3" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Introduction<a href="chapter3.html#intro-ch3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this chapter, we show how to use the <code>R-INLA</code> package for analyzing univariate time series. Specifically, we show how we set up the formula and model statements for analyzing a time series as a random walk, a random walk with drift, or autoregessions of various orders, excluding or including a level coefficient.
<code>R-INLA</code> implements the integrated nested Laplace approximations that we discussed in Chapter <a href="chapter2.html#chapter2">2</a> in order to carry out approximate Bayesian inference.
We first show the details of Bayesian model fitting using <code>R-INLA</code> for time series simulated from a <em>random walk plus noise model</em> (also called the <em>local level model</em>), which was introduced in Chapter <a href="chapter1.html#chapter1">1</a>. We then discuss several other models for univariate time series. Further, we use these model fits to obtain future forecasts on hold-out (test) data. These forecasts can be used for predictive cross-validation and model selection. In practice, one can then use the best fitting model to forecast the time series into the future.</p>
<p>The first step is to install the package <code>R-INLA</code>:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="chapter3.html#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(</span>
<span id="cb9-2"><a href="chapter3.html#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;INLA&quot;</span>,</span>
<span id="cb9-3"><a href="chapter3.html#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">repos =</span> <span class="fu">c</span>(<span class="fu">getOption</span>(<span class="st">&quot;repos&quot;</span>),</span>
<span id="cb9-4"><a href="chapter3.html#cb9-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">INLA =</span> <span class="st">&quot;https://inla.r-inla-download.org/R/stable&quot;</span>),</span>
<span id="cb9-5"><a href="chapter3.html#cb9-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">dep =</span> <span class="cn">TRUE</span></span>
<span id="cb9-6"><a href="chapter3.html#cb9-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>Then, we source the package, along with other packages used in this chapter.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="chapter3.html#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(INLA)</span>
<span id="cb10-2"><a href="chapter3.html#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code></pre></div>
<p>Next, the set of custom functions that we have built must be sourced so that they may be called at various places in the chapter.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="chapter3.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">&quot;functions_custom.R&quot;</span>)</span></code></pre></div>
</div>
<div id="ch3-rw1noise" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Random walk plus noise model<a href="chapter3.html#ch3-rw1noise" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In Chapter <a href="chapter1.html#chapter1">1</a>, we defined the random walk plus noise model (also referred to as the local level model) using the observation equation and state equation shown in <a href="chapter1.html#eq:dlm-rw-obs">(1.15)</a> and <a href="chapter1.html#eq:dlm-rw-st">(1.16)</a> as</p>
<p><span class="math display">\[\begin{align*}
y_t &amp;= x_t + v_t;~~ v_t \sim N(0, \sigma^2_v), \\
x_t &amp;=  x_{t-1}+ w_t;~~ w_t \sim N(0, \sigma^2_w),  
\end{align*}\]</span>
where <span class="math inline">\(x_0=0\)</span>, and <span class="math inline">\(v_t\)</span> and <span class="math inline">\(w_t\)</span> are uncorrelated errors, following zero mean normal distributions with unknown variances <span class="math inline">\(\sigma^2_v\)</span> and <span class="math inline">\(\sigma^2_w\)</span> respectively.
The response variable is denoted by <span class="math inline">\(y_t\)</span>.
The <em>state variable</em> <span class="math inline">\(x_t\)</span> is a latent Gaussian variable. Let <span class="math inline">\(\boldsymbol{\theta}=(\sigma^2_v, \sigma^2_w)&#39;\)</span> denote the vector of unknown hyperparameters.
This is a special case of the DLM shown in
<a href="chapter1.html#eq:dlm-obseq-uv">(1.17)</a> and <a href="chapter1.html#eq:dlm-steq-uv">(1.18)</a> with
<span class="math inline">\(\alpha=0\)</span>, <span class="math inline">\(F_t =1\)</span> and <span class="math inline">\(G_t=1\)</span>.
We show the detailed steps for fitting this model to a simulated time series and verify that we are able to recover the true parameters that we used to generate the series.
We set the length of the time series to be <span class="math inline">\(n=500\)</span>. The true parameter values for the observation error variance and state error variance are <span class="math inline">\(\sigma^2_v=0.5\)</span> and <span class="math inline">\(\sigma^2_w=0.25\)</span> respectively.</p>
<p>We simulate a time series from the model in <a href="chapter1.html#eq:dlm-rw-obs">(1.15)</a> and <a href="chapter1.html#eq:dlm-rw-st">(1.16)</a> using the custom function
<code>simulation.from.rw1()</code> which is included in the set of functions that we sourced in the introduction via</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="chapter3.html#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">&quot;functions_custom.R&quot;</span>)</span></code></pre></div>
<p>To see a plot of the time series, use <code>plot.data = TRUE</code>.
Figure <a href="chapter3.html#fig:rw1noise">3.1</a> shows a wandering behavior which is typical of the nonstationary random walk series.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="chapter3.html#cb13-1" aria-hidden="true" tabindex="-1"></a>sim.rw1 <span class="ot">&lt;-</span></span>
<span id="cb13-2"><a href="chapter3.html#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">simulation.from.rw1</span>(</span>
<span id="cb13-3"><a href="chapter3.html#cb13-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">sample.size =</span> <span class="dv">500</span>,</span>
<span id="cb13-4"><a href="chapter3.html#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">burn.in =</span> <span class="dv">100</span>,</span>
<span id="cb13-5"><a href="chapter3.html#cb13-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">level =</span> <span class="dv">0</span>,</span>
<span id="cb13-6"><a href="chapter3.html#cb13-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">drift =</span> <span class="dv">0</span>,</span>
<span id="cb13-7"><a href="chapter3.html#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">V =</span> <span class="fl">0.5</span>,</span>
<span id="cb13-8"><a href="chapter3.html#cb13-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">W =</span> <span class="fl">0.25</span>,</span>
<span id="cb13-9"><a href="chapter3.html#cb13-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot.data =</span> <span class="cn">TRUE</span>,</span>
<span id="cb13-10"><a href="chapter3.html#cb13-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">seed =</span> <span class="dv">123457</span></span>
<span id="cb13-11"><a href="chapter3.html#cb13-11" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb13-12"><a href="chapter3.html#cb13-12" aria-hidden="true" tabindex="-1"></a>sim.rw1<span class="sc">$</span>sim.plot</span></code></pre></div>
<div class="figure"><span id="fig:rw1noise"></span>
<img src="gitbook_version_files/figure-html/rw1noise-1.png" alt="Simulated random walk plus noise series." width="672" />
<p class="caption">
FIGURE 3.1: Simulated random walk plus noise series.
</p>
</div>
<p>To use <code>R-INLA</code> for fitting this model to the data, we discuss three main components:</p>
<ol style="list-style-type: lower-roman">
<li><p>a <code>formula</code> to specify the model, similar to the formula in the R function <code>lm()</code> used to fit the usual linear regression model
(see Section <a href="chapter3.html#inlaformula">3.2.1</a>).</p></li>
<li><p>model <em>execution</em>, which is used to obtain results and posterior summaries (see Section <a href="chapter3.html#inlaexec">3.2.2</a>), and</p></li>
<li><p><em>prior</em> and <em>hyperprior</em> specifications, when relevant (see Section <a href="chapter3.html#inlaprior">3.2.3</a>).</p></li>
</ol>
<div id="inlaformula" class="section level3 hasAnchor" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> <code>R-INLA</code> model formula<a href="chapter3.html#inlaformula" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The information in the observation and state equations of a DLM is represented as a formula, similar to the formula used in the R function <code>lm()</code>.
We can specify time effects, and in general any structured effect, using a function <code>f()</code> within the formula. Examples of structured effects for univariate time series are <em>iid</em>, <em>rw1</em>, <em>ar1</em>, etc.
The time effect is represented as an index in <code>f()</code>.
Specifically, we set up a time index <em>id.w</em> that runs from <span class="math inline">\(1\)</span> to <span class="math inline">\(n\)</span>, where <span class="math inline">\(n\)</span> denotes the length of the time series.
We then set up a data frame <em>rw1.dat</em>, with two columns containing the time series <span class="math inline">\(y_t\)</span> and the time index <em>id.w</em>.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="chapter3.html#cb14-1" aria-hidden="true" tabindex="-1"></a>y.rw1 <span class="ot">&lt;-</span> sim.rw1<span class="sc">$</span>sim.data</span>
<span id="cb14-2"><a href="chapter3.html#cb14-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(y.rw1)</span>
<span id="cb14-3"><a href="chapter3.html#cb14-3" aria-hidden="true" tabindex="-1"></a>id.w <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>n</span>
<span id="cb14-4"><a href="chapter3.html#cb14-4" aria-hidden="true" tabindex="-1"></a>rw1.dat <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(y.rw1, id.w)</span></code></pre></div>
<p>The <em>model</em> argument within the function <code>f()</code> is specified to be <em>rw1</em>. Since no intercept needs to be estimated in the observation equation (i.e., <span class="math inline">\(\alpha=0\)</span>), we include “<span class="math inline">\(-1\)</span>” in the formula; note that this usage is similar to the <code>lm()</code> function.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="chapter3.html#cb15-1" aria-hidden="true" tabindex="-1"></a>formula.rw1 <span class="ot">&lt;-</span> y.rw1 <span class="sc">~</span> <span class="fu">f</span>(id.w, <span class="at">model =</span> <span class="st">&quot;rw1&quot;</span>,</span>
<span id="cb15-2"><a href="chapter3.html#cb15-2" aria-hidden="true" tabindex="-1"></a>                         <span class="at">constr =</span> <span class="cn">FALSE</span>) <span class="sc">-</span> <span class="dv">1</span></span></code></pre></div>
<p>In the formula, <code>constr</code> is an option to let the sum of terms (in this case <span class="math inline">\(x_t\)</span>) be zero, which is the default option in <code>R-INLA</code>.
Using <code>?f()</code>, we can get help on the
<!-- This is a quote from the help manual about the -->
<code>constr</code> option:
“<em>A boolean variable indicating whether to set a sum to 0 constraint on the term. By default the sum to 0 constraint is imposed on all intrinsic models (”iid”,”rw1”,”rw2”,”besag”, etc.).</em>”
We specify <code>constr=FALSE</code>, since there is no constraint in the random walk plus noise model. Information on all arguments available with the function <code>f()</code> can be accessed using <code>?f()</code>.</p>
</div>
<div id="inlaexec" class="section level3 hasAnchor" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Model execution<a href="chapter3.html#inlaexec" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can fit the model using the function <code>inla()</code>. The general syntax is shown below, where <code>formula</code> was defined in the previous subsection.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="chapter3.html#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inla</span>(<span class="at">formula =</span> ,<span class="at">family =</span> ,<span class="at">data =</span> ,<span class="at">control.compute =</span> ,</span>
<span id="cb16-2"><a href="chapter3.html#cb16-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">control.predictor =</span> ,<span class="at">control.family =</span> ,...)</span></code></pre></div>
<p>For the Gaussian DLM, <span class="math inline">\(y_t\)</span> has a normal distribution and we set <code>family = gaussian</code>.<br />
In later chapters, we will look at examples of non-Gaussian families for <span class="math inline">\(y_t\)</span>, and specify these via the appropriate input in <code>family =</code>.
Recall that the latent state variable <span class="math inline">\(x_t\)</span> is always assumed to be Gaussian in this framework (see Chapter <a href="chapter2.html#chapter2">2</a>).</p>
<p>The data is set to be the data frame we created earlier, i.e., <code>data = rw1.dat</code>.
<code>R-INLA</code> has several control options which enable a user to control different aspects of the modeling and output generation, and excellent documentation of these options is available on their website by using <code>?inla</code>. For example, information on <code>control.compute</code> can be obtained from <code>?control.compute</code>. <span class="citation">Gómez-Rubio (<a href="#ref-gomez2020bayesian" role="doc-biblioref">2020</a>)</span> has presented a table with various options in <code>control.compute</code>; we show a similar display in Table
<a href="resources.html#tab:controloptions">14.1</a>.
In the code below, we include the option <code>control.predictor</code>, which provides information on fitted values.
In later sections of this chapter and in later chapters, we discuss other control options. In Chapter <a href="resources.html#resources">14</a>, we collect some of these items in a single place for quick reference.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="chapter3.html#cb17-1" aria-hidden="true" tabindex="-1"></a>model.rw1 <span class="ot">&lt;-</span> <span class="fu">inla</span>(</span>
<span id="cb17-2"><a href="chapter3.html#cb17-2" aria-hidden="true" tabindex="-1"></a>  formula.rw1,</span>
<span id="cb17-3"><a href="chapter3.html#cb17-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb17-4"><a href="chapter3.html#cb17-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> rw1.dat,</span>
<span id="cb17-5"><a href="chapter3.html#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">control.predictor =</span> <span class="fu">list</span>(<span class="at">compute =</span> <span class="cn">TRUE</span>)</span>
<span id="cb17-6"><a href="chapter3.html#cb17-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>The results from the <code>inla()</code> call shown above are stored in <em>model.rw1</em>, which is a list consisting of a number of objects. Before we do a deep dive into the output generated by <code>inla()</code>, we look at the detailed model summary, which is obtained using the function <code>summary()</code>:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="chapter3.html#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model.rw1)</span>
<span id="cb18-2"><a href="chapter3.html#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb18-3"><a href="chapter3.html#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Call:</span></span>
<span id="cb18-4"><a href="chapter3.html#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="do">##    c(&quot;inla(formula = formula.rw1, family = \&quot;gaussian\&quot;, data = </span></span>
<span id="cb18-5"><a href="chapter3.html#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="do">##    rw1.dat, &quot;, &quot; control.predictor = list(compute = TRUE))&quot;) </span></span>
<span id="cb18-6"><a href="chapter3.html#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="do">## Time used:</span></span>
<span id="cb18-7"><a href="chapter3.html#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="do">##     Pre = 4.43, Running = 3.31, Post = 0.387, Total = 8.13 </span></span>
<span id="cb18-8"><a href="chapter3.html#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="do">## Random effects:</span></span>
<span id="cb18-9"><a href="chapter3.html#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="do">##   Name     Model</span></span>
<span id="cb18-10"><a href="chapter3.html#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="do">##     id.w RW1 model</span></span>
<span id="cb18-11"><a href="chapter3.html#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb18-12"><a href="chapter3.html#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="do">## Model hyperparameters:</span></span>
<span id="cb18-13"><a href="chapter3.html#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="do">##                                         mean    sd 0.025quant</span></span>
<span id="cb18-14"><a href="chapter3.html#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="do">## Precision for the Gaussian observations 1.66 0.152       1.38</span></span>
<span id="cb18-15"><a href="chapter3.html#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="do">## Precision for id.w                      4.79 0.868       3.32</span></span>
<span id="cb18-16"><a href="chapter3.html#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="do">##                                         0.5quant 0.975quant mode</span></span>
<span id="cb18-17"><a href="chapter3.html#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="do">## Precision for the Gaussian observations     1.65       1.98 1.64</span></span>
<span id="cb18-18"><a href="chapter3.html#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="do">## Precision for id.w                          4.71       6.72 4.56</span></span>
<span id="cb18-19"><a href="chapter3.html#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb18-20"><a href="chapter3.html#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="do">## Expected number of effective parameters(stdev): 143.47(15.72)</span></span>
<span id="cb18-21"><a href="chapter3.html#cb18-21" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of equivalent replicates : 3.48 </span></span>
<span id="cb18-22"><a href="chapter3.html#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb18-23"><a href="chapter3.html#cb18-23" aria-hidden="true" tabindex="-1"></a><span class="do">## Marginal log-Likelihood:  -750.25 </span></span>
<span id="cb18-24"><a href="chapter3.html#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="do">## Posterior marginals for the linear predictor and</span></span>
<span id="cb18-25"><a href="chapter3.html#cb18-25" aria-hidden="true" tabindex="-1"></a><span class="do">##  the fitted values are computed</span></span></code></pre></div>
<p><strong>Description of the output</strong></p>
<p>The output from <code>summary()</code> is very detailed, parts of which are self-explanatory, while others need some explanation. Below, we describe all the terms from the output.</p>
<ol style="list-style-type: decimal">
<li><em>call</em>: the function called, with relevant arguments. Here,</li>
</ol>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="chapter3.html#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model.rw1)<span class="sc">$</span>call</span>
<span id="cb19-2"><a href="chapter3.html#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;inla(formula = formula.rw1, family = \&quot;gaussian\&quot;, data = rw1.dat, &quot;</span></span>
<span id="cb19-3"><a href="chapter3.html#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="do">## [2] &quot;    control.predictor = list(compute = TRUE))&quot;</span></span></code></pre></div>
<p>We can also obtain this using <code>model.rw1$call</code>.</p>
<ol start="2" style="list-style-type: decimal">
<li><em>Time used</em>: time taken by the system to execute the model fit. Here,</li>
</ol>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="chapter3.html#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model.rw1)<span class="sc">$</span>cpu.used</span>
<span id="cb20-2"><a href="chapter3.html#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;Pre = 4.43, Running = 3.31, Post = 0.387, Total = 8.13&quot;</span></span></code></pre></div>
<p>We can also obtain the same output by using <code>model.rw1$cpu.used</code>.</p>
<ol start="3" style="list-style-type: decimal">
<li><p><em>The model has no fixed effects</em>: note that in the equations for the random walk plus noise model, <span class="math inline">\(x_t\)</span> is time varying, and there are no “fixed” effects in the model (such as the intercept, <span class="math inline">\(\alpha\)</span>, say).</p></li>
<li><p><em>Random effects</em>: in the model, <span class="math inline">\(x_t\)</span> is a latent process and the structured effect <em>rw1</em> is captured through the variable <em>id.w</em>. See</p></li>
</ol>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="chapter3.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model.rw1)<span class="sc">$</span>random.names</span>
<span id="cb21-2"><a href="chapter3.html#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;id.w&quot;</span></span>
<span id="cb21-3"><a href="chapter3.html#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model.rw1)<span class="sc">$</span>random.model</span>
<span id="cb21-4"><a href="chapter3.html#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;RW1 model&quot;</span></span></code></pre></div>
<ol start="5" style="list-style-type: decimal">
<li><em>Model hyperparameters</em>: a summary of parameter estimation corresponding to <span class="math inline">\(\sigma^2_v\)</span> and <span class="math inline">\(\sigma^2_w\)</span> is shown under this heading, and consists of the mean, standard deviation, <span class="math inline">\(2.5^{th}\)</span> quantile, median, <span class="math inline">\(97.5^{th}\)</span> quantile, and the mode of the posterior distributions of the following terms:
precision for the Gaussian observations, i.e., the precision for <span class="math inline">\(v_t\)</span>, which is <span class="math inline">\(1/\sigma^2_v\)</span>, and
precision for <em>id.w</em>, i.e., the precision of <span class="math inline">\(w_t\)</span>, which is <span class="math inline">\(1/\sigma^2_w\)</span>.</li>
</ol>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="chapter3.html#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model.rw1)<span class="sc">$</span>hyperpar</span>
<span id="cb22-2"><a href="chapter3.html#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="do">##                                          mean    sd 0.025quant</span></span>
<span id="cb22-3"><a href="chapter3.html#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Precision for the Gaussian observations 1.661 0.152      1.380</span></span>
<span id="cb22-4"><a href="chapter3.html#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Precision for id.w                      4.791 0.868      3.316</span></span>
<span id="cb22-5"><a href="chapter3.html#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="do">##                                         0.5quant 0.975quant  mode</span></span>
<span id="cb22-6"><a href="chapter3.html#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="do">## Precision for the Gaussian observations    1.654      1.978 1.643</span></span>
<span id="cb22-7"><a href="chapter3.html#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="do">## Precision for id.w                         4.712      6.720 4.559</span></span></code></pre></div>
<p>We can also get this using <code>model.rw1$summary.hyperpar</code>; note the difference in the number of digits printed.</p>
<ol start="6" style="list-style-type: decimal">
<li><em>Expected number of effective parameters</em>: this is the number of <em>independently estimated</em> parameters in the model.</li>
</ol>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="chapter3.html#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model.rw1)<span class="sc">$</span>neffp</span>
<span id="cb23-2"><a href="chapter3.html#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="do">##                                      [,1]</span></span>
<span id="cb23-3"><a href="chapter3.html#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Expectected  number of parameters 143.475</span></span>
<span id="cb23-4"><a href="chapter3.html#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Stdev of the number of parameters  15.719</span></span>
<span id="cb23-5"><a href="chapter3.html#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of equivalent replicates     3.485</span></span></code></pre></div>
<ol start="7" style="list-style-type: decimal">
<li><em>Marginal log-likelihood</em>: this was defined in Chapter <a href="chapter2.html#chapter2">2</a> and is used in model selection, as discussed in Section <a href="chapter3.html#modsel">3.8</a>.</li>
</ol>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="chapter3.html#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model.rw1)<span class="sc">$</span>mlik</span>
<span id="cb24-2"><a href="chapter3.html#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="do">##                                         [,1]</span></span>
<span id="cb24-3"><a href="chapter3.html#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="do">## log marginal-likelihood (integration) -750.0</span></span>
<span id="cb24-4"><a href="chapter3.html#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="do">## log marginal-likelihood (Gaussian)    -750.3</span></span></code></pre></div>
<p>We can also obtain this using <code>model.rw1$mlik</code>.</p>
<ol start="8" style="list-style-type: decimal">
<li><em>Posterior marginals for linear predictor and fitted values</em>: while calling the <code>inla()</code> function, we request this output through the option <code>control.predictor = list(compute = TRUE)</code>.</li>
</ol>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="chapter3.html#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">summary</span>(model.rw1)<span class="sc">$</span>linear.predictor)</span></code></pre></div>
<p>This can also be obtained using <code>model.rw1$summary.linear.predictor</code>. It is useful to print a condensed summary for the fitted values:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="chapter3.html#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">summary</span>(model.rw1)<span class="sc">$</span>linear.predictor)</span>
<span id="cb26-2"><a href="chapter3.html#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="do">##                mean    sd 0.025quant 0.5quant 0.975quant  mode kld</span></span>
<span id="cb26-3"><a href="chapter3.html#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Predictor.001 2.488 0.518      1.473    2.488      3.504 2.487   0</span></span>
<span id="cb26-4"><a href="chapter3.html#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Predictor.002 2.428 0.450      1.547    2.428      3.310 2.428   0</span></span>
<span id="cb26-5"><a href="chapter3.html#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="do">## Predictor.003 2.331 0.426      1.496    2.331      3.167 2.330   0</span></span>
<span id="cb26-6"><a href="chapter3.html#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="do">## Predictor.004 2.270 0.419      1.449    2.269      3.093 2.268   0</span></span>
<span id="cb26-7"><a href="chapter3.html#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="do">## Predictor.005 1.918 0.417      1.099    1.918      2.734 1.919   0</span></span>
<span id="cb26-8"><a href="chapter3.html#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="do">## Predictor.006 1.745 0.417      0.925    1.746      2.561 1.747   0</span></span></code></pre></div>
<p><strong>Condensed output</strong></p>
<p>The output from <code>inla()</code> can be unwieldy. It is possible to show a condensed output by excluding selected columns from the detailed output, as we show below. Our function <code>format.inla.out()</code> requires the <code>R</code> package <code>tidyverse</code> <span class="citation">(<a href="#ref-tidy17" role="doc-biblioref">Wickham et al. 2019</a>)</span>. For details on the <code>tidyverse</code> package and other data wrangling approaches, see <span class="citation">Boehmke (<a href="#ref-boehmke2016data" role="doc-biblioref">2016</a>)</span>. To show only the mean, standard deviation, and median of the hyperparameter distributions, we use</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="chapter3.html#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(model.rw1<span class="sc">$</span>summary.hyperpar[,<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">4</span>)])</span></code></pre></div>
<pre><code>##   name                       mean  sd    0.5q 
## 1 Precision for Gaussian obs 1.661 0.152 1.654
## 2 Precision for id.w         4.791 0.868 4.712</code></pre>
<p>The condensed output below only shows the three quantiles from the hyperparameter distributions.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="chapter3.html#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(model.rw1<span class="sc">$</span>summary.hyperpar[,<span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>)])</span></code></pre></div>
<pre><code>  name                       0.025q 0.5q  0.975q
1 Precision for Gaussian obs 1.380  1.654 1.978 
2 Precision for id.w         3.316  4.712 6.720 </code></pre>
<p>Below, we illustrate output only on the mean, median, and mode of the hyperparameter distributions.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="chapter3.html#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(model.rw1<span class="sc">$</span>summary.hyperpar[,<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">4</span>,<span class="dv">6</span>)])</span></code></pre></div>
<pre><code>  name                       mean  0.5q  mode 
1 Precision for Gaussian obs 1.661 1.654 1.643
2 Precision for id.w         4.791 4.712 4.559</code></pre>
<p>Although we only show condensed output in most places in the book due to space restrictions, a user may obtain and directly view the full output by excluding <code>format.inla.out()</code>.</p>
</div>
<div id="inlaprior" class="section level3 hasAnchor" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> Prior specifications for hyperparameters<a href="chapter3.html#inlaprior" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Setting prior specifications for the hyperparameters is an important step in the Bayesian framework. Data analysts often give considerable thought to specifying appropriate and reasonable priors. If a user does not wish to specify a custom prior distribution, <code>R-INLA</code> uses a default prior specification. In most situations, these default priors work quite well.
Here, we talk about <em>default priors</em> available for hyperparameters (or model parameters) in a Gaussian DLM. In Section <a href="chapter3.html#nondefault-priors">3.9</a>, we discuss how a user may set up non-default or custom priors (also see Chapter 5 in <span class="citation">Gómez-Rubio (<a href="#ref-gomez2020bayesian" role="doc-biblioref">2020</a>)</span>).</p>
<p>It is important to note that <code>R-INLA</code> assigns priors via an <em>internal representation</em> for the parameters. This representation may not be the same as the scale of the parameter that is specified in the model by a user.
For instance, precisions (which are reciprocals of variances) are represented on the <em>log scale</em>. In the Gausssian DLM, the precision corresponding to the observation noise variance is <span class="math inline">\(1/\sigma^2_v\)</span>, and <code>R-INLA</code> sets a prior for
<span class="math inline">\(\theta_v = \log(1/\sigma^2_v)\)</span>.
As explained in <span class="citation">Rue, Martino, and Chopin (<a href="#ref-rue09" role="doc-biblioref">2009</a>)</span>, the internal representation is computationally convenient, since the parameter is not bounded in the internal scale and has the entire real line <span class="math inline">\(\mathbb{R}\)</span> as support. We next show how we set up and execute the model under default priors for observation and state noise variances via <span class="math inline">\(\theta_v = \log(1/\sigma^2_v)\)</span> and <span class="math inline">\(\theta_w = \log(1/\sigma^2_w)\)</span>.</p>
<div id="default-priors-for-sigma2_v-and-sigma2_w" class="section level4 unnumbered hasAnchor">
<h4>Default priors for <span class="math inline">\(\sigma^2_v\)</span> and <span class="math inline">\(\sigma^2_w\)</span><a href="chapter3.html#default-priors-for-sigma2_v-and-sigma2_w" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>To define the prior specification corresponding to the observation noise variance <span class="math inline">\(\sigma^2_v\)</span>, consider the corresponding log precision</p>
<p><span class="math display">\[\begin{align*}
\theta_v = \log\left(\frac{1}{\sigma^2_v}\right),
\end{align*}\]</span>
and let</p>
<p><span class="math display">\[\begin{align*}
\theta_v \sim {\rm log~gamma}({\rm shape} =1, {\rm inverse~scale = 5e-05}).
\end{align*}\]</span><br />
The logarithm of the precision <span class="math inline">\(\theta_v\)</span>
is assumed by default to follow a log-gamma distribution.
The shape and inverse scale parameters of this log-gamma prior are unknown, and by default, <code>R-INLA</code> assigns to them the values <span class="math inline">\(1\)</span> and 5e-05 respectively.
The default initial value for this log-gamma hyperparameter is set as <span class="math inline">\(4\)</span>.</p>
<p>Similarly, a default log-gamma prior with values <span class="math inline">\(1\)</span> and 5e-05 for the shape and inverse scale and a default initial value of <span class="math inline">\(4\)</span> is specified for <span class="math inline">\(\theta_w = \log(1/\sigma^2_w)\)</span>, the logarithm of the reciprocal of the state error variance <span class="math inline">\(\sigma^2_w\)</span>. That is, we let</p>
<p><span class="math display">\[\begin{align*}
\theta_w = \log\left(\frac{1}{\sigma^2_w}\right),
\end{align*}\]</span>
and<br />
<span class="math display">\[\begin{align*}
\theta_w \sim {\rm log~gamma}({\rm shape} =1, {\rm inverse~scale = 5e-05}).
\end{align*}\]</span>
More details on these default prior specifications for this model can be accessed from the INLA documentation <code>inla.doc("rw1")</code>.</p>
</div>
</div>
<div id="inlaposterior" class="section level3 hasAnchor" number="3.2.4">
<h3><span class="header-section-number">3.2.4</span> Posterior distributions of hyperparameters<a href="chapter3.html#inlaposterior" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can obtain marginal posterior distributions of the latent variables (treated as parameters) <span class="math inline">\(x_t\)</span> and the hyperparameters
<span class="math inline">\(\boldsymbol{\theta}\)</span>, and manipulate these distributions.
The options are summarized in Table <a href="resources.html#tab:marginaloptions">14.2</a>, which shows the different functions and their descriptions (similar to the one displayed in <span class="citation">Gómez-Rubio (<a href="#ref-gomez2020bayesian" role="doc-biblioref">2020</a>)</span>).</p>
<p>We have seen that <code>R-INLA</code> works with the log precisions of hyperparameters rather than their variances. Therefore, in order to obtain marginal posterior distributions of <span class="math inline">\(\sigma^2_v\)</span> and <span class="math inline">\(\sigma^2_w\)</span>, we must transform each log(precision) back to the corresponding variance using the function <code>inla.tmarginal()</code>.
The result for <span class="math inline">\(\sigma^2_v\)</span> is shown in Figure <a href="chapter3.html#fig:post-sig2v-rw1">3.2</a>.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="chapter3.html#cb33-1" aria-hidden="true" tabindex="-1"></a>sigma2.v.dist <span class="ot">&lt;-</span> <span class="fu">inla.tmarginal</span>(</span>
<span id="cb33-2"><a href="chapter3.html#cb33-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">fun =</span> <span class="cf">function</span>(x)</span>
<span id="cb33-3"><a href="chapter3.html#cb33-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">exp</span>(<span class="sc">-</span>x),</span>
<span id="cb33-4"><a href="chapter3.html#cb33-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">marginal =</span> model.rw1<span class="sc">$</span></span>
<span id="cb33-5"><a href="chapter3.html#cb33-5" aria-hidden="true" tabindex="-1"></a>  internal.marginals.hyperpar<span class="sc">$</span><span class="st">`</span><span class="at">Log precision for the Gaussian observations</span><span class="st">`</span></span>
<span id="cb33-6"><a href="chapter3.html#cb33-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-7"><a href="chapter3.html#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(</span>
<span id="cb33-8"><a href="chapter3.html#cb33-8" aria-hidden="true" tabindex="-1"></a>  sigma2.v.dist,</span>
<span id="cb33-9"><a href="chapter3.html#cb33-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;l&quot;</span>,</span>
<span id="cb33-10"><a href="chapter3.html#cb33-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="fu">expression</span>(<span class="fu">paste</span>(</span>
<span id="cb33-11"><a href="chapter3.html#cb33-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Observation noise variance &quot;</span>, sigma[v] <span class="sc">^</span> <span class="dv">2</span>, <span class="at">sep =</span> <span class="st">&quot; &quot;</span></span>
<span id="cb33-12"><a href="chapter3.html#cb33-12" aria-hidden="true" tabindex="-1"></a>  )),</span>
<span id="cb33-13"><a href="chapter3.html#cb33-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;density&quot;</span></span>
<span id="cb33-14"><a href="chapter3.html#cb33-14" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure"><span id="fig:post-sig2v-rw1"></span>
<img src="gitbook_version_files/figure-html/post-sig2v-rw1-1.png" alt="Posterior distribution of $\sigma^2_v$ in the random walk plus noise model." width="672" />
<p class="caption">
FIGURE 3.2: Posterior distribution of <span class="math inline">\(\sigma^2_v\)</span> in the random walk plus noise model.
</p>
</div>
<p>The marginal posterior for <span class="math inline">\(\sigma^2_w\)</span> may be similarly obtained, see Figure <a href="chapter3.html#fig:post-sig2w-rw1">3.3</a>.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="chapter3.html#cb34-1" aria-hidden="true" tabindex="-1"></a>sigma2.w.dist <span class="ot">&lt;-</span> <span class="fu">inla.tmarginal</span>(</span>
<span id="cb34-2"><a href="chapter3.html#cb34-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">fun =</span> <span class="cf">function</span>(x)</span>
<span id="cb34-3"><a href="chapter3.html#cb34-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">exp</span>(<span class="sc">-</span>x),</span>
<span id="cb34-4"><a href="chapter3.html#cb34-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">marginal =</span> model.rw1<span class="sc">$</span>internal.marginals.hyperpar<span class="sc">$</span><span class="st">`</span><span class="at">Log precision for id</span><span class="st">`</span></span>
<span id="cb34-5"><a href="chapter3.html#cb34-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-6"><a href="chapter3.html#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(sigma2.w.dist,</span>
<span id="cb34-7"><a href="chapter3.html#cb34-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">type =</span> <span class="st">&quot;l&quot;</span>,</span>
<span id="cb34-8"><a href="chapter3.html#cb34-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="fu">expression</span>(<span class="fu">paste</span>(</span>
<span id="cb34-9"><a href="chapter3.html#cb34-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;State noise variance &quot;</span>, sigma[w]<span class="sc">^</span><span class="dv">2</span>, <span class="at">sep =</span> <span class="st">&quot; &quot;</span></span>
<span id="cb34-10"><a href="chapter3.html#cb34-10" aria-hidden="true" tabindex="-1"></a>  )),</span>
<span id="cb34-11"><a href="chapter3.html#cb34-11" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;density&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:post-sig2w-rw1"></span>
<img src="gitbook_version_files/figure-html/post-sig2w-rw1-1.png" alt="Posterior distribution of $\sigma^2_w$ in the random walk plus noise model." width="672" />
<p class="caption">
FIGURE 3.3: Posterior distribution of <span class="math inline">\(\sigma^2_w\)</span> in the random walk plus noise model.
</p>
</div>
<p><code>R-INLA</code> incorporates several functions to manipulate the posterior marginals. For example, <code>inla.emarginal()</code> and <code>inla.qmarginal()</code> respectively calculate the expectation and quantiles of the marginal posteriors. The function <code>inla.smarginal()</code> can be used to do spline smoothing, <code>inla.tmarginal()</code> can be used to transform the marginals, and <code>inla.zmarginal()</code> provides summary statistics.</p>
<p>We can write the posterior expectations of <span class="math inline">\(\sigma^2_v\)</span> and <span class="math inline">\(\sigma^2_w\)</span>.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="chapter3.html#cb35-1" aria-hidden="true" tabindex="-1"></a>sigma2.v.hat <span class="ot">&lt;-</span></span>
<span id="cb35-2"><a href="chapter3.html#cb35-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">inla.emarginal</span>(</span>
<span id="cb35-3"><a href="chapter3.html#cb35-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> <span class="cf">function</span>(x)</span>
<span id="cb35-4"><a href="chapter3.html#cb35-4" aria-hidden="true" tabindex="-1"></a>      <span class="fu">exp</span>(<span class="sc">-</span>x),</span>
<span id="cb35-5"><a href="chapter3.html#cb35-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">marginal =</span> model.rw1<span class="sc">$</span>internal.marginals.hyperpar<span class="sc">$</span></span>
<span id="cb35-6"><a href="chapter3.html#cb35-6" aria-hidden="true" tabindex="-1"></a>      <span class="st">`</span><span class="at">Log precision for the Gaussian observations</span><span class="st">`</span></span>
<span id="cb35-7"><a href="chapter3.html#cb35-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb35-8"><a href="chapter3.html#cb35-8" aria-hidden="true" tabindex="-1"></a>sigma2.w.hat <span class="ot">&lt;-</span></span>
<span id="cb35-9"><a href="chapter3.html#cb35-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">inla.emarginal</span>(</span>
<span id="cb35-10"><a href="chapter3.html#cb35-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> <span class="cf">function</span>(x)</span>
<span id="cb35-11"><a href="chapter3.html#cb35-11" aria-hidden="true" tabindex="-1"></a>      <span class="fu">exp</span>(<span class="sc">-</span>x),</span>
<span id="cb35-12"><a href="chapter3.html#cb35-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">marginal =</span> model.rw1<span class="sc">$</span>internal.marginals.hyperpar<span class="sc">$</span><span class="st">`</span><span class="at">Log precision for id</span><span class="st">`</span></span>
<span id="cb35-13"><a href="chapter3.html#cb35-13" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb35-14"><a href="chapter3.html#cb35-14" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">paste</span>(</span>
<span id="cb35-15"><a href="chapter3.html#cb35-15" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;Estimated observation noise variance, sigma2.v&quot;</span>,</span>
<span id="cb35-16"><a href="chapter3.html#cb35-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">round</span>(sigma2.v.hat, <span class="dv">2</span>),</span>
<span id="cb35-17"><a href="chapter3.html#cb35-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">sep =</span> <span class="st">&quot; = &quot;</span></span>
<span id="cb35-18"><a href="chapter3.html#cb35-18" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb35-19"><a href="chapter3.html#cb35-19" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb35-20"><a href="chapter3.html#cb35-20" aria-hidden="true" tabindex="-1"></a><span class="do">## Estimated observation noise variance, sigma2.v = 0.61</span></span>
<span id="cb35-21"><a href="chapter3.html#cb35-21" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">paste</span>(</span>
<span id="cb35-22"><a href="chapter3.html#cb35-22" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;Estimated state noise variance, sigma2.w&quot;</span>,</span>
<span id="cb35-23"><a href="chapter3.html#cb35-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">round</span>(sigma2.w.hat, <span class="dv">2</span>),</span>
<span id="cb35-24"><a href="chapter3.html#cb35-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">sep =</span> <span class="st">&quot; = &quot;</span></span>
<span id="cb35-25"><a href="chapter3.html#cb35-25" aria-hidden="true" tabindex="-1"></a>))</span>
<span id="cb35-26"><a href="chapter3.html#cb35-26" aria-hidden="true" tabindex="-1"></a><span class="do">## Estimated state noise variance, sigma2.w = 0.22</span></span></code></pre></div>
</div>
<div id="fittedvalues" class="section level3 hasAnchor" number="3.2.5">
<h3><span class="header-section-number">3.2.5</span> Fitted values for latent states and responses<a href="chapter3.html#fittedvalues" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We describe how we recover the fitted state variables <span class="math inline">\(x_t\)</span> and the
fitted responses <span class="math inline">\(y_t\)</span> for each time <span class="math inline">\(t=1,\ldots,n\)</span>. The fitted state variable
from <code>R-INLA</code> corresponds to the smoothed estimate of <span class="math inline">\(x_t\)</span>, as we discuss below.</p>
<div id="fitted-values-for-the-state-variables-x_t" class="section level4 unnumbered hasAnchor">
<h4>Fitted values for the state variables <span class="math inline">\(x_t\)</span><a href="chapter3.html#fitted-values-for-the-state-variables-x_t" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>For <span class="math inline">\(t=1,\ldots,n\)</span>, fitted values of the state variable <span class="math inline">\(x_t\)</span> are obtained as the means of the posterior distributions of <span class="math inline">\(x_t\)</span> given all the data
<span class="math inline">\({\boldsymbol y}^n=(y_1,\ldots, y_n)&#39;\)</span>, i.e.,
<span class="math inline">\(\pi(x_t \vert {\boldsymbol y}^n)\)</span>.
Posterior summaries of the state variable (the local level variable in the case of the random walk plus noise model) <span class="math inline">\(x_t\)</span> are stored in <em>summary.random</em>. We display the first few rows below.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="chapter3.html#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(model.rw1<span class="sc">$</span>summary.random<span class="sc">$</span>id.w)</span>
<span id="cb36-2"><a href="chapter3.html#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="do">##   ID  mean     sd 0.025quant 0.5quant 0.975quant  mode       kld</span></span>
<span id="cb36-3"><a href="chapter3.html#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="do">## 1  1 2.488 0.5178     1.4718    2.488      3.505 2.487 8.692e-08</span></span>
<span id="cb36-4"><a href="chapter3.html#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="do">## 2  2 2.428 0.4497     1.5453    2.428      3.311 2.428 1.188e-07</span></span>
<span id="cb36-5"><a href="chapter3.html#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="do">## 3  3 2.331 0.4262     1.4943    2.331      3.168 2.330 9.244e-08</span></span>
<span id="cb36-6"><a href="chapter3.html#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="do">## 4  4 2.270 0.4191     1.4475    2.269      3.093 2.268 1.318e-07</span></span>
<span id="cb36-7"><a href="chapter3.html#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="do">## 5  5 1.918 0.4166     1.0983    1.918      2.734 1.919 8.678e-08</span></span>
<span id="cb36-8"><a href="chapter3.html#cb36-8" aria-hidden="true" tabindex="-1"></a><span class="do">## 6  6 1.745 0.4170     0.9234    1.746      2.561 1.747 2.460e-07</span></span></code></pre></div>
<p>A condensed output is shown below.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="chapter3.html#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(<span class="fu">head</span>(model.rw1<span class="sc">$</span>summary.random<span class="sc">$</span>id[,<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>)]))</span>
<span id="cb37-2"><a href="chapter3.html#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="do">##   ID mean  sd    0.025q 0.5q </span></span>
<span id="cb37-3"><a href="chapter3.html#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 1  2.488 0.518 1.472  2.488</span></span>
<span id="cb37-4"><a href="chapter3.html#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="do">## 2 2  2.428 0.450 1.545  2.428</span></span>
<span id="cb37-5"><a href="chapter3.html#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="do">## 3 3  2.331 0.426 1.494  2.331</span></span>
<span id="cb37-6"><a href="chapter3.html#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="do">## 4 4  2.270 0.419 1.448  2.269</span></span>
<span id="cb37-7"><a href="chapter3.html#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="do">## 5 5  1.918 0.417 1.098  1.918</span></span>
<span id="cb37-8"><a href="chapter3.html#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="do">## 6 6  1.745 0.417 0.923  1.746</span></span></code></pre></div>
<p>In the usual Gaussian DLM terminology, these estimates are called the Kalman smoothed estimates or simply, the <em>smooth</em> <span class="citation">(<a href="#ref-ss2017" role="doc-biblioref">Shumway and Stoffer 2017</a>)</span>, and
are obtained for <span class="math inline">\(t=1,\ldots,n\)</span> using just one <code>inla()</code> call. By default, <code>R-INLA</code> uses a <em>simplified Laplace approximation</em> (see Chapter <a href="chapter2.html#chapter2">2</a> for a description).
For each <span class="math inline">\(t\)</span>, posterior summaries of
<span class="math inline">\(\pi(x_t \vert {\boldsymbol y}^n)\)</span> are given, along with the Kullback-Leibler Divergence (KLD) defined in
<a href="chapter2.html#eq:KLdivergence">(2.17)</a>. The KLD gives the distance between the standard Gaussian distribution and the <em>simplified Laplace approximation</em> to the marginal posterior densities (see Chapter <a href="chapter2.html#chapter2">2</a> – Appendix for a description).</p>
<p>A plot of the posterior means of <span class="math inline">\(x_t\)</span> over time together with the 2.5th and 97.5th percentiles for the random walk plus noise model is shown in Figure <a href="chapter3.html#fig:post-statets-rw1">3.4</a>.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="chapter3.html#cb38-1" aria-hidden="true" tabindex="-1"></a>plot.data <span class="ot">&lt;-</span> model.rw1<span class="sc">$</span>summary.random<span class="sc">$</span>id <span class="sc">%&gt;%</span></span>
<span id="cb38-2"><a href="chapter3.html#cb38-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="at">time =</span> ID, mean,</span>
<span id="cb38-3"><a href="chapter3.html#cb38-3" aria-hidden="true" tabindex="-1"></a>         <span class="st">&quot;0.025quant&quot;</span>, <span class="st">&quot;0.975quant&quot;</span>)</span>
<span id="cb38-4"><a href="chapter3.html#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="fu">multiline.plot</span>(plot.data, <span class="at">xlab =</span> <span class="st">&quot;t&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;posterior mean&quot;</span>,</span>
<span id="cb38-5"><a href="chapter3.html#cb38-5" aria-hidden="true" tabindex="-1"></a>               <span class="at">line.color =</span> <span class="fu">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;red&quot;</span>),</span>
<span id="cb38-6"><a href="chapter3.html#cb38-6" aria-hidden="true" tabindex="-1"></a>               <span class="at">line.size =</span> <span class="fl">0.6</span>)</span></code></pre></div>
<div class="figure"><span id="fig:post-statets-rw1"></span>
<img src="gitbook_version_files/figure-html/post-statets-rw1-1.png" alt="Posterior means and percentiles of the state variable over time in the random walk plus noise model." width="672" />
<p class="caption">
FIGURE 3.4: Posterior means and percentiles of the state variable over time in the random walk plus noise model.
</p>
</div>
<p>For plotting multiple lines, we have used a customized function called <code>multiline.plot()</code>, which uses the <code>R</code> package <code>ggplot2</code> <span class="citation">(<a href="#ref-ggplot2wick" role="doc-biblioref">Wickham 2016</a>)</span>. A summary of this function and other customized functions is shown in Chapter <a href="resources.html#resources">14</a>.</p>
</div>
<div id="fitted-values-for-y_t" class="section level4 unnumbered hasAnchor">
<h4>Fitted values for <span class="math inline">\(y_t\)</span><a href="chapter3.html#fitted-values-for-y_t" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>For <span class="math inline">\(t=1,\ldots,n\)</span>, the fitted values of <span class="math inline">\(y_t\)</span> are the posterior means of the predictive distributions of <span class="math inline">\(y_t\)</span> given <span class="math inline">\({\boldsymbol y}^n = (y_1,\ldots, y_n)&#39;\)</span>
and can be retrieved by using the code below; see Figure <a href="chapter3.html#fig:fity-rw1">3.5</a> for a plot.
As we discussed in Chapter <a href="chapter2.html#chapter2">2</a>, for Gaussian response models (where the link is the identity link),
we can use either the <code>summary.linear.predictor</code> or the <code>summary.fitted.values</code> in the
<code>control.predictor</code> option in <code>inla()</code>, setting <code>compute = TRUE</code>.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="chapter3.html#cb39-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> model.rw1<span class="sc">$</span>summary.linear.predictor<span class="sc">$</span>mean</span>
<span id="cb39-2"><a href="chapter3.html#cb39-2" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(<span class="fu">cbind.data.frame</span>(<span class="at">time =</span> <span class="dv">1</span><span class="sc">:</span>n, y.rw1, fit))</span>
<span id="cb39-3"><a href="chapter3.html#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="fu">multiline.plot</span>(</span>
<span id="cb39-4"><a href="chapter3.html#cb39-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">plot.data =</span> df,</span>
<span id="cb39-5"><a href="chapter3.html#cb39-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">title =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb39-6"><a href="chapter3.html#cb39-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;t&quot;</span>,</span>
<span id="cb39-7"><a href="chapter3.html#cb39-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;y&quot;</span>,</span>
<span id="cb39-8"><a href="chapter3.html#cb39-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">line.type =</span> <span class="st">&quot;dashed&quot;</span>,</span>
<span id="cb39-9"><a href="chapter3.html#cb39-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">line.color =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>),</span>
<span id="cb39-10"><a href="chapter3.html#cb39-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">line.size =</span> <span class="fl">0.6</span></span>
<span id="cb39-11"><a href="chapter3.html#cb39-11" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure"><span id="fig:fity-rw1"></span>
<img src="gitbook_version_files/figure-html/fity-rw1-1.png" alt="Simulated and fitted responses under the random walk plus noise model." width="672" />
<p class="caption">
FIGURE 3.5: Simulated and fitted responses under the random walk plus noise model.
</p>
</div>
<p>Two other approaches to obtain the fitted values are shown below. For Gaussian DLMs, each of these three ways gives exactly the same results. Other summaries such as standard deviation (sd) or quantiles can be obtained similarly. However, for non-Gaussian DLMs, note that we cannot use <code>summary.linear.predictor</code>, but can instead use one of the two alternate approaches shown below. We will revisit this in Chapter <a href="ch-count.html#ch-count">9</a> for count time series. See <code>?inla</code> for more details.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="chapter3.html#cb40-1" aria-hidden="true" tabindex="-1"></a>fit.alt<span class="fl">.1</span> <span class="ot">&lt;-</span> model.rw1<span class="sc">$</span>summary.fitted.values<span class="sc">$</span>mean</span>
<span id="cb40-2"><a href="chapter3.html#cb40-2" aria-hidden="true" tabindex="-1"></a>fit.alt<span class="fl">.2</span> <span class="ot">&lt;-</span> model.rw1<span class="sc">$</span>marginals.linear.predictor <span class="sc">%&gt;%</span> </span>
<span id="cb40-3"><a href="chapter3.html#cb40-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sapply</span>(<span class="cf">function</span>(x) <span class="fu">inla.emarginal</span>(<span class="at">fun =</span> <span class="cf">function</span>(y) y, <span class="at">marginal =</span>x))</span></code></pre></div>
</div>
</div>
<div id="filterestimate" class="section level3 hasAnchor" number="3.2.6">
<h3><span class="header-section-number">3.2.6</span> Filtering and smoothing in DLM<a href="chapter3.html#filterestimate" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As we mentioned in Chapter <a href="chapter1.html#chapter1">1</a>, the Kalman filtering algorithm is a recursive algorithm to estimate the state variable <span class="math inline">\(\boldsymbol{x}_t\)</span> in a DLM given data/information up to time <span class="math inline">\(t\)</span>, i.e., given
<span class="math inline">\({\boldsymbol y}^t\)</span> <span class="citation">(<a href="#ref-ss2017" role="doc-biblioref">Shumway and Stoffer 2017</a>)</span>. Using this algorithm, a time series analyst is able to compute filter estimates of <span class="math inline">\(\boldsymbol{x}_t\)</span> for <span class="math inline">\(t=1,\ldots,n\)</span>. Kalman filtering thus enables <em>recursive estimation</em> of the state variable as information comes in sequentially over time.
It is well known that Kalman smoothing, on the other hand, estimates <span class="math inline">\(\boldsymbol{x}_t\)</span> for times <span class="math inline">\(t = 1,\ldots,n\)</span> given <em>all</em> the data
<span class="math inline">\({\boldsymbol y}^n\)</span>.
<!-- to obtain $\boldsymbol{x}_t^n$ for $t=1,\ldots,n$. -->
When we use <code>R-INLA</code> to fit a DLM, it returns the <em>smoothed</em> estimates of <span class="math inline">\(\boldsymbol{x}_t,~t=1,\ldots,n\)</span>. The posteriors of interest are therefore also approximated using all the information <span class="math inline">\({\boldsymbol y}^n\)</span>.
The forward recursion to obtain filter estimates and backward recursions to obtain the smoothed estimates underlies Kalman’s algorithm (<span class="citation">Kalman (<a href="#ref-kalman1960" role="doc-biblioref">1960</a>)</span>). These estimates are then used to recursively estimate the states and the hyperparameters. As discussed in <span class="citation">Ruiz-Cárdenas, Krainski, and Rue (<a href="#ref-ruiz2012direct" role="doc-biblioref">2012</a>)</span>, a recursive (or sequential) approach for estimation and prediction is necessary in <em>online</em> (or real-time) settings as each new observation arrives, for instance in
computer vision, finance, IoT monitoring systems, real-time traffic monitoring, etc.
In these examples, it is useful to obtain <em>filter estimates</em> of the state variable <span class="math inline">\(x_t\)</span>, and then obtain the corresponding fits for <span class="math inline">\(y_t\)</span>.</p>
<p>The INLA approach argues that the estimation need not be recursive (or <em>dynamic</em>) in situations where all <span class="math inline">\(n\)</span> observations in the time series are available rather than trickling in sequentially. The posteriors of interest are directly approximated in a non-sequential manner.
While filter estimates of the state variable cannot be directly output in <code>R-INLA</code>, we can obtain filter estimates for <span class="math inline">\(x_t,~t=1,\ldots,n\)</span> by repeatedly calling the <code>inla()</code> function <span class="math inline">\(n\)</span> times. This is clearly a computationally expensive exercise, and when possible, it is useful to run the <span class="math inline">\(n\)</span> <code>inla()</code> calls in parallel. We implement the parallel runs using the <code>R</code> package <code>doParallel()</code>.</p>
<p>We obtain filter estimates of <span class="math inline">\(x_t\)</span> from the random walk plus noise model, using the series <span class="math inline">\(y_t\)</span> that we simulated earlier in this section; see Figure <span class="math inline">\(\ref{fig:rw1filter}\)</span>. The custom function to obtain the filter estimates, <code>filt.inla()</code>, is shown in Section <a href="resources.html#custom-functions">14.3</a> and is included in the set of functions we sourced at the beginning of the chapter. Compared with the smoothed estimates for <span class="math inline">\(x_t\)</span>, computation of the filter estimates is time-consuming as expected (since we call <code>inla()</code> <span class="math inline">\(n\)</span> times).</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="chapter3.html#cb41-1" aria-hidden="true" tabindex="-1"></a>out <span class="ot">&lt;-</span></span>
<span id="cb41-2"><a href="chapter3.html#cb41-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filt.inla</span>(</span>
<span id="cb41-3"><a href="chapter3.html#cb41-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">data.series =</span> y.rw1,</span>
<span id="cb41-4"><a href="chapter3.html#cb41-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">model =</span> <span class="st">&quot;rw1&quot;</span>,</span>
<span id="cb41-5"><a href="chapter3.html#cb41-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">trend =</span> <span class="st">&quot;no&quot;</span>,</span>
<span id="cb41-6"><a href="chapter3.html#cb41-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="st">&quot;no&quot;</span></span>
<span id="cb41-7"><a href="chapter3.html#cb41-7" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="chapter3.html#cb42-1" aria-hidden="true" tabindex="-1"></a>filt.all.rw1 <span class="ot">&lt;-</span> out<span class="sc">$</span>filt.all.bind </span>
<span id="cb42-2"><a href="chapter3.html#cb42-2" aria-hidden="true" tabindex="-1"></a>filt.estimate.rw1 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="cn">NA</span>, filt.all.rw1<span class="sc">$</span>mean)</span>
<span id="cb42-3"><a href="chapter3.html#cb42-3" aria-hidden="true" tabindex="-1"></a>smooth.est <span class="ot">&lt;-</span> model.rw1<span class="sc">$</span>summary.random<span class="sc">$</span>id<span class="sc">$</span>mean</span>
<span id="cb42-4"><a href="chapter3.html#cb42-4" aria-hidden="true" tabindex="-1"></a>plot.df <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(<span class="fu">cbind.data.frame</span>(<span class="at">time =</span> id.w,</span>
<span id="cb42-5"><a href="chapter3.html#cb42-5" aria-hidden="true" tabindex="-1"></a>                                      <span class="at">y =</span> y.rw1,</span>
<span id="cb42-6"><a href="chapter3.html#cb42-6" aria-hidden="true" tabindex="-1"></a>                                      <span class="at">filter =</span> filt.estimate.rw1,</span>
<span id="cb42-7"><a href="chapter3.html#cb42-7" aria-hidden="true" tabindex="-1"></a>                                      <span class="at">smooth =</span> smooth.est))</span>
<span id="cb42-8"><a href="chapter3.html#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="fu">multiline.plot</span>(plot.df,</span>
<span id="cb42-9"><a href="chapter3.html#cb42-9" aria-hidden="true" tabindex="-1"></a>               <span class="at">title =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb42-10"><a href="chapter3.html#cb42-10" aria-hidden="true" tabindex="-1"></a>               <span class="at">xlab =</span> <span class="st">&quot;t&quot;</span>,</span>
<span id="cb42-11"><a href="chapter3.html#cb42-11" aria-hidden="true" tabindex="-1"></a>               <span class="at">ylab =</span> <span class="st">&quot; &quot;</span>, <span class="at">line.type =</span> <span class="st">&quot;solid&quot;</span>, <span class="at">line.size =</span> <span class="fl">0.6</span>, </span>
<span id="cb42-12"><a href="chapter3.html#cb42-12" aria-hidden="true" tabindex="-1"></a>               <span class="at">line.color =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;yellow&quot;</span>, <span class="st">&quot;green&quot;</span>))</span></code></pre></div>
<div class="figure"><span id="fig:rw1filter"></span>
<img src="gitbook_version_files/figure-html/rw1filter-1.png" alt="Simulated responses (red), with filtered (yellow) and smoothed (green) estimates of the state variable in the random walk plus noise model." width="672" />
<p class="caption">
FIGURE 3.6: Simulated responses (red), with filtered (yellow) and smoothed (green) estimates of the state variable in the random walk plus noise model.
</p>
</div>
</div>
</div>
<div id="ch3-ar1levelnoise" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> AR(1) with level plus noise model<a href="chapter3.html#ch3-ar1levelnoise" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In Chapter <a href="chapter1.html#chapter1">1</a>, we defined the AR(1) plus noise model using the observation and state equations <a href="chapter1.html#eq:dlm-ar1-obs">(1.19)</a> and <a href="chapter1.html#eq:dlm-ar1-st">(1.20)</a>.
Here, we describe the <code>R-INLA</code> fit for an AR(1) with level plus noise model defined by the following DLM equations:</p>
<p><span class="math display" id="eq:ar1-alpha-st" id="eq:ar1-alpha-obs">\[\begin{align}
y_t &amp;= \alpha + x_t + v_t;~~ v_t \sim N(0, \sigma^2_v),  \tag{3.1}\\
x_t &amp;= \phi x_{t-1} + w_t;~~ w_t \sim N(0, \sigma^2_w), ~
t=2,\ldots,n,
\tag{3.2}
\end{align}\]</span>
and</p>
<p><span class="math display" id="eq:ar1-alpha-st-x1">\[\begin{align}
x_1 \sim N(0, \sigma^2_w/(1-\phi^2)), \tag{3.3}
\end{align}\]</span>
where <span class="math inline">\(\vert \phi \vert &lt;1\)</span> and <span class="math inline">\(\alpha\)</span> is the level parameter.
Let
<span class="math inline">\(\tau = 1/\sigma^2_w\)</span> and <span class="math inline">\(\kappa = \tau (1-\phi^2) = (1-\phi^2)/\sigma^2_w\)</span> denote the marginal precision of the state <span class="math inline">\(x_t\)</span>.</p>
<p>Note: <code>R-INLA</code> uses the notation <span class="math inline">\(\rho\)</span> instead of <span class="math inline">\(\phi\)</span> in the AR(1) model. In the output, when we see <em>Rho</em>, it refers to <span class="math inline">\(\phi\)</span> in our notation.</p>
<p>We use the custom function <code>simulation.from.ar()</code> to simulate <span class="math inline">\(n=500\)</span> values <span class="math inline">\(x_t\)</span> from a Gaussian AR(1) process with <span class="math inline">\(\sigma^2_w=0.1\)</span> and <span class="math inline">\(\phi=0.6\)</span>. This is done using the R function <code>arima.sim()</code>. We add <span class="math inline">\(\alpha=1.4\)</span> and Gaussian errors <span class="math inline">\(v_t\)</span> with variance <span class="math inline">\(\sigma^2_v=0.2\)</span> to <span class="math inline">\(x_t\)</span> in order to get the process <span class="math inline">\(y_t\)</span>; see Figure <span class="math inline">\(\ref{fig:ar1levelnoise}\)</span>.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="chapter3.html#cb43-1" aria-hidden="true" tabindex="-1"></a>sim.ar1.level <span class="ot">&lt;-</span></span>
<span id="cb43-2"><a href="chapter3.html#cb43-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">simulation.from.ar</span>(</span>
<span id="cb43-3"><a href="chapter3.html#cb43-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">sample.size =</span> <span class="dv">500</span>,</span>
<span id="cb43-4"><a href="chapter3.html#cb43-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">burn.in =</span> <span class="dv">100</span>,</span>
<span id="cb43-5"><a href="chapter3.html#cb43-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">phi =</span> <span class="fl">0.6</span>,</span>
<span id="cb43-6"><a href="chapter3.html#cb43-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">level =</span> <span class="fl">1.4</span>,</span>
<span id="cb43-7"><a href="chapter3.html#cb43-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">drift =</span> <span class="dv">0</span>,</span>
<span id="cb43-8"><a href="chapter3.html#cb43-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">V =</span> <span class="fl">0.2</span>,</span>
<span id="cb43-9"><a href="chapter3.html#cb43-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">W =</span> <span class="fl">0.1</span>,</span>
<span id="cb43-10"><a href="chapter3.html#cb43-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot.data =</span> <span class="cn">TRUE</span>,</span>
<span id="cb43-11"><a href="chapter3.html#cb43-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">seed =</span> <span class="dv">123457</span></span>
<span id="cb43-12"><a href="chapter3.html#cb43-12" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb43-13"><a href="chapter3.html#cb43-13" aria-hidden="true" tabindex="-1"></a>sim.ar1.level<span class="sc">$</span>sim.plot</span></code></pre></div>
<div class="figure"><span id="fig:ar1levelnoise"></span>
<img src="gitbook_version_files/figure-html/ar1levelnoise-1.png" alt="Simulated AR(1) with level plus noise series." width="672" />
<p class="caption">
FIGURE 3.7: Simulated AR(1) with level plus noise series.
</p>
</div>
<p>We next describe hyperparameter prior specifications. Let</p>
<p><span class="math display" id="eq:ar1-alpha-priors">\[\begin{align}
\theta_v &amp; = \log(1/\sigma^2_v), \quad \theta_w = \log \kappa = \log \left( \frac{1-\phi^2}{\sigma^2_w}\right), \notag \\
\theta_\phi &amp; = \log \frac{1+\phi}{1-\phi},
\tag{3.4}
\end{align}\]</span>
and let
<span class="math inline">\(\boldsymbol\theta = (\theta_v,\theta_w,\theta_\phi)&#39;\)</span> be the internal representation of the hyperparameters.
The default priors on <span class="math inline">\(\theta_v\)</span> and <span class="math inline">\(\theta_w\)</span> are log-gamma priors with shape and inverse scale being <span class="math inline">\(1\)</span> and 5e-05, and default initial values of <span class="math inline">\(4\)</span> in each case.
Assume that</p>
<p><span class="math display">\[\begin{align*}
\theta_\phi \sim N({\rm mean} =0, {\rm precision}=0.15);
\end{align*}\]</span>
the normal prior depends on the mean and precision (reciprocal of the variance) parameters. <code>R-INLA</code> sets default values of <span class="math inline">\(0\)</span> and <span class="math inline">\(0.15\)</span> respectively for these values, while the initial value of <span class="math inline">\(\theta_\phi\)</span> is assumed to be <span class="math inline">\(2\)</span>. For more details on the default prior specifications, see the <code>R-INLA</code> documentation <code>inla.doc("ar1")</code> and Chapter 5 of <span class="citation">Gómez-Rubio (<a href="#ref-gomez2020bayesian" role="doc-biblioref">2020</a>)</span>.
The prior for the level parameter (intercept) <span class="math inline">\(\alpha\)</span> is assumed to be a normal distribution with mean <span class="math inline">\(0\)</span> and precision <span class="math inline">\(0.001\)</span>. For more details on this, see the <code>R-INLA</code> documentation for <code>?control.fixed</code>.
The code for model fitting is similar to the <em>rw1</em> example, except that we now give a formula for an AR(1) model by inserting
<code>formula.ar1.level</code> as the first item in the call to <code>inla()</code>:</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="chapter3.html#cb44-1" aria-hidden="true" tabindex="-1"></a>y.ar1.level <span class="ot">&lt;-</span> sim.ar1.level<span class="sc">$</span>sim.data</span>
<span id="cb44-2"><a href="chapter3.html#cb44-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(y.ar1.level)</span>
<span id="cb44-3"><a href="chapter3.html#cb44-3" aria-hidden="true" tabindex="-1"></a>id.x <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>n</span>
<span id="cb44-4"><a href="chapter3.html#cb44-4" aria-hidden="true" tabindex="-1"></a>data.ar1.level <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(y.ar1.level, id.x)</span>
<span id="cb44-5"><a href="chapter3.html#cb44-5" aria-hidden="true" tabindex="-1"></a>formula.ar1.level <span class="ot">&lt;-</span></span>
<span id="cb44-6"><a href="chapter3.html#cb44-6" aria-hidden="true" tabindex="-1"></a>  y.ar1.level <span class="sc">~</span> <span class="fu">f</span>(id.x, <span class="at">model =</span> <span class="st">&quot;ar1&quot;</span>, <span class="at">constr =</span> <span class="cn">FALSE</span>)</span>
<span id="cb44-7"><a href="chapter3.html#cb44-7" aria-hidden="true" tabindex="-1"></a>model.ar1.level <span class="ot">&lt;-</span> <span class="fu">inla</span>(</span>
<span id="cb44-8"><a href="chapter3.html#cb44-8" aria-hidden="true" tabindex="-1"></a>  formula.ar1.level,</span>
<span id="cb44-9"><a href="chapter3.html#cb44-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb44-10"><a href="chapter3.html#cb44-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> data.ar1.level,</span>
<span id="cb44-11"><a href="chapter3.html#cb44-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">control.predictor =</span> <span class="fu">list</span>(<span class="at">compute =</span> <span class="cn">TRUE</span>)</span>
<span id="cb44-12"><a href="chapter3.html#cb44-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-13"><a href="chapter3.html#cb44-13" aria-hidden="true" tabindex="-1"></a><span class="co"># summary(model.ar1.level)</span></span>
<span id="cb44-14"><a href="chapter3.html#cb44-14" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(model.ar1.level<span class="sc">$</span>summary.hyperpar[,<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)])</span>
<span id="cb44-15"><a href="chapter3.html#cb44-15" aria-hidden="true" tabindex="-1"></a><span class="do">##   name                       mean  sd   </span></span>
<span id="cb44-16"><a href="chapter3.html#cb44-16" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 Precision for Gaussian obs 4.509 0.591</span></span>
<span id="cb44-17"><a href="chapter3.html#cb44-17" aria-hidden="true" tabindex="-1"></a><span class="do">## 2 Precision for id.x         8.170 1.853</span></span>
<span id="cb44-18"><a href="chapter3.html#cb44-18" aria-hidden="true" tabindex="-1"></a><span class="do">## 3 Rho for id.x               0.450 0.075</span></span>
<span id="cb44-19"><a href="chapter3.html#cb44-19" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(model.ar1.level<span class="sc">$</span>summary.hyperpar[,<span class="fu">c</span>(<span class="dv">3</span><span class="sc">:</span><span class="dv">5</span>)])</span>
<span id="cb44-20"><a href="chapter3.html#cb44-20" aria-hidden="true" tabindex="-1"></a><span class="do">##   name                       0.025q 0.5q  0.975q</span></span>
<span id="cb44-21"><a href="chapter3.html#cb44-21" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 Precision for Gaussian obs 3.389  4.496  5.748</span></span>
<span id="cb44-22"><a href="chapter3.html#cb44-22" aria-hidden="true" tabindex="-1"></a><span class="do">## 2 Precision for id.x         5.277  7.898 12.634</span></span>
<span id="cb44-23"><a href="chapter3.html#cb44-23" aria-hidden="true" tabindex="-1"></a><span class="do">## 3 Rho for id.x               0.301  0.450  0.597</span></span></code></pre></div>
<p>We can then explore the posterior estimates of <span class="math inline">\(\sigma^2_v\)</span>, <span class="math inline">\(Var(x_t)=\sigma^2_x\)</span>, <span class="math inline">\(\phi\)</span>, and <span class="math inline">\(\alpha\)</span>, using code similar to that in the <em>rw1</em> example.
Specifically, for the AR(1) coefficient <span class="math inline">\(\phi\)</span>,
the inverse transformation from <span class="math inline">\(\theta_\phi\)</span> to <span class="math inline">\(\phi\)</span> is obtained as</p>
<p><span class="math display" id="eq:thetatophi">\[\begin{align}
\phi = \frac{2 \exp(\theta_\phi)}{1+\exp(\theta_\phi)} -1.
\tag{3.5}
\end{align}\]</span></p>
<p>For an AR(1) model, note that <code>R-INLA</code> returns the precision of <span class="math inline">\(x_t\)</span> i.e.,
<span class="math inline">\(1/{\rm Var}(x_t)\)</span>. This is different from the output we saw earlier for the <em>rw1</em> model, where <code>inla()</code> returns the precision of the state error, <span class="math inline">\(1/\sigma^2_w\)</span>. For the variance of the state variable, <span class="math inline">\({\rm Var}(x_t)\)</span>, we have</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="chapter3.html#cb45-1" aria-hidden="true" tabindex="-1"></a>var.x.dist <span class="ot">&lt;-</span>  <span class="fu">inla.tmarginal</span>(</span>
<span id="cb45-2"><a href="chapter3.html#cb45-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">fun =</span> <span class="cf">function</span>(x)</span>
<span id="cb45-3"><a href="chapter3.html#cb45-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">exp</span>(<span class="sc">-</span>x),</span>
<span id="cb45-4"><a href="chapter3.html#cb45-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">marginal =</span> </span>
<span id="cb45-5"><a href="chapter3.html#cb45-5" aria-hidden="true" tabindex="-1"></a>    model.ar1.level<span class="sc">$</span>internal.marginals.hyperpar<span class="sc">$</span><span class="st">`</span><span class="at">Log precision for id</span><span class="st">`</span></span>
<span id="cb45-6"><a href="chapter3.html#cb45-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb45-7"><a href="chapter3.html#cb45-7" aria-hidden="true" tabindex="-1"></a>var.x.zm <span class="ot">&lt;-</span> <span class="fu">inla.zmarginal</span>(var.x.dist)</span>
<span id="cb45-8"><a href="chapter3.html#cb45-8" aria-hidden="true" tabindex="-1"></a><span class="do">## Mean            0.128389 </span></span>
<span id="cb45-9"><a href="chapter3.html#cb45-9" aria-hidden="true" tabindex="-1"></a><span class="do">## Stdev           0.027596 </span></span>
<span id="cb45-10"><a href="chapter3.html#cb45-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Quantile  0.025 0.0799905 </span></span>
<span id="cb45-11"><a href="chapter3.html#cb45-11" aria-hidden="true" tabindex="-1"></a><span class="do">## Quantile  0.25  0.10859 </span></span>
<span id="cb45-12"><a href="chapter3.html#cb45-12" aria-hidden="true" tabindex="-1"></a><span class="do">## Quantile  0.5   0.126634 </span></span>
<span id="cb45-13"><a href="chapter3.html#cb45-13" aria-hidden="true" tabindex="-1"></a><span class="do">## Quantile  0.75  0.145925 </span></span>
<span id="cb45-14"><a href="chapter3.html#cb45-14" aria-hidden="true" tabindex="-1"></a><span class="do">## Quantile  0.975 0.187606</span></span></code></pre></div>
<p>The level (or intercept) is a fixed effect in this model. We can recover a summary of the fixed effect using</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="chapter3.html#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(model.ar1.level<span class="sc">$</span>summary.fixed[,<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>)])</span>
<span id="cb46-2"><a href="chapter3.html#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="do">##   name      mean  sd    0.025q 0.5q  0.975q</span></span>
<span id="cb46-3"><a href="chapter3.html#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 Intercept 1.287 0.034 1.221  1.287 1.354</span></span></code></pre></div>
<p>The <em>Highest Posterior Density</em> (HPD) interval <span class="citation">(<a href="#ref-GamermanLopes" role="doc-biblioref">D. Gamerman and Lopes 2006</a>)</span> for <span class="math inline">\(\alpha\)</span> is</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="chapter3.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inla.hpdmarginal</span>(<span class="fl">0.95</span>, model.ar1.level<span class="sc">$</span>marginals.fixed<span class="sc">$</span><span class="st">`</span><span class="at">(Intercept)</span><span class="st">`</span>)</span>
<span id="cb47-2"><a href="chapter3.html#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="do">##              low  high</span></span>
<span id="cb47-3"><a href="chapter3.html#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="do">## level:0.95 1.221 1.353</span></span></code></pre></div>
<p>An alternate way to obtain posterior summaries for the fixed effect is given below.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="chapter3.html#cb48-1" aria-hidden="true" tabindex="-1"></a>alpha.fe <span class="ot">&lt;-</span>  <span class="fu">inla.tmarginal</span>(</span>
<span id="cb48-2"><a href="chapter3.html#cb48-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">fun =</span> <span class="cf">function</span>(x)</span>
<span id="cb48-3"><a href="chapter3.html#cb48-3" aria-hidden="true" tabindex="-1"></a>    x,</span>
<span id="cb48-4"><a href="chapter3.html#cb48-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">marginal =</span> model.ar1.level<span class="sc">$</span>marginals.fixed<span class="sc">$</span><span class="st">`</span><span class="at">(Intercept)</span><span class="st">`</span></span>
<span id="cb48-5"><a href="chapter3.html#cb48-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb48-6"><a href="chapter3.html#cb48-6" aria-hidden="true" tabindex="-1"></a>alpha.fe.zm <span class="ot">&lt;-</span> <span class="fu">inla.zmarginal</span>(alpha.fe, <span class="at">silent =</span> <span class="cn">TRUE</span>)</span>
<span id="cb48-7"><a href="chapter3.html#cb48-7" aria-hidden="true" tabindex="-1"></a>alpha.hpd.interval <span class="ot">&lt;-</span> <span class="fu">inla.hpdmarginal</span>(<span class="at">p =</span> <span class="fl">0.95</span>, alpha.fe)</span></code></pre></div>
<p>The fitted values for <span class="math inline">\(x_t\)</span> and <span class="math inline">\(y_t\)</span> for the AR(1) with level plus noise model can be obtained using a code similar to that for the <em>rw1</em> model. This is available on the GitHub link associated with the book.</p>
<p>It is useful to illustrate the effect of ignoring the level <span class="math inline">\(\alpha\)</span> in fitting the model. While the correct (simulated) model is <a href="chapter3.html#eq:ar1-alpha-obs">(3.1)</a> and <a href="chapter3.html#eq:ar1-alpha-st">(3.2)</a>, suppose instead that a user fits a model without level by using the formula shown below.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="chapter3.html#cb49-1" aria-hidden="true" tabindex="-1"></a>formula.ar1.nolevel <span class="ot">&lt;-</span></span>
<span id="cb49-2"><a href="chapter3.html#cb49-2" aria-hidden="true" tabindex="-1"></a>  y.ar1.level <span class="sc">~</span> <span class="sc">-</span><span class="dv">1</span> <span class="sc">+</span> <span class="fu">f</span>(id.x, <span class="at">model =</span> <span class="st">&quot;ar1&quot;</span>, <span class="at">constr =</span> <span class="cn">FALSE</span>)</span>
<span id="cb49-3"><a href="chapter3.html#cb49-3" aria-hidden="true" tabindex="-1"></a>model.ar1.nolevel <span class="ot">&lt;-</span> <span class="fu">inla</span>(</span>
<span id="cb49-4"><a href="chapter3.html#cb49-4" aria-hidden="true" tabindex="-1"></a>  formula.ar1.nolevel,</span>
<span id="cb49-5"><a href="chapter3.html#cb49-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb49-6"><a href="chapter3.html#cb49-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> data.ar1.level,</span>
<span id="cb49-7"><a href="chapter3.html#cb49-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">control.predictor =</span> <span class="fu">list</span>(<span class="at">compute =</span> <span class="cn">TRUE</span>)</span>
<span id="cb49-8"><a href="chapter3.html#cb49-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-9"><a href="chapter3.html#cb49-9" aria-hidden="true" tabindex="-1"></a><span class="co"># summary(model.ar1.nolevel)</span></span>
<span id="cb49-10"><a href="chapter3.html#cb49-10" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(model.ar1.nolevel<span class="sc">$</span>summary.hyperpar[,<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)])</span>
<span id="cb49-11"><a href="chapter3.html#cb49-11" aria-hidden="true" tabindex="-1"></a><span class="do">##   name                       mean  sd   </span></span>
<span id="cb49-12"><a href="chapter3.html#cb49-12" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 Precision for Gaussian obs 2.843 0.181</span></span>
<span id="cb49-13"><a href="chapter3.html#cb49-13" aria-hidden="true" tabindex="-1"></a><span class="do">## 2 Precision for id.x         3.100 1.791</span></span>
<span id="cb49-14"><a href="chapter3.html#cb49-14" aria-hidden="true" tabindex="-1"></a><span class="do">## 3 Rho for id.x               1.000 0.000</span></span>
<span id="cb49-15"><a href="chapter3.html#cb49-15" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(model.ar1.nolevel<span class="sc">$</span>summary.hyperpar[,<span class="fu">c</span>(<span class="dv">3</span><span class="sc">:</span><span class="dv">5</span>)])</span>
<span id="cb49-16"><a href="chapter3.html#cb49-16" aria-hidden="true" tabindex="-1"></a><span class="do">##   name                       0.025q 0.5q  0.975q</span></span>
<span id="cb49-17"><a href="chapter3.html#cb49-17" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 Precision for Gaussian obs 2.504  2.837 3.217 </span></span>
<span id="cb49-18"><a href="chapter3.html#cb49-18" aria-hidden="true" tabindex="-1"></a><span class="do">## 2 Precision for id.x         0.844  2.715 7.642 </span></span>
<span id="cb49-19"><a href="chapter3.html#cb49-19" aria-hidden="true" tabindex="-1"></a><span class="do">## 3 Rho for id.x               0.998  1.000 1.000</span></span></code></pre></div>
<p>Note that as a consequence of omitting <span class="math inline">\(\alpha\)</span> in the modeling, the estimate of the coefficient <span class="math inline">\(\phi\)</span> tends to
<span class="math inline">\(1\)</span>, which would indicate a latent random walk dependence! To avoid this, we recommend that a user always fits a model which includes a level <span class="math inline">\(\alpha\)</span> in the observation equation. Of course, this coefficient will be estimated close to <span class="math inline">\(0\)</span> when the level in the time series is zero.</p>
</div>
<div id="ch3-high-lags" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> Dynamic linear models with higher order AR lags<a href="chapter3.html#ch3-high-lags" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In <code>R-INLA</code>, we can assume that the latent Gaussian process <span class="math inline">\(x_t\)</span> is an autoregressive process of order <span class="math inline">\(p\)</span> (i.e., an AR<span class="math inline">\((p)\)</span> process) for
<span class="math inline">\(p \ge 1\)</span>, as described below.</p>
<div id="arp-with-level-plus-noise-model" class="section level3 unnumbered hasAnchor">
<h3>AR<span class="math inline">\((p)\)</span> with level plus noise model<a href="chapter3.html#arp-with-level-plus-noise-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Assume that the latent process <span class="math inline">\(x_t\)</span> follows a stationary Gaussian AR<span class="math inline">\((p)\)</span> process</p>
<p><span class="math display" id="eq:arp">\[\begin{align}
\phi(B) x_t = (1-\phi_1 B - \phi_2 B^2 -\ldots - \phi_p B^p) x_t = w_t,
\tag{3.6}
\end{align}\]</span>
where <span class="math inline">\(w_t \sim N(0,\sigma^2_w)\)</span>, and
the AR coefficients <span class="math inline">\(\phi_1, \phi_2,\ldots, \phi_p\)</span> satisfy the stationarity condition, i.e., the modulus of each root of the AR polynomial equation
<span class="math inline">\(\phi(B)= 0\)</span> is greater than 1. See Chapter <a href="chapter3.html#chapter3">3</a> – Appendix for more details, such as a definition of the backshift operator <span class="math inline">\(B\)</span>, and checking the stationarity conditions using the <code>polyroot()</code> function in <code>R</code>.</p>
<p>The AR<span class="math inline">\((p)\)</span> with level plus noise model for <span class="math inline">\(y_t\)</span> is defined as follows:</p>
<p><span class="math display" id="eq:dlm-arp-st" id="eq:dlm-arp-obs">\[\begin{align}
y_t &amp;= \alpha + x_t + v_t;~~ v_t \sim N(0, \sigma^2_v),  \tag{3.7} \\
x_t &amp;=  \sum_{j=1}^p \phi_j x_{t-j} + w_t;~~
w_t  \sim N(0, \sigma^2_w),   \tag{3.8}
\end{align}\]</span>
where, <span class="math inline">\(\alpha\)</span> is the level; we assume that <span class="math inline">\(x_0= x_{-1}=\ldots=x_{1-p}=0\)</span>, and the errors <span class="math inline">\(v_t\)</span> and <span class="math inline">\(w_t\)</span> follow zero mean normal distributions with unknown variances <span class="math inline">\(\sigma^2_v\)</span> and <span class="math inline">\(\sigma^2_w\)</span> respectively. <code>R-INLA</code> parameterizes the AR<span class="math inline">\((p)\)</span> process in terms of the partial autocorrelations (see Chapter <a href="chapter3.html#chapter3">3</a> – Appendix). When <span class="math inline">\(p=2\)</span>,</p>
<p><span class="math display" id="eq:pacftrans1">\[\begin{align}
r_1 = \phi_1/(1 - \phi_2), \mbox{ and } ~r_2 = \phi_2, \tag{3.9}
\end{align}\]</span>
<code>R-INLA</code> estimates these together with the error precisions
<span class="math inline">\(1/\sigma^2_v\)</span> and <span class="math inline">\(1/\sigma^2_w\)</span>. Using the inverse of this 1-1 transformation (see <a href="chapter3.html#eq:pacftrans2">(3.40)</a> in Chapter <a href="chapter3.html#chapter3">3</a> - Appendix), we can recover the estimates of <span class="math inline">\(\boldsymbol{\phi} = (\phi_1,\ldots,\phi_p)&#39;\)</span>. These steps are shown below for an AR<span class="math inline">\((2)\)</span> model.</p>
<div id="example-ar2-with-level-plus-noise-model" class="section level4 unnumbered hasAnchor">
<h4>Example: AR(2) with level plus noise model<a href="chapter3.html#example-ar2-with-level-plus-noise-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We simulate an AR(2) with level plus noise model with true values <span class="math inline">\(\phi_1=1.5\)</span> and <span class="math inline">\(\phi_2=-0.75\)</span> (corresponding to a stationary process), level <span class="math inline">\(\alpha=10\)</span>, and error variances <span class="math inline">\(\sigma^2_v=1.25\)</span> and <span class="math inline">\(\sigma^2_w=0.05\)</span>. The plot of simulated series is shown in Figure <a href="chapter3.html#fig:ar2">3.8</a>.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="chapter3.html#cb50-1" aria-hidden="true" tabindex="-1"></a>sim.ar2 <span class="ot">&lt;-</span></span>
<span id="cb50-2"><a href="chapter3.html#cb50-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">simulation.from.ar</span>(</span>
<span id="cb50-3"><a href="chapter3.html#cb50-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">sample.size =</span> <span class="dv">500</span>,</span>
<span id="cb50-4"><a href="chapter3.html#cb50-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">burn.in =</span> <span class="dv">100</span>,</span>
<span id="cb50-5"><a href="chapter3.html#cb50-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">phi =</span> <span class="fu">c</span>(<span class="fl">1.5</span>,<span class="sc">-</span><span class="fl">0.75</span>),</span>
<span id="cb50-6"><a href="chapter3.html#cb50-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">level =</span> <span class="dv">10</span>,</span>
<span id="cb50-7"><a href="chapter3.html#cb50-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">drift =</span> <span class="dv">0</span>,</span>
<span id="cb50-8"><a href="chapter3.html#cb50-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">V =</span> <span class="fl">1.25</span>,</span>
<span id="cb50-9"><a href="chapter3.html#cb50-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">W =</span> <span class="fl">0.05</span>,</span>
<span id="cb50-10"><a href="chapter3.html#cb50-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot.data =</span> <span class="cn">TRUE</span>,</span>
<span id="cb50-11"><a href="chapter3.html#cb50-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">seed =</span> <span class="dv">123457</span></span>
<span id="cb50-12"><a href="chapter3.html#cb50-12" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb50-13"><a href="chapter3.html#cb50-13" aria-hidden="true" tabindex="-1"></a>sim.ar2<span class="sc">$</span>sim.plot</span></code></pre></div>
<div class="figure"><span id="fig:ar2"></span>
<img src="gitbook_version_files/figure-html/ar2-1.png" alt="Simulated AR(2) with level plus noise series." width="672" />
<p class="caption">
FIGURE 3.8: Simulated AR(2) with level plus noise series.
</p>
</div>
<p>The 1-1 transformation in <a href="chapter3.html#eq:pacftrans1">(3.9)</a> can be written as</p>
<!--r_1 = \phi_1/(1 - \phi_2), \mbox{ and } ~r_2 = \phi_2.-->
<p><span class="math display">\[\begin{align*}
\phi_1 = r_1 (1-r_2), \mbox{ and } \phi_2 = r_2.
\end{align*}\]</span>
The model fitting is shown below.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="chapter3.html#cb51-1" aria-hidden="true" tabindex="-1"></a>y.ar2 <span class="ot">&lt;-</span> sim.ar2<span class="sc">$</span>sim.data</span>
<span id="cb51-2"><a href="chapter3.html#cb51-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(y.ar2)</span>
<span id="cb51-3"><a href="chapter3.html#cb51-3" aria-hidden="true" tabindex="-1"></a>id.x <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>n</span>
<span id="cb51-4"><a href="chapter3.html#cb51-4" aria-hidden="true" tabindex="-1"></a>ar2.dat <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(y.ar2, id.x)</span>
<span id="cb51-5"><a href="chapter3.html#cb51-5" aria-hidden="true" tabindex="-1"></a>formula.ar2 <span class="ot">&lt;-</span> y.ar2 <span class="sc">~</span>  <span class="fu">f</span>(id.x,</span>
<span id="cb51-6"><a href="chapter3.html#cb51-6" aria-hidden="true" tabindex="-1"></a>                     <span class="at">model =</span> <span class="st">&quot;ar&quot;</span>,</span>
<span id="cb51-7"><a href="chapter3.html#cb51-7" aria-hidden="true" tabindex="-1"></a>                     <span class="at">order =</span> <span class="dv">2</span>,</span>
<span id="cb51-8"><a href="chapter3.html#cb51-8" aria-hidden="true" tabindex="-1"></a>                     <span class="at">constr =</span> <span class="cn">FALSE</span>) </span>
<span id="cb51-9"><a href="chapter3.html#cb51-9" aria-hidden="true" tabindex="-1"></a>model.ar2 <span class="ot">&lt;-</span> <span class="fu">inla</span>(</span>
<span id="cb51-10"><a href="chapter3.html#cb51-10" aria-hidden="true" tabindex="-1"></a>  formula.ar2,</span>
<span id="cb51-11"><a href="chapter3.html#cb51-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb51-12"><a href="chapter3.html#cb51-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> ar2.dat,</span>
<span id="cb51-13"><a href="chapter3.html#cb51-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">control.predictor =</span> <span class="fu">list</span>(<span class="at">compute =</span> <span class="cn">TRUE</span>)</span>
<span id="cb51-14"><a href="chapter3.html#cb51-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb51-15"><a href="chapter3.html#cb51-15" aria-hidden="true" tabindex="-1"></a><span class="co"># summary(model.ar2)</span></span>
<span id="cb51-16"><a href="chapter3.html#cb51-16" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(model.ar2<span class="sc">$</span>summary.hyperpar[,<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)])</span>
<span id="cb51-17"><a href="chapter3.html#cb51-17" aria-hidden="true" tabindex="-1"></a><span class="do">##   name                       mean   sd   </span></span>
<span id="cb51-18"><a href="chapter3.html#cb51-18" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 Precision for Gaussian obs  0.808 0.062</span></span>
<span id="cb51-19"><a href="chapter3.html#cb51-19" aria-hidden="true" tabindex="-1"></a><span class="do">## 2 Precision for id.x          2.106 0.481</span></span>
<span id="cb51-20"><a href="chapter3.html#cb51-20" aria-hidden="true" tabindex="-1"></a><span class="do">## 3 PACF1 for id.x              0.856 0.021</span></span>
<span id="cb51-21"><a href="chapter3.html#cb51-21" aria-hidden="true" tabindex="-1"></a><span class="do">## 4 PACF2 for id.x             -0.743 0.074</span></span>
<span id="cb51-22"><a href="chapter3.html#cb51-22" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(model.ar2<span class="sc">$</span>summary.hyperpar[,<span class="fu">c</span>(<span class="dv">3</span><span class="sc">:</span><span class="dv">5</span>)])</span>
<span id="cb51-23"><a href="chapter3.html#cb51-23" aria-hidden="true" tabindex="-1"></a><span class="do">##   name                       0.025q 0.5q   0.975q</span></span>
<span id="cb51-24"><a href="chapter3.html#cb51-24" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 Precision for Gaussian obs  0.692  0.806  0.937</span></span>
<span id="cb51-25"><a href="chapter3.html#cb51-25" aria-hidden="true" tabindex="-1"></a><span class="do">## 2 Precision for id.x          1.335  2.047  3.215</span></span>
<span id="cb51-26"><a href="chapter3.html#cb51-26" aria-hidden="true" tabindex="-1"></a><span class="do">## 3 PACF1 for id.x              0.812  0.857  0.893</span></span>
<span id="cb51-27"><a href="chapter3.html#cb51-27" aria-hidden="true" tabindex="-1"></a><span class="do">## 4 PACF2 for id.x             -0.863 -0.752 -0.572</span></span></code></pre></div>
<p>We can recover the summary of the fixed level <span class="math inline">\(\alpha\)</span> using</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="chapter3.html#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(model.ar2<span class="sc">$</span>summary.fixed[,<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>)])</span>
<span id="cb52-2"><a href="chapter3.html#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="do">##   name      mean  sd    0.025q 0.5q  0.975q</span></span>
<span id="cb52-3"><a href="chapter3.html#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 Intercept 9.843 0.067 9.712  9.843 9.974</span></span></code></pre></div>
<p>The inverse of the 1-1 transformation <a href="chapter3.html#eq:pacftrans2">(3.40)</a> enables us to recover the estimated <span class="math inline">\(\phi_1\)</span> and <span class="math inline">\(\phi_2\)</span> coefficients from the estimated partial autocorrelations, using
the following functions:</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="chapter3.html#cb53-1" aria-hidden="true" tabindex="-1"></a>pacf <span class="ot">&lt;-</span> model.ar2<span class="sc">$</span>summary.hyperpar<span class="sc">$</span>mean[<span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>]</span>
<span id="cb53-2"><a href="chapter3.html#cb53-2" aria-hidden="true" tabindex="-1"></a>phi <span class="ot">&lt;-</span> <span class="fu">inla.ar.pacf2phi</span>(pacf)</span>
<span id="cb53-3"><a href="chapter3.html#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(phi)</span>
<span id="cb53-4"><a href="chapter3.html#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="do">## [1]  1.491 -0.743</span></span></code></pre></div>
<p>We see that these values <span class="math inline">\(\hat{\phi}_1 =\)</span> 1.491 and <span class="math inline">\(\hat{\phi}_2 =\)</span> <span class="math inline">\(-0.743\)</span> are close to the true values <span class="math inline">\(\phi_1=1.5\)</span> and <span class="math inline">\(\phi_2= -0.75\)</span>.
We can recover the variance of the state error <span class="math inline">\(w_t\)</span> as follows. Recall
that the Wold representation (or the MA<span class="math inline">\((\infty)\)</span> representation) of a stationary AR<span class="math inline">\((p)\)</span> process <a href="chapter3.html#eq:arp">(3.6)</a> is given by (see <span class="citation">Shumway and Stoffer (<a href="#ref-ss2017" role="doc-biblioref">2017</a>)</span>)</p>
<p><span class="math display" id="eq:mainfty">\[\begin{align}
x_t = \phi^{-1}(B) w_t = \sum_{j=0}^\infty \psi_j w_{t-j},   \tag{3.10}
\end{align}\]</span>
where the weights in the infinite order polynomial
<span class="math inline">\(\psi(B) = \sum_{j=0}^\infty \psi_j B^j\)</span> are obtained by solving
<span class="math inline">\(\psi(B) \phi(B)=1\)</span>. Then,</p>
<p><span class="math display" id="eq:varx">\[\begin{align}
{\rm Var}(x_t) = \sigma^2_w  \sum_{j=0}^\infty \psi_j^2.   \tag{3.11}
\end{align}\]</span>
We use the R function <code>ARMAtoMA()</code> to get a large number (here, <span class="math inline">\(100\)</span>) of <span class="math inline">\(\psi\)</span> weights to approximate the infinite sum in <a href="chapter3.html#eq:varx">(3.11)</a>.
The <code>inla()</code> output provides an estimate of <span class="math inline">\(1/{\rm Var}(x_t)\)</span>; using these, we can recover an estimate of <span class="math inline">\(\sigma^2_w\)</span> using <a href="chapter3.html#eq:varx">(3.11)</a>.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="chapter3.html#cb54-1" aria-hidden="true" tabindex="-1"></a>phi <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">1.5</span>, <span class="sc">-</span><span class="fl">0.75</span>)</span>
<span id="cb54-2"><a href="chapter3.html#cb54-2" aria-hidden="true" tabindex="-1"></a>psiwt.ar2 <span class="ot">&lt;-</span> <span class="fu">ARMAtoMA</span>(<span class="at">ar =</span> phi, <span class="at">ma =</span> <span class="dv">0</span>, <span class="dv">100</span>)</span>
<span id="cb54-3"><a href="chapter3.html#cb54-3" aria-hidden="true" tabindex="-1"></a>precision.x.hat <span class="ot">&lt;-</span> model.ar2<span class="sc">$</span>summary.hyperpar<span class="sc">$</span>mean[<span class="dv">2</span>]</span>
<span id="cb54-4"><a href="chapter3.html#cb54-4" aria-hidden="true" tabindex="-1"></a>sigma2.w.hat <span class="ot">&lt;-</span></span>
<span id="cb54-5"><a href="chapter3.html#cb54-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">inla.emarginal</span>(</span>
<span id="cb54-6"><a href="chapter3.html#cb54-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> <span class="cf">function</span>(x)</span>
<span id="cb54-7"><a href="chapter3.html#cb54-7" aria-hidden="true" tabindex="-1"></a>      <span class="fu">exp</span>(<span class="sc">-</span>x),</span>
<span id="cb54-8"><a href="chapter3.html#cb54-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">marginal =</span> model.ar2<span class="sc">$</span>internal.marginals.hyperpar<span class="sc">$</span><span class="st">`</span><span class="at">Log precision for id</span><span class="st">`</span></span>
<span id="cb54-9"><a href="chapter3.html#cb54-9" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">/</span> <span class="fu">sum</span>(psiwt.ar2 <span class="sc">^</span> <span class="dv">2</span>)</span>
<span id="cb54-10"><a href="chapter3.html#cb54-10" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">paste</span>(</span>
<span id="cb54-11"><a href="chapter3.html#cb54-11" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;Estimated state noise variance, sigma2.w&quot;</span>,</span>
<span id="cb54-12"><a href="chapter3.html#cb54-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">round</span>(sigma2.w.hat, <span class="dv">2</span>),</span>
<span id="cb54-13"><a href="chapter3.html#cb54-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">sep =</span> <span class="st">&quot; = &quot;</span></span>
<span id="cb54-14"><a href="chapter3.html#cb54-14" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb54-15"><a href="chapter3.html#cb54-15" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb54-16"><a href="chapter3.html#cb54-16" aria-hidden="true" tabindex="-1"></a><span class="do">## Estimated state noise variance, sigma2.w = 0.07</span></span></code></pre></div>
<p>The posterior estimate 0.07 is close to
the true value of <span class="math inline">\(\sigma^2_w = 0.05\)</span>.</p>
<p>We end this example by estimating posterior marginals of the parameters <span class="math inline">\(\phi_1\)</span> and <span class="math inline">\(\phi_2\)</span> using <code>inla.hyperpar.sample()</code>. In Figure <a href="chapter3.html#fig:phi-plot">3.9</a>, we show plots of the marginal posterior distributions of <span class="math inline">\(\phi_1\)</span> and <span class="math inline">\(\phi_2\)</span>.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="chapter3.html#cb55-1" aria-hidden="true" tabindex="-1"></a>n.samples <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb55-2"><a href="chapter3.html#cb55-2" aria-hidden="true" tabindex="-1"></a>pacfs <span class="ot">&lt;-</span> <span class="fu">inla.hyperpar.sample</span>(n.samples, model.ar2)[, <span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>]</span>
<span id="cb55-3"><a href="chapter3.html#cb55-3" aria-hidden="true" tabindex="-1"></a>phis <span class="ot">&lt;-</span> <span class="fu">apply</span>(pacfs, 1L, inla.ar.pacf2phi)</span>
<span id="cb55-4"><a href="chapter3.html#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb55-5"><a href="chapter3.html#cb55-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(</span>
<span id="cb55-6"><a href="chapter3.html#cb55-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">density</span>(phis[<span class="dv">1</span>, ]),</span>
<span id="cb55-7"><a href="chapter3.html#cb55-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;l&quot;</span>,</span>
<span id="cb55-8"><a href="chapter3.html#cb55-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">main=</span><span class="st">&quot;&quot;</span>,</span>
<span id="cb55-9"><a href="chapter3.html#cb55-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="fu">expression</span>(phi[<span class="dv">1</span>]),</span>
<span id="cb55-10"><a href="chapter3.html#cb55-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;density&quot;</span></span>
<span id="cb55-11"><a href="chapter3.html#cb55-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb55-12"><a href="chapter3.html#cb55-12" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fl">1.5</span>)</span>
<span id="cb55-13"><a href="chapter3.html#cb55-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(</span>
<span id="cb55-14"><a href="chapter3.html#cb55-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">density</span>(phis[<span class="dv">2</span>, ]),</span>
<span id="cb55-15"><a href="chapter3.html#cb55-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;l&quot;</span>,</span>
<span id="cb55-16"><a href="chapter3.html#cb55-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">main=</span><span class="st">&quot;&quot;</span>,</span>
<span id="cb55-17"><a href="chapter3.html#cb55-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="fu">expression</span>(phi[<span class="dv">2</span>]),</span>
<span id="cb55-18"><a href="chapter3.html#cb55-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;density&quot;</span></span>
<span id="cb55-19"><a href="chapter3.html#cb55-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb55-20"><a href="chapter3.html#cb55-20" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="sc">-</span><span class="fl">0.75</span>)</span></code></pre></div>
<div class="figure"><span id="fig:phi-plot"></span>
<img src="gitbook_version_files/figure-html/phi-plot-1.png" alt="Marginal posterior densities of $\phi_1$ (left panel) and $\phi_2$ (right panel) in the AR(2) with level plus noise model. The vertical lines represent the true values assumed in the simulation." width="672" />
<p class="caption">
FIGURE 3.9: Marginal posterior densities of <span class="math inline">\(\phi_1\)</span> (left panel) and <span class="math inline">\(\phi_2\)</span> (right panel) in the AR(2) with level plus noise model. The vertical lines represent the true values assumed in the simulation.
</p>
</div>
<p>Since <code>R-INLA</code> parametrizes <span class="math inline">\(\phi_1\)</span> and <span class="math inline">\(\phi_2\)</span> as <span class="math inline">\(r_1\)</span> and <span class="math inline">\(r_2\)</span> (see <a href="chapter3.html#eq:pacftrans1">(3.9)</a>), we show the code to obtain their marginal posteriors as well (see Figure <a href="chapter3.html#fig:pacf-plot">3.10</a>).</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="chapter3.html#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb56-2"><a href="chapter3.html#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(</span>
<span id="cb56-3"><a href="chapter3.html#cb56-3" aria-hidden="true" tabindex="-1"></a>  model.ar2<span class="sc">$</span>marginals.hyperpar<span class="sc">$</span><span class="st">`</span><span class="at">PACF1 for id.x</span><span class="st">`</span>,</span>
<span id="cb56-4"><a href="chapter3.html#cb56-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;l&quot;</span>,</span>
<span id="cb56-5"><a href="chapter3.html#cb56-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb56-6"><a href="chapter3.html#cb56-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="fu">expression</span>(r[<span class="dv">1</span>]),</span>
<span id="cb56-7"><a href="chapter3.html#cb56-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;density&quot;</span></span>
<span id="cb56-8"><a href="chapter3.html#cb56-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb56-9"><a href="chapter3.html#cb56-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(</span>
<span id="cb56-10"><a href="chapter3.html#cb56-10" aria-hidden="true" tabindex="-1"></a>  model.ar2<span class="sc">$</span>marginals.hyperpar<span class="sc">$</span><span class="st">`</span><span class="at">PACF2 for id.x</span><span class="st">`</span>,</span>
<span id="cb56-11"><a href="chapter3.html#cb56-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;l&quot;</span>,</span>
<span id="cb56-12"><a href="chapter3.html#cb56-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb56-13"><a href="chapter3.html#cb56-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="fu">expression</span>(r[<span class="dv">2</span>]),</span>
<span id="cb56-14"><a href="chapter3.html#cb56-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;density&quot;</span></span>
<span id="cb56-15"><a href="chapter3.html#cb56-15" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure"><span id="fig:pacf-plot"></span>
<img src="gitbook_version_files/figure-html/pacf-plot-1.png" alt="Marginal posterior densities of PACF(1) and PACF(2) in the internal `R-INLA` representation for an AR(2) with level plus noise model." width="672" />
<p class="caption">
FIGURE 3.10: Marginal posterior densities of PACF(1) and PACF(2) in the internal <code>R-INLA</code> representation for an AR(2) with level plus noise model.
</p>
</div>
<p>We end this section with a note that the syntax for fitting an AR<span class="math inline">\((p)\)</span> model also works when <span class="math inline">\(p=1\)</span>, so that we can also fit an AR(1) with the level plus noise model using</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="chapter3.html#cb57-1" aria-hidden="true" tabindex="-1"></a>formula <span class="ot">&lt;-</span> y <span class="sc">~</span> <span class="fu">f</span>(id.x, <span class="at">model =</span> <span class="st">&quot;ar&quot;</span>,<span class="at">order =</span> <span class="dv">1</span>) </span></code></pre></div>
</div>
</div>
</div>
<div id="ch3-rwdrift" class="section level2 hasAnchor" number="3.5">
<h2><span class="header-section-number">3.5</span> Random walk with drift plus noise model<a href="chapter3.html#ch3-rwdrift" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The state equation describes <span class="math inline">\(x_t\)</span> as a random walk with drift <span class="math inline">\(\delta\)</span> plus Gaussian noise. We then observe the signal <span class="math inline">\(x_t\)</span> with measurement noise, as described below:</p>
<p><span class="math display" id="eq:rw-delta-st" id="eq:rw-delta-obs">\[\begin{align}
y_t &amp;= x_t + v_t;~~ v_t \sim N(0, \sigma^2_v),  \tag{3.12}\\
x_t &amp;= \delta + x_{t-1} + w_t;~~ w_t \sim N(0, \sigma^2_w).
\tag{3.13}
\end{align}\]</span>
Using the <code>arima.sim()</code> function, we simulate the latent Gaussian process <span class="math inline">\(x_t\)</span>,
assuming a state error variance <span class="math inline">\(\sigma^2_w = 0.05\)</span> and drift <span class="math inline">\(\delta = 0.1\)</span>. Adding Gaussian observation noise <span class="math inline">\(v_t\)</span> with variance <span class="math inline">\(\sigma^2_v = 0.5\)</span> then generates <span class="math inline">\(y_t\)</span>.</p>
<p>Since it is not possible to directly code the drift <span class="math inline">\(\delta\)</span> into the <code>R-INLA</code> formula, we must <em>reparameterize</em> the model as follows. Let <span class="math inline">\(z_t\)</span> denote a random walk process without drift, derived from the same Gaussian white noise <span class="math inline">\(w_t\)</span>. We can rewrite the random walk plus drift process <span class="math inline">\(x_t\)</span> in <a href="chapter3.html#eq:rw-delta-st">(3.13)</a> as</p>
<p><span class="math display" id="eq:rw-delta2">\[\begin{align}
x_t &amp;= \delta t + z_t,  \\
z_t - z_{t-1} &amp;= w_t, \tag{3.14}
\end{align}\]</span>
so that</p>
<p><span class="math display">\[\begin{align*}
x_t - x_{t-1} = \delta t + z_t - \delta (t-1) - z_{t-1}=\delta + (z_t - z_{t-1}) = \delta + w_t.
\end{align*}\]</span>
Substituting <span class="math inline">\(x_t\)</span> from <a href="chapter3.html#eq:rw-delta2">(3.14)</a> into the observation equation
<a href="chapter3.html#eq:rw-delta-obs">(3.12)</a>, we get the model</p>
<p><span class="math display" id="eq:rw-delta-alt-st" id="eq:rw-delta-alt-obs">\[\begin{align}
y_t &amp;= \delta t + z_t + v_t;~~ v_t \sim N(0, \sigma^2_v),  
\tag{3.15} \\
z_t &amp;=  z_{t-1} + w_t;~~ w_t \sim N(0, \sigma^2_w).
\tag{3.16}
\end{align}\]</span>
That is, we have re-written a DLM with a drift coefficient in the state equation (see <a href="chapter3.html#eq:rw-delta-st">(3.13)</a>)
as a DLM with a deterministic trend <span class="math inline">\(\delta t\)</span> in the observation equation
<a href="chapter3.html#eq:rw-delta-alt-obs">(3.15)</a>,
and a random walk without drift in the state equation
(see <a href="chapter3.html#eq:rw-delta-alt-st">(3.16)</a>).
This <em>reparametrization</em> of the DLM now enables us to formulate and fit the random walk with drift plus noise model in <code>R-INLA</code>.
To illustrate, we generate a time series from this model; see Figure <a href="chapter3.html#fig:rw1-drift-plot-ts">3.11</a>.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="chapter3.html#cb58-1" aria-hidden="true" tabindex="-1"></a>sim.rw1.drift <span class="ot">&lt;-</span></span>
<span id="cb58-2"><a href="chapter3.html#cb58-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">simulation.from.rw1</span>(</span>
<span id="cb58-3"><a href="chapter3.html#cb58-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">sample.size =</span> <span class="dv">500</span>,</span>
<span id="cb58-4"><a href="chapter3.html#cb58-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">burn.in =</span> <span class="dv">100</span>,</span>
<span id="cb58-5"><a href="chapter3.html#cb58-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">level =</span> <span class="dv">0</span>,</span>
<span id="cb58-6"><a href="chapter3.html#cb58-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">drift =</span> <span class="fl">0.1</span>,</span>
<span id="cb58-7"><a href="chapter3.html#cb58-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">V =</span> <span class="fl">0.5</span>,</span>
<span id="cb58-8"><a href="chapter3.html#cb58-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">W =</span> <span class="fl">0.05</span>,</span>
<span id="cb58-9"><a href="chapter3.html#cb58-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot.data =</span> <span class="cn">TRUE</span>,</span>
<span id="cb58-10"><a href="chapter3.html#cb58-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">seed =</span> <span class="dv">1</span></span>
<span id="cb58-11"><a href="chapter3.html#cb58-11" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb58-12"><a href="chapter3.html#cb58-12" aria-hidden="true" tabindex="-1"></a>sim.rw1.drift<span class="sc">$</span>sim.plot</span></code></pre></div>
<div class="figure"><span id="fig:rw1-drift-plot-ts"></span>
<img src="gitbook_version_files/figure-html/rw1-drift-plot-ts-1.png" alt="Simulated data from a random walk with drift plus noise model." width="672" />
<p class="caption">
FIGURE 3.11: Simulated data from a random walk with drift plus noise model.
</p>
</div>
<p>There are two ways to implement the modeling in <code>R-INLA</code>.</p>
<p><strong>Method 1.</strong> Let <em>id.delta</em> correspond to the non time-varying coefficient <span class="math inline">\(\delta\)</span>
in <a href="chapter3.html#eq:rw-delta-alt-obs">(3.15)</a>, taking values from <span class="math inline">\(1\)</span> to <span class="math inline">\(n\)</span>. Let
<em>id.w</em> be an <span class="math inline">\(n\)</span>-dimensional vector denoting the white noise <span class="math inline">\(w_t\)</span> which corresponds to <span class="math inline">\(z_t\)</span> (the random walk process without drift defined in <a href="chapter3.html#eq:rw-delta-alt-st">(3.16)</a>).
We assume the prior distribution of <span class="math inline">\(\delta\)</span> to be
<span class="math inline">\(N({\rm mean} = 0, {\rm precision} = 0.001)\)</span>, the default prior specification, which is a vague prior specification on <span class="math inline">\(\delta\)</span>. This can be accessed from <code>inla.set.control.fixed.default()[c("mean", "prec")]</code>. The priors for <span class="math inline">\(\theta_v = \log(1/\sigma^2_v)\)</span> and <span class="math inline">\(\theta_w = \log(1/\sigma^2_w)\)</span> have been described earlier.
Based on the time indexes <em>id.w</em> and <em>id.delta</em>, we create a data frame <em>rw1.drift.dat</em> with three columns containing the time series <span class="math inline">\(y_t\)</span> and the time indexes. The formula, model setup, and results are shown below.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="chapter3.html#cb59-1" aria-hidden="true" tabindex="-1"></a>y.rw1.drift <span class="ot">&lt;-</span> sim.rw1.drift<span class="sc">$</span>sim.data</span>
<span id="cb59-2"><a href="chapter3.html#cb59-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(y.rw1.drift)</span>
<span id="cb59-3"><a href="chapter3.html#cb59-3" aria-hidden="true" tabindex="-1"></a>id.w <span class="ot">&lt;-</span> id.delta <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>n</span>
<span id="cb59-4"><a href="chapter3.html#cb59-4" aria-hidden="true" tabindex="-1"></a>rw1.drift.dat <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(y.rw1.drift, id.w, id.delta)</span>
<span id="cb59-5"><a href="chapter3.html#cb59-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-6"><a href="chapter3.html#cb59-6" aria-hidden="true" tabindex="-1"></a>formula.rw1.drift<span class="fl">.1</span> <span class="ot">&lt;-</span></span>
<span id="cb59-7"><a href="chapter3.html#cb59-7" aria-hidden="true" tabindex="-1"></a>  y.rw1.drift <span class="sc">~</span> <span class="fu">f</span>(id.w, <span class="at">model =</span> <span class="st">&quot;rw1&quot;</span>, <span class="at">constr =</span> <span class="cn">FALSE</span>) <span class="sc">-</span> <span class="dv">1</span> <span class="sc">+</span> id.delta  </span>
<span id="cb59-8"><a href="chapter3.html#cb59-8" aria-hidden="true" tabindex="-1"></a>model.rw1.drift<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">inla</span>(</span>
<span id="cb59-9"><a href="chapter3.html#cb59-9" aria-hidden="true" tabindex="-1"></a>  formula.rw1.drift<span class="fl">.1</span>,</span>
<span id="cb59-10"><a href="chapter3.html#cb59-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb59-11"><a href="chapter3.html#cb59-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> rw1.drift.dat,</span>
<span id="cb59-12"><a href="chapter3.html#cb59-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">control.predictor =</span> <span class="fu">list</span>(<span class="at">compute =</span> <span class="cn">TRUE</span>)</span>
<span id="cb59-13"><a href="chapter3.html#cb59-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb59-14"><a href="chapter3.html#cb59-14" aria-hidden="true" tabindex="-1"></a><span class="co"># summary(model.rw1.drift.1)</span></span>
<span id="cb59-15"><a href="chapter3.html#cb59-15" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(model.rw1.drift<span class="fl">.1</span><span class="sc">$</span>summary.fixed[,<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>)])</span>
<span id="cb59-16"><a href="chapter3.html#cb59-16" aria-hidden="true" tabindex="-1"></a><span class="do">##   name     mean  sd   0.025q 0.5q  0.975q</span></span>
<span id="cb59-17"><a href="chapter3.html#cb59-17" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 id.delta 0.098 0.01 0.079  0.098 0.117</span></span>
<span id="cb59-18"><a href="chapter3.html#cb59-18" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(model.rw1.drift<span class="fl">.1</span><span class="sc">$</span>summary.hyperpar[,<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)])</span>
<span id="cb59-19"><a href="chapter3.html#cb59-19" aria-hidden="true" tabindex="-1"></a><span class="do">##   name                       mean   sd   </span></span>
<span id="cb59-20"><a href="chapter3.html#cb59-20" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 Precision for Gaussian obs  1.717 0.125</span></span>
<span id="cb59-21"><a href="chapter3.html#cb59-21" aria-hidden="true" tabindex="-1"></a><span class="do">## 2 Precision for id.w         23.676 5.893</span></span></code></pre></div>
<p>From the output, we see that the posterior mean of <span class="math inline">\(\delta\)</span> is 0.098 with a posterior standard deviation of 0.01; recall that the true value of <span class="math inline">\(\delta\)</span> is <span class="math inline">\(0.1\)</span>. The estimates of <span class="math inline">\(\sigma^2_v\)</span> and <span class="math inline">\(\sigma^2_w\)</span> are respectively 0.582 (true value is <span class="math inline">\(0.5\)</span>) and 0.042 (true value is <span class="math inline">\(0.05\)</span>). Note that if we wish to change the prior specification on <span class="math inline">\(\delta\)</span>, we can use <code>control.fixed</code> within <code>inla()</code> (although we do not show this here).</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="chapter3.html#cb60-1" aria-hidden="true" tabindex="-1"></a>prior.fixed <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="dv">0</span>, <span class="at">prec =</span> <span class="fl">0.1</span>)</span>
<span id="cb60-2"><a href="chapter3.html#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="fu">inla</span>(<span class="at">formula =</span> ,</span>
<span id="cb60-3"><a href="chapter3.html#cb60-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">data =</span> ,</span>
<span id="cb60-4"><a href="chapter3.html#cb60-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">control.fixed =</span> prior.fixed)</span></code></pre></div>
<p><strong>Method 2.</strong> This is an equivalent <code>R-INLA</code> approach for this model and uses a formulation with the <code>model = linear</code> option.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="chapter3.html#cb61-1" aria-hidden="true" tabindex="-1"></a>formula.rw1.drift<span class="fl">.2</span> <span class="ot">&lt;-</span></span>
<span id="cb61-2"><a href="chapter3.html#cb61-2" aria-hidden="true" tabindex="-1"></a>  y.rw1.drift <span class="sc">~</span> <span class="fu">f</span>(id.w, <span class="at">model =</span> <span class="st">&quot;rw1&quot;</span>, <span class="at">constr =</span> <span class="cn">FALSE</span>) <span class="sc">-</span> <span class="dv">1</span> <span class="sc">+</span> </span>
<span id="cb61-3"><a href="chapter3.html#cb61-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">f</span>(id.delta, <span class="at">model =</span> <span class="st">&quot;linear&quot;</span>, <span class="at">mean.linear =</span> <span class="dv">0</span>, <span class="at">prec.linear =</span> <span class="fl">0.001</span>)</span>
<span id="cb61-4"><a href="chapter3.html#cb61-4" aria-hidden="true" tabindex="-1"></a>model.rw1.drift<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">inla</span>(</span>
<span id="cb61-5"><a href="chapter3.html#cb61-5" aria-hidden="true" tabindex="-1"></a>  formula.rw1.drift<span class="fl">.2</span>,</span>
<span id="cb61-6"><a href="chapter3.html#cb61-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb61-7"><a href="chapter3.html#cb61-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> rw1.drift.dat,</span>
<span id="cb61-8"><a href="chapter3.html#cb61-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">control.predictor =</span> <span class="fu">list</span>(<span class="at">compute =</span> <span class="cn">TRUE</span>)</span>
<span id="cb61-9"><a href="chapter3.html#cb61-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb61-10"><a href="chapter3.html#cb61-10" aria-hidden="true" tabindex="-1"></a><span class="co"># summary(model.rw1.drift.2)</span></span>
<span id="cb61-11"><a href="chapter3.html#cb61-11" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(model.rw1.drift<span class="fl">.2</span><span class="sc">$</span>summary.fixed[,<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>)])</span>
<span id="cb61-12"><a href="chapter3.html#cb61-12" aria-hidden="true" tabindex="-1"></a><span class="do">##   name     mean  sd   0.025q 0.5q  0.975q</span></span>
<span id="cb61-13"><a href="chapter3.html#cb61-13" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 id.delta 0.098 0.01 0.079  0.098 0.117</span></span>
<span id="cb61-14"><a href="chapter3.html#cb61-14" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(model.rw1.drift<span class="fl">.2</span><span class="sc">$</span>summary.hyperpar[,<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)])</span>
<span id="cb61-15"><a href="chapter3.html#cb61-15" aria-hidden="true" tabindex="-1"></a><span class="do">##   name                       mean   sd   </span></span>
<span id="cb61-16"><a href="chapter3.html#cb61-16" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 Precision for Gaussian obs  1.717 0.125</span></span>
<span id="cb61-17"><a href="chapter3.html#cb61-17" aria-hidden="true" tabindex="-1"></a><span class="do">## 2 Precision for id.w         23.676 5.893</span></span></code></pre></div>
<p>Note that we get similar results from both methods, and we may use either code to fit and analyze this model.
Similar to what we have seen earlier, the following code is useful to recover and print posterior estimates of <span class="math inline">\(\sigma^2_v\)</span>, <span class="math inline">\(\sigma^2_w\)</span> and <span class="math inline">\(\delta\)</span> from the <code>inla()</code> output.</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="chapter3.html#cb62-1" aria-hidden="true" tabindex="-1"></a>sigma2.v.hat <span class="ot">&lt;-</span></span>
<span id="cb62-2"><a href="chapter3.html#cb62-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">inla.emarginal</span>(</span>
<span id="cb62-3"><a href="chapter3.html#cb62-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> <span class="cf">function</span>(x)</span>
<span id="cb62-4"><a href="chapter3.html#cb62-4" aria-hidden="true" tabindex="-1"></a>      <span class="fu">exp</span>(<span class="sc">-</span>x),</span>
<span id="cb62-5"><a href="chapter3.html#cb62-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">marginal =</span> model.rw1.drift<span class="fl">.1</span><span class="sc">$</span>internal.marginals.hyperpar<span class="sc">$</span></span>
<span id="cb62-6"><a href="chapter3.html#cb62-6" aria-hidden="true" tabindex="-1"></a>      <span class="st">`</span><span class="at">Log precision for the Gaussian observations</span><span class="st">`</span></span>
<span id="cb62-7"><a href="chapter3.html#cb62-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb62-8"><a href="chapter3.html#cb62-8" aria-hidden="true" tabindex="-1"></a>sigma2.w.hat <span class="ot">&lt;-</span></span>
<span id="cb62-9"><a href="chapter3.html#cb62-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">inla.emarginal</span>(</span>
<span id="cb62-10"><a href="chapter3.html#cb62-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> <span class="cf">function</span>(x)</span>
<span id="cb62-11"><a href="chapter3.html#cb62-11" aria-hidden="true" tabindex="-1"></a>      <span class="fu">exp</span>(<span class="sc">-</span>x),</span>
<span id="cb62-12"><a href="chapter3.html#cb62-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">marginal =</span> model.rw1.drift<span class="fl">.1</span><span class="sc">$</span>internal.marginals.hyperpar<span class="sc">$</span></span>
<span id="cb62-13"><a href="chapter3.html#cb62-13" aria-hidden="true" tabindex="-1"></a>      <span class="st">`</span><span class="at">Log precision for id.w</span><span class="st">`</span></span>
<span id="cb62-14"><a href="chapter3.html#cb62-14" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb62-15"><a href="chapter3.html#cb62-15" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">paste</span>(</span>
<span id="cb62-16"><a href="chapter3.html#cb62-16" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;Estimated observation noise variance, sigma2.v&quot;</span>,</span>
<span id="cb62-17"><a href="chapter3.html#cb62-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">round</span>(sigma2.v.hat, <span class="dv">2</span>),</span>
<span id="cb62-18"><a href="chapter3.html#cb62-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">sep =</span> <span class="st">&quot; = &quot;</span></span>
<span id="cb62-19"><a href="chapter3.html#cb62-19" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb62-20"><a href="chapter3.html#cb62-20" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb62-21"><a href="chapter3.html#cb62-21" aria-hidden="true" tabindex="-1"></a><span class="do">## Estimated observation noise variance, sigma2.v = 0.59</span></span>
<span id="cb62-22"><a href="chapter3.html#cb62-22" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">paste</span>(</span>
<span id="cb62-23"><a href="chapter3.html#cb62-23" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;Estimated state noise variance, sigma2.w&quot;</span>,</span>
<span id="cb62-24"><a href="chapter3.html#cb62-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">round</span>(sigma2.w.hat, <span class="dv">2</span>),</span>
<span id="cb62-25"><a href="chapter3.html#cb62-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">sep =</span> <span class="st">&quot; = &quot;</span></span>
<span id="cb62-26"><a href="chapter3.html#cb62-26" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb62-27"><a href="chapter3.html#cb62-27" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb62-28"><a href="chapter3.html#cb62-28" aria-hidden="true" tabindex="-1"></a><span class="do">## Estimated state noise variance, sigma2.w = 0.04</span></span>
<span id="cb62-29"><a href="chapter3.html#cb62-29" aria-hidden="true" tabindex="-1"></a>delta.hat <span class="ot">&lt;-</span> model.rw1.drift<span class="fl">.1</span><span class="sc">$</span>summary.fixed<span class="sc">$</span>mean</span>
<span id="cb62-30"><a href="chapter3.html#cb62-30" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">paste</span>(<span class="st">&quot;Estimated drift, delta&quot;</span>, <span class="fu">round</span>(delta.hat, <span class="dv">2</span>), <span class="at">sep =</span> <span class="st">&quot; = &quot;</span>), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb62-31"><a href="chapter3.html#cb62-31" aria-hidden="true" tabindex="-1"></a><span class="do">## Estimated drift, delta = 0.1</span></span></code></pre></div>
<p>Also, as we discussed earlier, we can pull out the posterior distributions of the hyperparameters using <code>inla.tmarginal()</code> and obtain HPD intervals using <code>inla.hpdmarginal()</code> (code not shown here).
We will revisit Method 2 in Chapter <a href="chapter5.html#chapter5">5</a>, further explaining the available options related to the term <em>linear</em> in the formula. We next describe an approach to use <code>R-INLA</code> for modeling a DLM with a <em>time-varying drift</em> in the state equation.</p>
</div>
<div id="ch3-rwtvdrift" class="section level2 hasAnchor" number="3.6">
<h2><span class="header-section-number">3.6</span> Second-order polynomial model<a href="chapter3.html#ch3-rwtvdrift" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Given an observed time series <span class="math inline">\(y_t,~t=1,\ldots,n\)</span>, consider the model with a random walk latent state <span class="math inline">\(x_t\)</span> with a random, time-varying drift <span class="math inline">\(\delta_{t-1}\)</span>:</p>
<p><span class="math display" id="eq:second-poly-3" id="eq:second-poly-2" id="eq:second-poly-1">\[\begin{align}
y_t&amp;= x_t + v_t,   \tag{3.17} \\
x_t &amp;= x_{t-1}+\delta_{t-1}+w_{t,1},    \tag{3.18}\\
\delta_{t} &amp;= \delta_{t-1} + w_{t,2}. \tag{3.19}
\end{align}\]</span>
This is usually called the second-order polynomial model.
Similar models have been discussed in
<span class="citation">Ruiz-Cárdenas, Krainski, and Rue (<a href="#ref-ruiz2012direct" role="doc-biblioref">2012</a>)</span>.
<!-- also see  http://faculty.chicagobooth.edu/hedibert.lopes. --></p>
<p>Let <span class="math inline">\({\boldsymbol x}^\ast_t = (x_t, \delta_t)&#39;\)</span> be the <span class="math inline">\(2\)</span>-dimensional state vector with
<span class="math inline">\(x^\ast_{t,1} =x_t\)</span> and <span class="math inline">\(x^\ast_{t,2}=\delta_t\)</span>. For <span class="math inline">\(t=2,\ldots,n\)</span>,
we can write <a href="chapter3.html#eq:second-poly-2">(3.18)</a> and <a href="chapter3.html#eq:second-poly-3">(3.19)</a> as</p>
<p><span class="math display" id="eq:second-poly-state">\[\begin{align}
{\boldsymbol x}^\ast_t &amp;= \begin{pmatrix} 1  &amp; 1 \\0 &amp; 1  \end{pmatrix} {\boldsymbol x}^\ast_{t-1} + {\boldsymbol w}^\ast_t \notag \\
&amp;= \boldsymbol{\Phi} {\boldsymbol x}^\ast_{t-1}  + {\boldsymbol w}^\ast_t, \text{ say},
\tag{3.20}
\end{align}\]</span>
where
<span class="math inline">\(\boldsymbol{\Phi} = \begin{pmatrix} 1 &amp; 1 \\0 &amp; 1 \end{pmatrix}\)</span> is a <span class="math inline">\(2 \times 2\)</span> state transition matrix. We assume that
<span class="math inline">\({\boldsymbol w}^\ast_t \sim N({\boldsymbol 0},{\boldsymbol W})\)</span>, where
<span class="math inline">\({\boldsymbol W} =\text{diag}(\sigma^2_{w1},\sigma^2_{w2})\)</span>.
The observation equation in the model is a linear function of the bivariate state vector <span class="math inline">\({\boldsymbol x}^\ast_t\)</span> plus an observation noise <span class="math inline">\(v_t\)</span>:</p>
<p><span class="math display" id="eq:second-poly-obs">\[\begin{align}
y_t = (1, \ 0) {\boldsymbol x}^\ast_t + v_t, \ t=1,\ldots,n,  
\tag{3.21}
\end{align}\]</span>
where <span class="math inline">\(v_t \sim N(0, V)\)</span>.</p>
<p>Following <span class="citation">Ruiz-Cárdenas, Krainski, and Rue (<a href="#ref-ruiz2012direct" role="doc-biblioref">2012</a>)</span>, we can express <a href="chapter3.html#eq:second-poly-state">(3.20)</a> as</p>
<p><span class="math display" id="eq:rw-faked-zero">\[\begin{align}
{\boldsymbol 0} = {\boldsymbol x}^\ast_t - \boldsymbol{\Phi} {\boldsymbol x}^\ast_{t-1} - {\boldsymbol w}^\ast_t, \ t=2,\ldots,n,
\tag{3.22}
\end{align}\]</span>
yielding a set of <span class="math inline">\(n-1\)</span> <em>faked zero observations</em>
on the left side written as a linear function of the terms on the right side. That is,
we rewrite the state equations <a href="chapter3.html#eq:second-poly-2">(3.18)</a> and <a href="chapter3.html#eq:second-poly-3">(3.19)</a> as</p>
<p><span class="math display" id="eq:second-poly-3-rew" id="eq:second-poly-2-rew">\[\begin{align}
0 &amp;= x_t - x_{t-1} -\delta_{t-1} - w_{t,1},  \tag{3.23}\\
0 &amp;= \delta_{t} - \delta_{t-1} - w_{t,2}. \tag{3.24}
\end{align}\]</span></p>
<p>Then, the augmented model has dimension <span class="math inline">\(n+ 2(n-1)\)</span>, the <span class="math inline">\(n\)</span> observations <span class="math inline">\(y_1,\ldots,y_n\)</span> being stacked together with the set of <span class="math inline">\(n-1\)</span> faked zero observations in <a href="chapter3.html#eq:rw-faked-zero">(3.22)</a>:</p>
<p><span class="math display" id="eq:rw-augment-mat">\[\begin{align}
\begin{pmatrix}
y_1 &amp; NA &amp; NA \\
\vdots &amp; \vdots &amp; \vdots \\
y_n &amp; NA &amp; NA \\
\hline \\
NA &amp; 0 &amp; NA \\
\vdots &amp; \vdots &amp; \vdots \\
NA &amp; 0 &amp; NA \\
\hline \\
NA &amp; NA &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots \\
NA &amp; NA &amp; 0
\end{pmatrix},
\tag{3.25}
\end{align}\]</span>
where each of the second and third horizontal blocks has dimension <span class="math inline">\((n-1) \times 3\)</span>.
The first <span class="math inline">\(n\)</span> rows of Column 1 contain the observations, <span class="math inline">\(y_1,\ldots,y_n\)</span>.
Column 2 is associated with the first state variable
<span class="math inline">\(x^\ast_{t,1}=x_t\)</span> whose entries are forced to zero for <span class="math inline">\(t=2,\ldots,n\)</span> (see <a href="chapter3.html#eq:rw-faked-zero">(3.22)</a>).
Column 3 is associated with the second state variable <span class="math inline">\(x^\ast_{t,2}=\delta_t\)</span> for <span class="math inline">\(t=2,\ldots,n\)</span>.
All the other entries in the structure have no values and are assigned NAs.
In summary, this augmented structure in <a href="chapter3.html#eq:rw-augment-mat">(3.25)</a> will have the observed <span class="math inline">\(y_t\)</span> in the first <span class="math inline">\(n\)</span> rows of Column 1, and there will be as many additional columns as the number of state variables in the state equation (here, <span class="math inline">\(2\)</span>).</p>
<p>For fitting the model, <code>R-INLA</code> considers different likelihoods for Column 1 and the other columns of the augmented structure in <a href="chapter3.html#eq:rw-augment-mat">(3.25)</a>.
As described in <span class="citation">Ruiz-Cárdenas, Krainski, and Rue (<a href="#ref-ruiz2012direct" role="doc-biblioref">2012</a>)</span>, given the state vector <span class="math inline">\({\boldsymbol x}^\ast_t\)</span>, the data <span class="math inline">\(y_t,~t=1,\ldots,n\)</span> are assumed to follow a Gaussian distribution with unknown precision <span class="math inline">\(V^{-1}\)</span>.
Given <span class="math inline">\({\boldsymbol x}^\ast_t, {\boldsymbol x}^\ast_{t-1}\)</span> and <span class="math inline">\({\boldsymbol w}^\ast_t\)</span>, the faked zero data in Columns 2 and 3 of <a href="chapter3.html#eq:rw-augment-mat">(3.25)</a> are artificial observations and are assumed to be deterministic (i.e., known, with zero variance).
<code>R-INLA</code> represents this condition by assuming that these faked zero data follow a Gaussian distribution with a high, fixed precision.
It is assumed that for <span class="math inline">\(t = 1\)</span>, <span class="math inline">\({\boldsymbol x}^\ast_1\)</span> follows a noninformative distribution, i.e., a bivariate normal distribution with a fixed and low-valued precision matrix.
For <span class="math inline">\(t = 2,\ldots,n\)</span>, it is assumed that <span class="math inline">\({\boldsymbol x}^\ast_t\)</span> follows
<a href="chapter3.html#eq:second-poly-state">(3.20)</a> and
<span class="math inline">\({\boldsymbol w}^\ast_t \sim N({\boldsymbol 0},{\boldsymbol W})\)</span>:</p>
<p><span class="math display">\[\begin{align*}
f_{{\boldsymbol w}^\ast_t}({\boldsymbol x}^\ast_t - \boldsymbol{\Phi}{\boldsymbol x}^\ast_{t-1}) \propto
\exp[-\frac{1}{2} ({\boldsymbol x}^\ast_t - \boldsymbol{\Phi}{\boldsymbol x}^\ast_{t-1})&#39;{\boldsymbol W}^{-1}({\boldsymbol x}^\ast_t - \boldsymbol{\Phi}{\boldsymbol x}^\ast_{t-1})].
\end{align*}\]</span>
We must define the
<span class="math inline">\(n \times 2\)</span> matrix
<span class="math inline">\({\boldsymbol X}^\ast =({\boldsymbol x}^\ast_1, \ldots,{\boldsymbol x}^\ast_n)&#39;\)</span>, and also define
<span class="math inline">\({\boldsymbol X}^\ast_{(-1)} =({\boldsymbol x}^\ast_2, \ldots,{\boldsymbol x}^\ast_n)&#39;\)</span> and
<span class="math inline">\({\boldsymbol X}^\ast_{(-n)} =({\boldsymbol x}^\ast_1, \ldots,{\boldsymbol x}^\ast_{n-1})&#39;\)</span>.</p>
<p>The following code simulates a time series <span class="math inline">\(y_t\)</span>, see Figure <a href="chapter3.html#fig:second-order-plot">3.12</a>, of length <span class="math inline">\(n=200\)</span>. The true values of the error variances are assumed to be <span class="math inline">\(V = 0.01\)</span>, and <span class="math inline">\({\boldsymbol W} = \text{diag}(0.0001, 0.0001)\)</span>.</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="chapter3.html#cb63-1" aria-hidden="true" tabindex="-1"></a>sim.secondorder <span class="ot">&lt;-</span></span>
<span id="cb63-2"><a href="chapter3.html#cb63-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">simulation.from.second.order.dlm</span>(</span>
<span id="cb63-3"><a href="chapter3.html#cb63-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">sample.size =</span> <span class="dv">200</span>,</span>
<span id="cb63-4"><a href="chapter3.html#cb63-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">V =</span> <span class="fl">0.01</span>,</span>
<span id="cb63-5"><a href="chapter3.html#cb63-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">W1 =</span> <span class="fl">1e-04</span>,</span>
<span id="cb63-6"><a href="chapter3.html#cb63-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">W2 =</span> <span class="fl">1e-04</span>,</span>
<span id="cb63-7"><a href="chapter3.html#cb63-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot.data =</span> <span class="cn">TRUE</span>,</span>
<span id="cb63-8"><a href="chapter3.html#cb63-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">seed =</span> <span class="dv">123457</span></span>
<span id="cb63-9"><a href="chapter3.html#cb63-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb63-10"><a href="chapter3.html#cb63-10" aria-hidden="true" tabindex="-1"></a>sim.secondorder<span class="sc">$</span>sim.plot</span></code></pre></div>
<div class="figure"><span id="fig:second-order-plot"></span>
<img src="gitbook_version_files/figure-html/second-order-plot-1.png" alt="Simulated data from a second-order polynomial model." width="672" />
<p class="caption">
FIGURE 3.12: Simulated data from a second-order polynomial model.
</p>
</div>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="chapter3.html#cb64-1" aria-hidden="true" tabindex="-1"></a>y.sec <span class="ot">&lt;-</span> sim.secondorder<span class="sc">$</span>sim.data</span>
<span id="cb64-2"><a href="chapter3.html#cb64-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(y.sec)</span></code></pre></div>
<p>The following code sets up the augmented model. Let <span class="math inline">\(m = n-1\)</span>. The observed time series <span class="math inline">\(y_t\)</span> forms the first block of rows.</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="chapter3.html#cb65-1" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> n<span class="dv">-1</span></span>
<span id="cb65-2"><a href="chapter3.html#cb65-2" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, n<span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>m, <span class="dv">3</span>)</span>
<span id="cb65-3"><a href="chapter3.html#cb65-3" aria-hidden="true" tabindex="-1"></a><span class="co"># actual observations (y.sec)</span></span>
<span id="cb65-4"><a href="chapter3.html#cb65-4" aria-hidden="true" tabindex="-1"></a>Y[<span class="dv">1</span><span class="sc">:</span>n, <span class="dv">1</span>] <span class="ot">&lt;-</span> y.sec </span>
<span id="cb65-5"><a href="chapter3.html#cb65-5" aria-hidden="true" tabindex="-1"></a>Y[<span class="dv">1</span><span class="sc">:</span>m <span class="sc">+</span> n, <span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="dv">0</span>  </span>
<span id="cb65-6"><a href="chapter3.html#cb65-6" aria-hidden="true" tabindex="-1"></a>Y[<span class="dv">1</span><span class="sc">:</span>m <span class="sc">+</span> (n<span class="sc">+</span>m), <span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="dv">0</span>  </span></code></pre></div>
<p>The set up of the vectors of indexes and vectors of weights (coefficients) for the different latent variables follows the discussion in <span class="citation">Ruiz-Cárdenas, Krainski, and Rue (<a href="#ref-ruiz2012direct" role="doc-biblioref">2012</a>)</span> (also see their Appendix).
In order to avoid confusion with the state errors <span class="math inline">\(w_t\)</span>, we use the symbols <span class="math inline">\(\boldsymbol{ci}, \boldsymbol{cj}\)</span>, etc., instead of <span class="math inline">\(\boldsymbol{wi}, \boldsymbol{wj}\)</span>, etc., to denote the weights (coefficients).
We give a description of these items for this model.</p>
<ol style="list-style-type: decimal">
<li><p>The vector of indexes denoted by <span class="math inline">\({\boldsymbol i}\)</span> for the latent series
<span class="math inline">\(x^\ast_{t,1} =x_t\)</span> consists of (a) a vector <span class="math inline">\(c(1:n)\)</span> of length <span class="math inline">\(n\)</span> (from the observation equation), (b) a vector <span class="math inline">\(c(2:n)\)</span> of length <span class="math inline">\(m\)</span> (from the rewritten first state equation <a href="chapter3.html#eq:second-poly-2-rew">(3.23)</a> for <span class="math inline">\(x^\ast_{t,1}=x_t\)</span> with fake zeroes),
and (c) a vector of NA’s of length <span class="math inline">\(m\)</span> (from the rewritten second state equation
<a href="chapter3.html#eq:second-poly-3-rew">(3.24)</a> for <span class="math inline">\(x^\ast_{t,2}=\delta_t\)</span> with fake zeroes).</p></li>
<li><p>The vector of indexes <span class="math inline">\({\boldsymbol j}\)</span> for the latent series <span class="math inline">\(x^\ast_{t-1,1}=x_{t-1}\)</span> consists of (a) a vector of NA’s of length <span class="math inline">\(n\)</span> (since the observation equation has no <span class="math inline">\(x_{t-1}\)</span>), (b) a vector <span class="math inline">\(c(1:m)\)</span> of length <span class="math inline">\(m\)</span> (from the rewritten state equation <a href="chapter3.html#eq:second-poly-2-rew">(3.23)</a>), and (c) a vector of NA’s of length <span class="math inline">\(m\)</span> (since the rewritten second state equation <a href="chapter3.html#eq:second-poly-3-rew">(3.24)</a> has no <span class="math inline">\(x_{t-1}\)</span>).</p></li>
<li><p>The vector <span class="math inline">\(\boldsymbol{cj}\)</span> consists of the coefficients corresponding to the vector <span class="math inline">\(\boldsymbol{j}\)</span> and has (a) a vector of NA’s of length <span class="math inline">\(n\)</span> (since the observation equation has no <span class="math inline">\(x_{t-1}\)</span>), (b) a vector of length <span class="math inline">\(m\)</span> with elements <span class="math inline">\(-1\)</span> (corresponding to the coefficient of <span class="math inline">\(x_{t-1}\)</span> in <a href="chapter3.html#eq:second-poly-2-rew">(3.23)</a>), and (c) a vector of NA’s of length <span class="math inline">\(m\)</span> (since the second state equation has no <span class="math inline">\(x_{t-1}\)</span>).</p></li>
<li><p>The vector of indexes <span class="math inline">\(\boldsymbol{l}\)</span> for the latent series <span class="math inline">\(x^\ast_{t,2}=\delta_t\)</span> consists of (a) a vector of NA’s of length <span class="math inline">\(n\)</span> (since the observation equation has no <span class="math inline">\(\delta_{t}\)</span>), (b) a vector of NA’s of length <span class="math inline">\(m\)</span> (since the first state equation has no <span class="math inline">\(\delta_{t}\)</span>), and (c) a vector <span class="math inline">\(c(2:n)\)</span> of length <!--$n$-->
<span class="math inline">\(m\)</span> (corresponding to the coefficient of <span class="math inline">\(\delta_{t}\)</span> in the rewritten second state equation).</p></li>
<li><p>The vector <span class="math inline">\(\boldsymbol{cl}\)</span> consists of coefficients corresponding to the vector <span class="math inline">\(\boldsymbol{l}\)</span> and has (a) a vector of NA’s of length <span class="math inline">\(n\)</span> (since the observation equation has no <span class="math inline">\(\delta_{t}\)</span>), (b) a vector of NA’s of length <span class="math inline">\(m-1\)</span> (since the first rewritten state equation <a href="chapter3.html#eq:second-poly-2-rew">(3.23)</a> has no <span class="math inline">\(\delta_{t}\)</span>),
and (c) a vector of length <span class="math inline">\(m\)</span> with elements 1 (corresponding to the coefficient of <span class="math inline">\(\delta_t\)</span> in <a href="chapter3.html#eq:second-poly-3-rew">(3.24)</a>).</p></li>
<li><p>The vector of indexes <span class="math inline">\(\boldsymbol{k}\)</span> for the latent series <span class="math inline">\(x^\ast_{t-1,2}=\delta_{t-1}\)</span> consists of (a) a vector of NA’s of length <span class="math inline">\(n\)</span> (since the observation equation has no <span class="math inline">\(\delta_{t-1}\)</span>), (b) a vector <span class="math inline">\(c(1:m)\)</span> of length <span class="math inline">\(m\)</span> (from the rewritten state equation <a href="chapter3.html#eq:second-poly-2-rew">(3.23)</a>),
and (c) a vector <span class="math inline">\(c(1:m)\)</span> of length <span class="math inline">\(m\)</span> (from the rewritten state equation <a href="chapter3.html#eq:second-poly-2-rew">(3.23)</a>).</p></li>
<li><p>The vector <span class="math inline">\(\boldsymbol{ck}\)</span> consists of coefficients corresponding to the vector of indexes <span class="math inline">\(\boldsymbol{k}\)</span> and has (a) a vector of NA’s of length <span class="math inline">\(n\)</span> (since the observation equation has no <span class="math inline">\(\delta_{t-1}\)</span>), (b) a vector of length <span class="math inline">\(m\)</span> with elements <span class="math inline">\(-1\)</span> (corresponding to the coefficient of <span class="math inline">\(\delta_{t-1}\)</span> in <a href="chapter3.html#eq:second-poly-2-rew">(3.23)</a>), and (c) a vector of length <span class="math inline">\(m\)</span> with elements <span class="math inline">\(-1\)</span> (corresponding to the coefficient of <span class="math inline">\(\delta_{t-1}\)</span> in <a href="chapter3.html#eq:second-poly-3-rew">(3.24)</a>).</p></li>
<li><p>The vector <span class="math inline">\(\boldsymbol{q}\)</span> consists of indexes for the state errors (perturbations) <span class="math inline">\(w_{t,1}\)</span> in <a href="chapter3.html#eq:second-poly-2-rew">(3.23)</a> and has NA’s in all entries except for the <span class="math inline">\(m\)</span> middle entries corresponding to <a href="chapter3.html#eq:second-poly-2-rew">(3.23)</a>.</p></li>
<li><p>The vector <span class="math inline">\(\boldsymbol{cq}\)</span> correspondingly has <span class="math inline">\(-1\)</span> in the middle <span class="math inline">\(m\)</span> positions and NA’s otherwise.</p></li>
<li><p>The vector <span class="math inline">\(\boldsymbol{s}\)</span> consists of indexes for the state errors (perturbations) <span class="math inline">\(w_{t,2}\)</span> in <a href="chapter3.html#eq:second-poly-3-rew">(3.24)</a> and has NA’s in all entries except for the last <span class="math inline">\(m\)</span> entries corresponding to <a href="chapter3.html#eq:second-poly-3-rew">(3.24)</a>.</p></li>
<li><p>The vector <span class="math inline">\(\boldsymbol{cs}\)</span> correspondingly has <span class="math inline">\(-1\)</span> in the last <span class="math inline">\(m\)</span> positions and NA’s otherwise.</p></li>
</ol>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="chapter3.html#cb66-1" aria-hidden="true" tabindex="-1"></a>i <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="dv">2</span><span class="sc">:</span>n, <span class="fu">rep</span>(<span class="cn">NA</span>, m))              <span class="co"># indexes for x_t</span></span>
<span id="cb66-2"><a href="chapter3.html#cb66-2" aria-hidden="true" tabindex="-1"></a>j <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="cn">NA</span>, n), <span class="dv">2</span><span class="sc">:</span>n <span class="sc">-</span> <span class="dv">1</span>, <span class="fu">rep</span>(<span class="cn">NA</span>, m))     <span class="co"># indexes for x_{t-1}</span></span>
<span id="cb66-3"><a href="chapter3.html#cb66-3" aria-hidden="true" tabindex="-1"></a>cj <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="cn">NA</span>, n), <span class="fu">rep</span>(<span class="sc">-</span><span class="dv">1</span>, m), <span class="fu">rep</span>(<span class="cn">NA</span>, m)) <span class="co"># weights for x_{t-1}</span></span>
<span id="cb66-4"><a href="chapter3.html#cb66-4" aria-hidden="true" tabindex="-1"></a>l <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="cn">NA</span>, n <span class="sc">+</span> n <span class="sc">-</span> <span class="dv">1</span>), <span class="dv">2</span><span class="sc">:</span>n)         <span class="co"># indexes for delta_t</span></span>
<span id="cb66-5"><a href="chapter3.html#cb66-5" aria-hidden="true" tabindex="-1"></a>cl <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="cn">NA</span>, n <span class="sc">+</span> m), <span class="fu">rep</span>(<span class="dv">1</span>, m))      <span class="co"># weights for delta_t</span></span>
<span id="cb66-6"><a href="chapter3.html#cb66-6" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="cn">NA</span>, n), <span class="dv">2</span><span class="sc">:</span>n <span class="sc">-</span> <span class="dv">1</span>, <span class="dv">2</span><span class="sc">:</span>n <span class="sc">-</span> <span class="dv">1</span>)  <span class="co"># indexes for delta_{t-1}</span></span>
<span id="cb66-7"><a href="chapter3.html#cb66-7" aria-hidden="true" tabindex="-1"></a>ck <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="cn">NA</span>, n), <span class="fu">rep</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">2</span> <span class="sc">*</span> m))     <span class="co"># weights for delta_{t-1}</span></span>
<span id="cb66-8"><a href="chapter3.html#cb66-8" aria-hidden="true" tabindex="-1"></a>q <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="cn">NA</span>, n), <span class="dv">1</span><span class="sc">:</span>m, <span class="fu">rep</span>(<span class="cn">NA</span>, m))  <span class="co"># indexes for w_{t,1}</span></span>
<span id="cb66-9"><a href="chapter3.html#cb66-9" aria-hidden="true" tabindex="-1"></a>s <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="cn">NA</span>, n <span class="sc">+</span> m), <span class="dv">1</span><span class="sc">:</span>m)           <span class="co"># indexes for  w_{t,2}</span></span>
<span id="cb66-10"><a href="chapter3.html#cb66-10" aria-hidden="true" tabindex="-1"></a>cq <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="cn">NA</span>, n), <span class="fu">rep</span>(<span class="sc">-</span><span class="dv">1</span>, m), <span class="fu">rep</span>(<span class="cn">NA</span>, m)) <span class="co"># weights for w_{t,1}</span></span>
<span id="cb66-11"><a href="chapter3.html#cb66-11" aria-hidden="true" tabindex="-1"></a>cs <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="cn">NA</span>, n <span class="sc">+</span> m), <span class="fu">rep</span>(<span class="sc">-</span><span class="dv">1</span>, m))          <span class="co"># weights for w_{t,2}</span></span></code></pre></div>
<p>The model formulation is shown below. The first term handles the first state variable <span class="math inline">\(x_t\)</span> (with index vector <span class="math inline">\({\boldsymbol i}\)</span>) while the second term handles the state variable <span class="math inline">\(x_{t-1}\)</span> (with index vector <span class="math inline">\({\boldsymbol j}\)</span>).
Since both have the same distribution, we may use <code>f(j, wj, copy="i")</code>.
A similar usage follows for index vectors <span class="math inline">\(\boldsymbol l\)</span> and <span class="math inline">\(\boldsymbol k\)</span> for the second state variables <span class="math inline">\(\delta_t\)</span> and <span class="math inline">\(\delta_{t-1}\)</span>.
The <code>R-INLA</code> feature <code>copy</code> enables us to share terms among different parts of the model and is explained below (also see Section 6.5 of <span class="citation">Gómez-Rubio (<a href="#ref-gomez2020bayesian" role="doc-biblioref">2020</a>)</span>).</p>
<p><strong><code>R-INLA</code> feature <code>copy</code></strong></p>
<p>Using the <code>copy</code> feature when defining different likelihoods associated with different latent random variables allows us to ensure that linear predictors of the different likelihoods share the same type of latent effect, with the values of the random effects being the same, while copied effects can be scaled by a parameter. All copies of the random effects share the same hyperparameters.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="chapter3.html#cb67-1" aria-hidden="true" tabindex="-1"></a>formula.second.poly <span class="ot">=</span> Y <span class="sc">~</span> <span class="fu">f</span>(i, <span class="at">model=</span><span class="st">&quot;iid&quot;</span>, <span class="at">initial=</span><span class="sc">-</span><span class="dv">10</span>, <span class="at">fixed=</span><span class="cn">TRUE</span>) <span class="sc">+</span></span>
<span id="cb67-2"><a href="chapter3.html#cb67-2" aria-hidden="true" tabindex="-1"></a>              <span class="fu">f</span>(j, cj, <span class="at">copy=</span><span class="st">&quot;i&quot;</span>) <span class="sc">+</span> </span>
<span id="cb67-3"><a href="chapter3.html#cb67-3" aria-hidden="true" tabindex="-1"></a>            <span class="fu">f</span>(l, cl, <span class="at">model=</span><span class="st">&quot;iid&quot;</span>, <span class="at">values =</span> <span class="dv">1</span><span class="sc">:</span>n, <span class="at">initial=</span><span class="sc">-</span><span class="dv">10</span>, <span class="at">fixed=</span><span class="cn">TRUE</span>)<span class="sc">+</span></span>
<span id="cb67-4"><a href="chapter3.html#cb67-4" aria-hidden="true" tabindex="-1"></a>              <span class="fu">f</span>(k, ck, <span class="at">copy=</span><span class="st">&quot;l&quot;</span>)<span class="sc">+</span></span>
<span id="cb67-5"><a href="chapter3.html#cb67-5" aria-hidden="true" tabindex="-1"></a>              <span class="fu">f</span>(q, cq, <span class="at">model =</span><span class="st">&quot;iid&quot;</span>) <span class="sc">+</span> </span>
<span id="cb67-6"><a href="chapter3.html#cb67-6" aria-hidden="true" tabindex="-1"></a>              <span class="fu">f</span>(s, cs, <span class="at">model =</span><span class="st">&quot;iid&quot;</span>) <span class="sc">-</span><span class="dv">1</span></span></code></pre></div>
<p>Here, <span class="math inline">\(\boldsymbol i\)</span> is the index variable used in the original effect, i.e., <span class="math inline">\(x_t\)</span>, and <span class="math inline">\(\boldsymbol j\)</span> is the index corresponding to <span class="math inline">\(x_{t-1}\)</span> which must take values in the same set as <span class="math inline">\(\boldsymbol i\)</span>. In general, the new index <span class="math inline">\(\boldsymbol j\)</span> need not have the same ordering as <span class="math inline">\(\boldsymbol i\)</span>, and only the elements of <span class="math inline">\(x_t\)</span> that are indexed in <span class="math inline">\(\boldsymbol j\)</span> will be copied (as pointed out in <span class="citation">Gómez-Rubio (<a href="#ref-gomez2020bayesian" role="doc-biblioref">2020</a>)</span>).</p>
<p>The argument <code>values</code> in the function <code>f()</code>is used to provide the set of all values assumed by the covariate for which we want the estimated effect. By default, <code>values</code> assumes the unique set of values defined in the index; for example, for index <span class="math inline">\(\boldsymbol l\)</span>, the set is <span class="math inline">\(\{2,\ldots,n\}\)</span>. In the model formula for the index <span class="math inline">\(\boldsymbol k\)</span>, we have <span class="math inline">\(copy =``\text{l}&quot;\)</span>; the argument <code>copy</code> enables the index <span class="math inline">\(\boldsymbol k\)</span> to inherit values of the argument <code>values</code> defined for index <span class="math inline">\(\boldsymbol l\)</span>. However, note that <code>values</code> for <span class="math inline">\(f(k, ck, copy= ``\text{l}&quot;)\)</span> is the set <span class="math inline">\(\{1,\ldots,n-1\}\)</span>. Therefore, for <code>inla()</code> to run without error, it is necessary to inform the model that <span class="math inline">\(\boldsymbol l\)</span> is being <em>copied</em>, for which we must include <code>values = 1:n</code> in the function <code>f()</code> defined for <span class="math inline">\(\boldsymbol l\)</span>.</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="chapter3.html#cb68-1" aria-hidden="true" tabindex="-1"></a>model.second.poly <span class="ot">=</span> <span class="fu">inla</span>(</span>
<span id="cb68-2"><a href="chapter3.html#cb68-2" aria-hidden="true" tabindex="-1"></a>  formula.second.poly,</span>
<span id="cb68-3"><a href="chapter3.html#cb68-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> <span class="fu">data.frame</span>(i, j, cj, k, ck, l, q, s, cq, cs),</span>
<span id="cb68-4"><a href="chapter3.html#cb68-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">rep</span>(<span class="st">&quot;gaussian&quot;</span>, <span class="dv">3</span>),</span>
<span id="cb68-5"><a href="chapter3.html#cb68-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">control.family =</span> <span class="fu">list</span>(</span>
<span id="cb68-6"><a href="chapter3.html#cb68-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">list</span>(),</span>
<span id="cb68-7"><a href="chapter3.html#cb68-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">list</span>(<span class="at">initial =</span> <span class="dv">10</span>, <span class="at">fixed =</span> <span class="cn">TRUE</span>),</span>
<span id="cb68-8"><a href="chapter3.html#cb68-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">list</span>(<span class="at">initial =</span> <span class="dv">10</span>, <span class="at">fixed =</span> <span class="cn">TRUE</span>)</span>
<span id="cb68-9"><a href="chapter3.html#cb68-9" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb68-10"><a href="chapter3.html#cb68-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">control.predictor =</span> <span class="fu">list</span>(<span class="at">compute =</span> <span class="cn">TRUE</span>)</span>
<span id="cb68-11"><a href="chapter3.html#cb68-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb68-12"><a href="chapter3.html#cb68-12" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(model.second.poly<span class="sc">$</span>summary.hyperpar[,<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)])</span>
<span id="cb68-13"><a href="chapter3.html#cb68-13" aria-hidden="true" tabindex="-1"></a><span class="do">##   name                       mean  sd      </span></span>
<span id="cb68-14"><a href="chapter3.html#cb68-14" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 Precision for Gaussian obs   105    11.25</span></span>
<span id="cb68-15"><a href="chapter3.html#cb68-15" aria-hidden="true" tabindex="-1"></a><span class="do">## 2 Precision for q            20081 16381.84</span></span>
<span id="cb68-16"><a href="chapter3.html#cb68-16" aria-hidden="true" tabindex="-1"></a><span class="do">## 3 Precision for s            51361 26504.35</span></span></code></pre></div>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="chapter3.html#cb69-1" aria-hidden="true" tabindex="-1"></a>post.mean.V <span class="ot">&lt;-</span> <span class="fu">inla.emarginal</span>(</span>
<span id="cb69-2"><a href="chapter3.html#cb69-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">fun =</span> <span class="cf">function</span>(x)</span>
<span id="cb69-3"><a href="chapter3.html#cb69-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">exp</span>(<span class="sc">-</span>x),</span>
<span id="cb69-4"><a href="chapter3.html#cb69-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">marginal =</span> model.second.poly<span class="sc">$</span>internal.marginals.hyperpar<span class="sc">$</span></span>
<span id="cb69-5"><a href="chapter3.html#cb69-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">`</span><span class="at">Log precision for the Gaussian observations</span><span class="st">`</span></span>
<span id="cb69-6"><a href="chapter3.html#cb69-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb69-7"><a href="chapter3.html#cb69-7" aria-hidden="true" tabindex="-1"></a>post.mean.W11 <span class="ot">&lt;-</span> <span class="fu">inla.emarginal</span>(</span>
<span id="cb69-8"><a href="chapter3.html#cb69-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">fun =</span> <span class="cf">function</span>(x)</span>
<span id="cb69-9"><a href="chapter3.html#cb69-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">exp</span>(<span class="sc">-</span>x),</span>
<span id="cb69-10"><a href="chapter3.html#cb69-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">marginal =</span> model.second.poly<span class="sc">$</span>internal.marginals.hyperpar<span class="sc">$</span></span>
<span id="cb69-11"><a href="chapter3.html#cb69-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">`</span><span class="at">Log precision for s</span><span class="st">`</span></span>
<span id="cb69-12"><a href="chapter3.html#cb69-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb69-13"><a href="chapter3.html#cb69-13" aria-hidden="true" tabindex="-1"></a>post.mean.W22 <span class="ot">&lt;-</span> <span class="fu">inla.emarginal</span>(</span>
<span id="cb69-14"><a href="chapter3.html#cb69-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">fun =</span> <span class="cf">function</span>(x)</span>
<span id="cb69-15"><a href="chapter3.html#cb69-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">exp</span>(<span class="sc">-</span>x),</span>
<span id="cb69-16"><a href="chapter3.html#cb69-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">marginal =</span> model.second.poly<span class="sc">$</span>internal.marginals.hyperpar<span class="sc">$</span></span>
<span id="cb69-17"><a href="chapter3.html#cb69-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">`</span><span class="at">Log precision for q</span><span class="st">`</span></span>
<span id="cb69-18"><a href="chapter3.html#cb69-18" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>The posterior mean of <span class="math inline">\(V\)</span> is 0.0096. The posterior means of <span class="math inline">\(\sigma^2_{w1}\)</span> and <span class="math inline">\(\sigma^2_{w2}\)</span> are 0.000025 and 0.00009833 respectively, and are not recovered as accurately as the mean of <span class="math inline">\(V\)</span>.</p>
</div>
<div id="forecasting" class="section level2 hasAnchor" number="3.7">
<h2><span class="header-section-number">3.7</span> Forecasting states and observations<a href="chapter3.html#forecasting" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>An important goal in time series analysis is to forecast future values of a time series based on a fitted model.
Suppose we split the observed data into a fitting or training portion <span class="math inline">\(y_1,\ldots, y_{n_t}\)</span> and a holdout or test portion <span class="math inline">\(y_{n_t +1},\ldots, y_{n_t + n_h}\)</span>. The training portion is of length <span class="math inline">\(n_t\)</span>, and the holdout portion is of length <span class="math inline">\(n_h\)</span>.
In the Bayesian DLM framework,
given the training data <span class="math inline">\(y_1,\ldots, y_{n_t}\)</span>, estimates of the states
<span class="math inline">\(x_1,\ldots, x_{n_t}\)</span> and estimates of the model hyperparameters <span class="math inline">\(\boldsymbol{\theta}\)</span>,
we first forecast <span class="math inline">\(x_{n_t+\ell},~\ell=1,\ldots,n_h\)</span> by <span class="math inline">\(f(x_{n_t+\ell}|\boldsymbol{y}^n),~\ell=1,\ldots,n_h\)</span>.
We then obtain <span class="math inline">\(n_h\)</span> forecasts of <span class="math inline">\(y_{n_t+\ell}\)</span> by
<span class="math inline">\(f(y_{n_t+\ell}|\boldsymbol{y}^n),~\ell=1,\ldots,n_h\)</span>.</p>
<p>In <code>R-INLA</code>, there is no separate forecasting function like the <code>predict()</code> function in the <code>stats</code> package which is commonly used with functions such as <code>lm()</code>. Therefore, we append the end of the training data of length <span class="math inline">\(n_t\)</span> with NA’s to represent the times to hold out the last <span class="math inline">\(n_h\)</span> data points. Forecasts for <span class="math inline">\(x_{n_t+\ell}\)</span> are obtained using the <code>summary.random</code> option. For example, we can forecast <span class="math inline">\(n_h = 10\)</span> future states in the AR(1) with level plus noise model; we use the <code>summary.random</code> option, as shown below.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="chapter3.html#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(<span class="fu">tail</span>(model.ar1.level<span class="sc">$</span>summary.random<span class="sc">$</span>id.x[,<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)],<span class="dv">10</span>))</span>
<span id="cb70-2"><a href="chapter3.html#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="do">##    ID  mean   sd   </span></span>
<span id="cb70-3"><a href="chapter3.html#cb70-3" aria-hidden="true" tabindex="-1"></a><span class="do">## 1  491  0.105 0.272</span></span>
<span id="cb70-4"><a href="chapter3.html#cb70-4" aria-hidden="true" tabindex="-1"></a><span class="do">## 2  492 -0.169 0.273</span></span>
<span id="cb70-5"><a href="chapter3.html#cb70-5" aria-hidden="true" tabindex="-1"></a><span class="do">## 3  493 -0.437 0.300</span></span>
<span id="cb70-6"><a href="chapter3.html#cb70-6" aria-hidden="true" tabindex="-1"></a><span class="do">## 4  494 -0.135 0.273</span></span>
<span id="cb70-7"><a href="chapter3.html#cb70-7" aria-hidden="true" tabindex="-1"></a><span class="do">## 5  495  0.220 0.279</span></span>
<span id="cb70-8"><a href="chapter3.html#cb70-8" aria-hidden="true" tabindex="-1"></a><span class="do">## 6  496  0.239 0.275</span></span>
<span id="cb70-9"><a href="chapter3.html#cb70-9" aria-hidden="true" tabindex="-1"></a><span class="do">## 7  497  0.122 0.272</span></span>
<span id="cb70-10"><a href="chapter3.html#cb70-10" aria-hidden="true" tabindex="-1"></a><span class="do">## 8  498  0.295 0.276</span></span>
<span id="cb70-11"><a href="chapter3.html#cb70-11" aria-hidden="true" tabindex="-1"></a><span class="do">## 9  499  0.261 0.275</span></span>
<span id="cb70-12"><a href="chapter3.html#cb70-12" aria-hidden="true" tabindex="-1"></a><span class="do">## 10 500  0.259 0.281</span></span></code></pre></div>
<p>We then obtain <span class="math inline">\(n_h =10\)</span> future forecasts <span class="math inline">\(y_{n_t+\ell}\)</span> using</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="chapter3.html#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(<span class="fu">tail</span>(model.ar1.level<span class="sc">$</span>summary.fitted.values[,<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)],<span class="dv">10</span>))</span>
<span id="cb71-2"><a href="chapter3.html#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="do">##    name         mean  sd    0.025q</span></span>
<span id="cb71-3"><a href="chapter3.html#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="do">## 1  fit.Pred.491 1.392 0.271 0.864 </span></span>
<span id="cb71-4"><a href="chapter3.html#cb71-4" aria-hidden="true" tabindex="-1"></a><span class="do">## 2  fit.Pred.492 1.118 0.273 0.575 </span></span>
<span id="cb71-5"><a href="chapter3.html#cb71-5" aria-hidden="true" tabindex="-1"></a><span class="do">## 3  fit.Pred.493 0.850 0.300 0.243 </span></span>
<span id="cb71-6"><a href="chapter3.html#cb71-6" aria-hidden="true" tabindex="-1"></a><span class="do">## 4  fit.Pred.494 1.152 0.272 0.611 </span></span>
<span id="cb71-7"><a href="chapter3.html#cb71-7" aria-hidden="true" tabindex="-1"></a><span class="do">## 5  fit.Pred.495 1.507 0.278 0.972 </span></span>
<span id="cb71-8"><a href="chapter3.html#cb71-8" aria-hidden="true" tabindex="-1"></a><span class="do">## 6  fit.Pred.496 1.526 0.275 0.996 </span></span>
<span id="cb71-9"><a href="chapter3.html#cb71-9" aria-hidden="true" tabindex="-1"></a><span class="do">## 7  fit.Pred.497 1.409 0.272 0.872 </span></span>
<span id="cb71-10"><a href="chapter3.html#cb71-10" aria-hidden="true" tabindex="-1"></a><span class="do">## 8  fit.Pred.498 1.583 0.276 1.050 </span></span>
<span id="cb71-11"><a href="chapter3.html#cb71-11" aria-hidden="true" tabindex="-1"></a><span class="do">## 9  fit.Pred.499 1.549 0.274 1.016 </span></span>
<span id="cb71-12"><a href="chapter3.html#cb71-12" aria-hidden="true" tabindex="-1"></a><span class="do">## 10 fit.Pred.500 1.547 0.281 1.002</span></span></code></pre></div>
<p>Figure <a href="chapter3.html#fig:fore-plot-ar1-level">3.13</a> shows the time series generated by the AR(1) with level plus noise model, together with the last <span class="math inline">\(10\)</span> forecasts. For a better visualization of forecasts (means of the posterior predictive distributions) and 2 standard deviation bounds, we show a plot with only the last 100 data points.</p>
<!-- BR: can you please make the x-label be "t" and y-label be $y_t$? -->
<div class="figure"><span id="fig:fore-plot-ar1-level"></span>
<img src="gitbook_version_files/figure-html/fore-plot-ar1-level-1.png" alt="Forecasts (blue) for ten future time points along with observed data (red) from the AR(1) with level plus noise model. The black vertical line divides the data into training and test portions. The gray shaded area shows forecast intervals based on 2 standard deviation (sd) bounds around the means of the posterior predictive distributions. " width="672" />
<p class="caption">
FIGURE 3.13: Forecasts (blue) for ten future time points along with observed data (red) from the AR(1) with level plus noise model. The black vertical line divides the data into training and test portions. The gray shaded area shows forecast intervals based on 2 standard deviation (sd) bounds around the means of the posterior predictive distributions.
</p>
</div>
</div>
<div id="modsel" class="section level2 hasAnchor" number="3.8">
<h2><span class="header-section-number">3.8</span> Model comparisons<a href="chapter3.html#modsel" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this section, we explain how to compare different fitted models. Many model comparison criteria have been defined in the Bayesian framework, including the conditional predictive ordinate (CPO),
the Bayes factor (BF), the deviance information criterion (DIC), and the Watanabe Akaike information criterion (WAIC). These are useful for comparing the relative performance of the fitted models based on the calibration (or training or fitting) data, and were reviewed in Chapters <a href="chapter1.html#chapter1">1</a> and <a href="chapter2.html#chapter2">2</a>.
We may also compare models based on their predictive performance using frequentist metrics such as the mean absolute percent error (MAPE) or mean absolute error (MAE). These two metrics can be computed from in-sample training data as well as out-of-sample test data.</p>
<div id="modsel-insamp-ch3" class="section level3 hasAnchor" number="3.8.1">
<h3><span class="header-section-number">3.8.1</span> In-sample model comparisons<a href="chapter3.html#modsel-insamp-ch3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We start with a discussion of in-sample model comparisons and illustrate code for the random walk plus noise model. In <code>R-INLA</code>, we compute these quantities using the <code>control.compute</code> option in the formula. If the output is saved in <code>out</code>, we can access the predictive quantities as <code>out$dic$dic</code>, or <code>out$cpo$cpo</code>, or <code>out$cpo$pit</code>, as shown below.</p>
<ol style="list-style-type: decimal">
<li>The <em>deviance information criterion</em> (DIC) was defined in <a href="chapter1.html#eq:DIC">(1.9)</a>. We use the <code>control.compute</code> option to obtain the DIC, via <code>control.compute=list(dic=TRUE)</code>, and access it by <code>out$dic$dic</code>. </li>
</ol>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="chapter3.html#cb72-1" aria-hidden="true" tabindex="-1"></a>model.rw1 <span class="ot">&lt;-</span> <span class="fu">inla</span>(</span>
<span id="cb72-2"><a href="chapter3.html#cb72-2" aria-hidden="true" tabindex="-1"></a>  formula.rw1,</span>
<span id="cb72-3"><a href="chapter3.html#cb72-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb72-4"><a href="chapter3.html#cb72-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> rw1.dat,</span>
<span id="cb72-5"><a href="chapter3.html#cb72-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">control.predictor =</span> <span class="fu">list</span>(<span class="at">compute =</span> <span class="cn">TRUE</span>),</span>
<span id="cb72-6"><a href="chapter3.html#cb72-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">control.compute =</span> <span class="fu">list</span>(<span class="at">dic =</span> <span class="cn">TRUE</span>, <span class="at">cpo =</span> <span class="cn">TRUE</span>)</span>
<span id="cb72-7"><a href="chapter3.html#cb72-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb72-8"><a href="chapter3.html#cb72-8" aria-hidden="true" tabindex="-1"></a>model.rw1<span class="sc">$</span>dic<span class="sc">$</span>dic</span>
<span id="cb72-9"><a href="chapter3.html#cb72-9" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 1312</span></span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>The <em>conditional predictive ordinate</em> (CPO) was defined in
Chapter <a href="chapter1.html#chapter1">1</a>
as <span class="math inline">\(p(y_t \vert \boldsymbol y_{(-t)})\)</span>, a “leave-one-out” measure of
model fit. The sum of the log CPO values gives us the
pseudo-Bayes factor. We again use <code>control.compute=list(cpo=TRUE)</code>, and access it by <code>out$cpo$cpo</code>.</li>
</ol>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="chapter3.html#cb73-1" aria-hidden="true" tabindex="-1"></a>cpo.rw1 <span class="ot">&lt;-</span> model.rw1<span class="sc">$</span>cpo<span class="sc">$</span>cpo</span>
<span id="cb73-2"><a href="chapter3.html#cb73-2" aria-hidden="true" tabindex="-1"></a>psBF.rw1 <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">log</span>(cpo.rw1))</span>
<span id="cb73-3"><a href="chapter3.html#cb73-3" aria-hidden="true" tabindex="-1"></a>psBF.rw1</span>
<span id="cb73-4"><a href="chapter3.html#cb73-4" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] -671</span></span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li>The <em>probability integral transform</em> (PIT) defined by</li>
</ol>
<p><span class="math display" id="eq:PIT">\[\begin{align}
p(y_t^{\mbox{new}} \le y_t \vert \boldsymbol y_{(-t)})
\tag{3.26}
\end{align}\]</span>
is another “leave-one-out” measure of fit computed by <code>R-INLA</code>.
A histogram of PIT must resemble a uniform distribution; extreme values indicate outlying observations.
We again use <code>control.compute=list(cpo=TRUE)</code>, and access by using <code>out$cpo$pit</code>.
The plot in Figure <a href="chapter3.html#fig:hist-pit">3.14</a> gives an indication of model adequacy, since the histogram is close to that of a sample from a uniform distribution.</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="chapter3.html#cb74-1" aria-hidden="true" tabindex="-1"></a>pit.rw1 <span class="ot">&lt;-</span> model.rw1<span class="sc">$</span>cpo<span class="sc">$</span>pit</span>
<span id="cb74-2"><a href="chapter3.html#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(pit.rw1,<span class="at">main =</span><span class="st">&quot; &quot;</span>, <span class="at">ylab=</span><span class="st">&quot;frequency&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:hist-pit"></span>
<img src="gitbook_version_files/figure-html/hist-pit-1.png" alt="Histogram of the probability integral transform (PIT) for the random walk plus noise model." width="672" />
<p class="caption">
FIGURE 3.14: Histogram of the probability integral transform (PIT) for the random walk plus noise model.
</p>
</div>
<p>Note that <code>R-INLA</code> computes CPO or PIT by keeping the integration-points fixed.
To get improved grid integration, we can include, for instance, <code>control.inla=list(int.strategy = "grid", diff.logdens = 4)</code>.
Also, to increase the accuracy of the tails of the marginals, we can use <code>control.inla = list(strategy = "laplace", npoints = 21)</code>.
This adds 21 evaluation points instead of the default <code>npoints=9</code>.</p>
<p>It is useful to understand what the following check for failure means. <code>R-INLA</code> makes some implicit assumptions which are tested using internal checks. If <code>model.rw1$cpo$failure[i] == 0</code>, then no assumption is violated.
If <code>model.rw1$cpo$failure[i] &gt; 0</code> for any row <span class="math inline">\(i\)</span> of the data, this indicates that some assumption is violated, larger values (maximum value is <span class="math inline">\(1\)</span>) indicating more serious violations of assumptions.</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="chapter3.html#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(model.rw1<span class="sc">$</span>cpo<span class="sc">$</span>failure)</span>
<span id="cb75-2"><a href="chapter3.html#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb75-3"><a href="chapter3.html#cb75-3" aria-hidden="true" tabindex="-1"></a><span class="do">##   0 </span></span>
<span id="cb75-4"><a href="chapter3.html#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="do">## 500</span></span></code></pre></div>
<p>It might be a good idea to recompute those, if any, CPO/PIT values for which <code>result$cpo$failure&gt;0</code>. INLA has provided
<code>improved.result = inla.cpo(result)</code>.
This takes an object which is the output from <code>inla()</code>, and recomputes (in an efficient way) the CPO/PIT for which <code>result$cpo$failure &gt; 0</code>, and returns <code>model.rw1</code> with the improved estimates of CPO/PIT. See <code>?inla.cpo</code> for details.
<code>R-INLA</code> recommends caution when using CPO or PIT for model validation, since they may depend on tail behavior, which is difficult to estimate.
We can verify that the smallest CPO values are estimated correctly by setting <code>res$cpo$failure[smallest cpo indices] = 1</code> and re-estimating them with <code>inla.cpo()</code>.</p>
<ol start="4" style="list-style-type: decimal">
<li><code>R-INLA</code> also outputs the marginal likelihood (see the definition in Chapter <a href="chapter1.html#chapter1">1</a>) on the logarithmic scale by default. Recall that a model with higher marginal likelihood is preferred.</li>
</ol>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="chapter3.html#cb76-1" aria-hidden="true" tabindex="-1"></a>model.rw1<span class="sc">$</span>mlik</span>
<span id="cb76-2"><a href="chapter3.html#cb76-2" aria-hidden="true" tabindex="-1"></a><span class="do">##                                         [,1]</span></span>
<span id="cb76-3"><a href="chapter3.html#cb76-3" aria-hidden="true" tabindex="-1"></a><span class="do">## log marginal-likelihood (integration) -750.0</span></span>
<span id="cb76-4"><a href="chapter3.html#cb76-4" aria-hidden="true" tabindex="-1"></a><span class="do">## log marginal-likelihood (Gaussian)    -750.3</span></span></code></pre></div>
</div>
<div id="modsel-outsamp-ch3" class="section level3 hasAnchor" number="3.8.2">
<h3><span class="header-section-number">3.8.2</span> Out-of-sample comparisons<a href="chapter3.html#modsel-outsamp-ch3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let <span class="math inline">\(y_{n_t} (\ell)\)</span> denote the forecast from origin <span class="math inline">\(n_t\)</span> for <span class="math inline">\(y_{t+\ell},~\ell=1,\ldots,n_h\)</span>, and let
<span class="math inline">\(e_{n_t} (\ell) = y_{n_t+\ell} - y_{n_t} (\ell)\)</span> be the <span class="math inline">\(\ell\)</span>th forecast error. The mean absolute percent error (MAPE) is a well known criterion, defined by</p>
<p><span class="math display" id="eq:mape">\[\begin{align}
{\rm MAPE} = \frac{100}{n_h} \sum_{\ell=1}^{n_h}\vert e_{n_t}(\ell)/y_{n_t+\ell}\vert.  \tag{3.27}
\end{align}\]</span>
Another widely used criterion is the mean absolute error (MAE) given by</p>
<p><span class="math display" id="eq:mae">\[\begin{align}
{\rm MAE} =  \frac{1}{n_h} \sum_{\ell=1}^{n_h} |e_{n_t}(\ell)|.  \tag{3.28}
\end{align}\]</span>
Small values of MAPE and MAE indicate better fitting models. We show the custom code for computing MAPE and MAE in Chapter <a href="resources.html#resources">14</a>. We can also compute in-sample MAPE and in-sample MAE, as we discuss in the following chapters.</p>
</div>
</div>
<div id="nondefault-priors" class="section level2 hasAnchor" number="3.9">
<h2><span class="header-section-number">3.9</span> Non-default prior specifications<a href="chapter3.html#nondefault-priors" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We look at a few ways for specifying non-default priors for hyperparameters. A listing of all prior distributions that <code>R-INLA</code> supports is given in Table <a href="resources.html#tab:inlapriors">14.4</a>; this is similar to Table 5.2 in <span class="citation">Gómez-Rubio (<a href="#ref-gomez2020bayesian" role="doc-biblioref">2020</a>)</span>. In some situations, we may wish to use alternatives to the default prior specifications, selecting one of the other options available in <code>R-INLA</code>. We show this using <span class="math inline">\(\theta_1 = \log(1/\sigma^2_w)\)</span> and
<span class="math inline">\(\theta_2 = \log(\frac{1+\phi}{1-\phi})\)</span>.</p>
<ol style="list-style-type: decimal">
<li>We can change the hyperprior <em>parameter values</em> from their default settings. For example, for the log-gamma prior for
<span class="math inline">\(\log(1/\sigma^2_w)\)</span>, we can change
<code>param = c(1, 0.00005)</code> to <code>param = c(1, 0.0001)</code>
and/or <code>initial = 4</code> to <code>initial = 2</code>. The prior for <span class="math inline">\(\theta_2\)</span> will remain at its default setting.</li>
</ol>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="chapter3.html#cb77-1" aria-hidden="true" tabindex="-1"></a>hyper.state <span class="ot">=</span> <span class="fu">list</span>(</span>
<span id="cb77-2"><a href="chapter3.html#cb77-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">theta1 =</span> <span class="fu">list</span>(</span>
<span id="cb77-3"><a href="chapter3.html#cb77-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">prior =</span> <span class="st">&quot;loggamma&quot;</span>,</span>
<span id="cb77-4"><a href="chapter3.html#cb77-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">param =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="fl">0.00005</span>),</span>
<span id="cb77-5"><a href="chapter3.html#cb77-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">initial =</span> <span class="dv">4</span>,</span>
<span id="cb77-6"><a href="chapter3.html#cb77-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">fixed =</span> <span class="cn">FALSE</span></span>
<span id="cb77-7"><a href="chapter3.html#cb77-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb77-8"><a href="chapter3.html#cb77-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>Or, we may use other prior distributions, such as the <em>beta correlation prior</em> for <span class="math inline">\(\theta_2\)</span> (see <code>inla.doc("betacorrelation")</code> for more details on this prior). The prior for <span class="math inline">\(\theta_1\)</span> will remain at its default setting.</li>
</ol>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="chapter3.html#cb78-1" aria-hidden="true" tabindex="-1"></a>hyper.state <span class="ot">=</span> <span class="fu">list</span>(</span>
<span id="cb78-2"><a href="chapter3.html#cb78-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">theta2 =</span> <span class="fu">list</span>(</span>
<span id="cb78-3"><a href="chapter3.html#cb78-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">prior =</span> <span class="st">&quot;betacorrelation&quot;</span>,</span>
<span id="cb78-4"><a href="chapter3.html#cb78-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">param =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>),</span>
<span id="cb78-5"><a href="chapter3.html#cb78-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">initial =</span> <span class="sc">-</span><span class="fl">1.098</span>,</span>
<span id="cb78-6"><a href="chapter3.html#cb78-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">fixed =</span> <span class="cn">FALSE</span></span>
<span id="cb78-7"><a href="chapter3.html#cb78-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb78-8"><a href="chapter3.html#cb78-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>The betacorrelation prior is a prior for the AR(1) correlation parameter <span class="math inline">\(\phi\)</span> (recall this is denoted by <span class="math inline">\(\rho\)</span> in <code>R-INLA</code>), represented internally as</p>
<p><span class="math display" id="eq:betacorrprior">\[\begin{align}
\theta_{\phi,bc} = \log \frac{1+\phi}{1-\phi}.
\tag{3.29}
\end{align}\]</span>
This prior is defined on <span class="math inline">\(\theta_{\phi,bc}\)</span> so that
<span class="math inline">\(\phi\)</span> is scaled to be in <span class="math inline">\((-1,1)\)</span> and follow a Beta<span class="math inline">\((a,b)\)</span> distribution given by</p>
<p><span class="math display">\[\begin{align*}
\pi(\phi; a,b) = \frac{1}{2} \frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)}
\phi^{a-1} (1-\phi)^{b-1}.
\end{align*}\]</span>
The inverse transformation from <span class="math inline">\(\theta_{\phi,bc}\)</span> to <span class="math inline">\(\phi\)</span> is the same as for the default prior on <span class="math inline">\(\phi\)</span>, and is done by <code>R-INLA</code>, so that the output is provided on <span class="math inline">\(\phi\)</span>.</p>
<div id="custom-priors" class="section level3 hasAnchor" number="3.9.1">
<h3><span class="header-section-number">3.9.1</span> Custom prior specifications<a href="chapter3.html#custom-priors" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In some examples, we may wish to specify priors that are not included in the list of priors provided in <code>R-INLA</code> and listed in <code>names(inla.models()$prior)</code>. In such cases,
there are two ways for building user-defined priors, i.e., <em>table priors</em>, which are based on tabulated values from the desired densities and <em>expression priors</em>, which are specified by formulas for the desired prior density functions.</p>
<div id="table-priors" class="section level4 unnumbered hasAnchor">
<h4>Table Priors<a href="chapter3.html#table-priors" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The user provides a table with values of the hyperparameter defined on <code>R-INLA</code>’s internal scale and the associated prior densities on the log-scale. Values not defined in the table are interpolated at run time.
INLA fits a spline through the points and continues with this in the succeeding computations. There is no transformation into a functional form. The input-format for the table is a string, which starts with <code>table:</code> and is then followed by a block of <span class="math inline">\(x\)</span>-values and a block of corresponding <span class="math inline">\(y\)</span>-values, which represent the values of the log-density evaluated at <span class="math inline">\(x\)</span>. The syntax is:</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="chapter3.html#cb79-1" aria-hidden="true" tabindex="-1"></a>    table<span class="sc">:</span> x_1 ... x_n y_1 ... y_n</span></code></pre></div>
<p>For more details, see inla.doc(“table”).
As an example, suppose we wish to set up a Gaussian prior with zero mean and precision <span class="math inline">\(0.001\)</span> for a hyperparameter <span class="math inline">\(\theta\)</span> (on the internal scale). The following code sets this up as a table prior.</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="chapter3.html#cb80-1" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">100</span>, <span class="dv">100</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span>
<span id="cb80-2"><a href="chapter3.html#cb80-2" aria-hidden="true" tabindex="-1"></a>log_dens <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(theta, <span class="dv">0</span>, <span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">/</span> <span class="fl">0.001</span>), <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb80-3"><a href="chapter3.html#cb80-3" aria-hidden="true" tabindex="-1"></a>gauss.prior <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">&quot;table: &quot;</span>,</span>
<span id="cb80-4"><a href="chapter3.html#cb80-4" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">paste</span>(<span class="fu">c</span>(theta, log_dens), <span class="at">collapse =</span> <span class="st">&quot; &quot;</span>)</span>
<span id="cb80-5"><a href="chapter3.html#cb80-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>Depending on what <span class="math inline">\(\theta\)</span> represents, <code>gauss.prior</code> will be included either in
<code>formula</code> under <code>f()</code> or in <code>control.family</code>, as mentioned earlier.</p>
</div>
<div id="expression-priors" class="section level4 unnumbered hasAnchor">
<h4>Expression Priors<a href="chapter3.html#expression-priors" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The expression prior definition uses the <code>muparser</code> library.<a href="resources.html#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> To set up a N<span class="math inline">\((0,0.01)\)</span> prior on a hyperparameter <span class="math inline">\(\theta\)</span> (i.e., with precision <span class="math inline">\(100\)</span>), we can include the following code in the formula and model execution:</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="chapter3.html#cb81-1" aria-hidden="true" tabindex="-1"></a>gauss.pr.e <span class="ot">&lt;-</span> <span class="st">&quot;expression:</span></span>
<span id="cb81-2"><a href="chapter3.html#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="st">  mean = 0;</span></span>
<span id="cb81-3"><a href="chapter3.html#cb81-3" aria-hidden="true" tabindex="-1"></a><span class="st">  prec = 1000;</span></span>
<span id="cb81-4"><a href="chapter3.html#cb81-4" aria-hidden="true" tabindex="-1"></a><span class="st">  logdens = 0.5 * log(prec) - 0.5 * log (2 * pi);</span></span>
<span id="cb81-5"><a href="chapter3.html#cb81-5" aria-hidden="true" tabindex="-1"></a><span class="st">  logdens = logdens - 0.5 * prec * (theta - mean)^2;</span></span>
<span id="cb81-6"><a href="chapter3.html#cb81-6" aria-hidden="true" tabindex="-1"></a><span class="st">  return(logdens);</span></span>
<span id="cb81-7"><a href="chapter3.html#cb81-7" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span></code></pre></div>
<p><code>R-INLA</code> recognizes several well known functions that can be used within the expression statement. These include common mathematical functions, such as <span class="math inline">\(\exp(x)\)</span>, <span class="math inline">\(\sin(x)\)</span>, <span class="math inline">\(x^y\)</span>, <span class="math inline">\(\mbox{pow}(x;y)\)</span> (to denote <span class="math inline">\(x\)</span> raised to power <span class="math inline">\(y\)</span>), <span class="math inline">\(\mbox{gamma}(x)\)</span> and <span class="math inline">\(\mbox{lgamma}(x)\)</span> (to denote the gamma function and its logarithm), etc.</p>
</div>
</div>
<div id="pc-priors" class="section level3 hasAnchor" number="3.9.2">
<h3><span class="header-section-number">3.9.2</span> Penalized complexity (PC) priors<a href="chapter3.html#pc-priors" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><code>R-INLA</code> provides a useful framework for building penalized complexity (PC) priors <span class="citation">(<a href="#ref-fuglstad2019constructing" role="doc-biblioref">Fuglstad et al. 2019</a>)</span>. These priors
are defined on individual model components that can be regarded as flexible extensions of a simple and interpretable base model, and then penalizes deviations from the base model. This allows us to control flexibility, reduce over-fitting, and improve predictive performance. PC priors include a single parameter to control the degree of flexibility allowed in the model. They are specified by setting values <span class="math inline">\((U,\alpha)\)</span> such that
<span class="math inline">\(P(T(\xi) &gt; U)=\alpha\)</span>,
where <span class="math inline">\(T(\xi)\)</span> is an interpretable transformation of the flexibility parameter <span class="math inline">\(xi\)</span>, and <span class="math inline">\(U\)</span> is an upper bound that specifies a tail event with probability <span class="math inline">\(\alpha\)</span>.</p>
<p>For example, recall that we assumed an inverse log-Gamma prior on <span class="math inline">\(\sigma^2_v\)</span>. Instead, we can set a PC prior on the standard deviation <span class="math inline">\(\sigma_v\)</span> by <span class="math inline">\(P(\sigma_v&gt;1)=0.01\)</span>:</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="chapter3.html#cb82-1" aria-hidden="true" tabindex="-1"></a>prior.prec <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">prec =</span> <span class="fu">list</span>(<span class="at">prior =</span> <span class="st">&quot;pc.prec&quot;</span>,</span>
<span id="cb82-2"><a href="chapter3.html#cb82-2" aria-hidden="true" tabindex="-1"></a>                               <span class="at">param =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="fl">0.01</span>)))</span></code></pre></div>
<p>Documentation and details on the PC prior <code>pc.prec</code> can be seen in <code>inla.doc("pc.prec")</code>.</p>
</div>
</div>
<div id="post-sampling" class="section level2 hasAnchor" number="3.10">
<h2><span class="header-section-number">3.10</span> Posterior sampling of latent effects and hyperparameters<a href="chapter3.html#post-sampling" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In addition to producing posterior summaries as we have seen earlier, <code>R-INLA</code> can also generate samples from the approximate posterior distributions of the latent effects and the hyperparameters <span class="citation">(<a href="#ref-rue2005gaussian" role="doc-biblioref">Rue and Held 2005</a>; <a href="#ref-gomez2018markov" role="doc-biblioref">Gómez-Rubio and Rue 2018</a>)</span>.
To do this, we first fit the <code>inla</code> model with the option
<code>config = TRUE</code> in <code>control.compute</code>, which keeps the internal GMRF representation for the latent effects in the object returned by <code>inla()</code>.
The table below shows the options a user may specify with the function
<code>inla.posterior.sample()</code> (see Table 2.11 in <span class="citation">Gómez-Rubio (<a href="#ref-gomez2020bayesian" role="doc-biblioref">2020</a>)</span>).</p>
<p>We illustrate posterior sample generation for the AR(1) with level plus noise model, which we discussed earlier in this chapter. Let <span class="math inline">\(n\)</span> denote the length of the entire time series,
while <span class="math inline">\(n_t\)</span> and <span class="math inline">\(n_h\)</span> are the lengths of the training and test (or holdout) portions respectively. We use <em>n.train</em> and <em>n.hold</em> to denote these in the code. Note that we use test and holdout interchangeably in the book.</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="chapter3.html#cb83-1" aria-hidden="true" tabindex="-1"></a>sim.ar1.level <span class="ot">&lt;-</span></span>
<span id="cb83-2"><a href="chapter3.html#cb83-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">simulation.from.ar</span>(</span>
<span id="cb83-3"><a href="chapter3.html#cb83-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">sample.size =</span> <span class="dv">500</span>,</span>
<span id="cb83-4"><a href="chapter3.html#cb83-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">burn.in =</span> <span class="dv">100</span>,</span>
<span id="cb83-5"><a href="chapter3.html#cb83-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">phi =</span> <span class="fl">0.6</span>,</span>
<span id="cb83-6"><a href="chapter3.html#cb83-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">level =</span> <span class="fl">1.4</span>,</span>
<span id="cb83-7"><a href="chapter3.html#cb83-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">drift =</span> <span class="dv">0</span>,</span>
<span id="cb83-8"><a href="chapter3.html#cb83-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">V =</span> <span class="fl">0.2</span>,</span>
<span id="cb83-9"><a href="chapter3.html#cb83-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">W =</span> <span class="fl">0.1</span>,</span>
<span id="cb83-10"><a href="chapter3.html#cb83-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot.data =</span> <span class="cn">FALSE</span>,</span>
<span id="cb83-11"><a href="chapter3.html#cb83-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">seed =</span> <span class="dv">123457</span></span>
<span id="cb83-12"><a href="chapter3.html#cb83-12" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb83-13"><a href="chapter3.html#cb83-13" aria-hidden="true" tabindex="-1"></a>y.ar1.level <span class="ot">&lt;-</span> sim.ar1.level<span class="sc">$</span>sim.data</span>
<span id="cb83-14"><a href="chapter3.html#cb83-14" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(y.ar1.level)</span>
<span id="cb83-15"><a href="chapter3.html#cb83-15" aria-hidden="true" tabindex="-1"></a>n.hold <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb83-16"><a href="chapter3.html#cb83-16" aria-hidden="true" tabindex="-1"></a>hold.y <span class="ot">&lt;-</span> <span class="fu">tail</span>(y.ar1.level, n.hold)</span>
<span id="cb83-17"><a href="chapter3.html#cb83-17" aria-hidden="true" tabindex="-1"></a>train.y <span class="ot">&lt;-</span> y.ar1.level[<span class="dv">1</span><span class="sc">:</span>(<span class="fu">length</span>(y.ar1.level) <span class="sc">-</span> n.hold)]</span>
<span id="cb83-18"><a href="chapter3.html#cb83-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Append training data with NA</span></span>
<span id="cb83-19"><a href="chapter3.html#cb83-19" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> train.y</span>
<span id="cb83-20"><a href="chapter3.html#cb83-20" aria-hidden="true" tabindex="-1"></a>y.append <span class="ot">&lt;-</span> <span class="fu">c</span>(y, <span class="fu">rep</span>(<span class="cn">NA</span>, n.hold))</span>
<span id="cb83-21"><a href="chapter3.html#cb83-21" aria-hidden="true" tabindex="-1"></a>id.x <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>n</span>
<span id="cb83-22"><a href="chapter3.html#cb83-22" aria-hidden="true" tabindex="-1"></a>data.ar1.level <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(y.ar1.level, id.x)</span>
<span id="cb83-23"><a href="chapter3.html#cb83-23" aria-hidden="true" tabindex="-1"></a>formula.ar1.level <span class="ot">&lt;-</span></span>
<span id="cb83-24"><a href="chapter3.html#cb83-24" aria-hidden="true" tabindex="-1"></a>  y.ar1.level <span class="sc">~</span> <span class="fu">f</span>(id.x, <span class="at">model =</span> <span class="st">&quot;ar1&quot;</span>, <span class="at">constr =</span> <span class="cn">FALSE</span>)</span>
<span id="cb83-25"><a href="chapter3.html#cb83-25" aria-hidden="true" tabindex="-1"></a>model.ar1.level <span class="ot">&lt;-</span> <span class="fu">inla</span>(</span>
<span id="cb83-26"><a href="chapter3.html#cb83-26" aria-hidden="true" tabindex="-1"></a>  formula.ar1.level,</span>
<span id="cb83-27"><a href="chapter3.html#cb83-27" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb83-28"><a href="chapter3.html#cb83-28" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> data.ar1.level,</span>
<span id="cb83-29"><a href="chapter3.html#cb83-29" aria-hidden="true" tabindex="-1"></a>  <span class="at">control.compute =</span> <span class="fu">list</span>(<span class="at">config =</span> <span class="cn">TRUE</span>),</span>
<span id="cb83-30"><a href="chapter3.html#cb83-30" aria-hidden="true" tabindex="-1"></a>  <span class="at">control.predictor =</span> <span class="fu">list</span>(<span class="at">compute =</span> <span class="cn">TRUE</span>)</span>
<span id="cb83-31"><a href="chapter3.html#cb83-31" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb83-32"><a href="chapter3.html#cb83-32" aria-hidden="true" tabindex="-1"></a><span class="co"># summary(model.ar1.level)</span></span>
<span id="cb83-33"><a href="chapter3.html#cb83-33" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(model.ar1.level<span class="sc">$</span>summary.fixed[,<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>)])</span>
<span id="cb83-34"><a href="chapter3.html#cb83-34" aria-hidden="true" tabindex="-1"></a><span class="do">##   name      mean  sd    0.025q 0.5q  0.975q</span></span>
<span id="cb83-35"><a href="chapter3.html#cb83-35" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 Intercept 1.287 0.034 1.221  1.287 1.354</span></span>
<span id="cb83-36"><a href="chapter3.html#cb83-36" aria-hidden="true" tabindex="-1"></a><span class="fu">format.inla.out</span>(model.ar1.level<span class="sc">$</span>summary.hyperpar[,<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)])</span>
<span id="cb83-37"><a href="chapter3.html#cb83-37" aria-hidden="true" tabindex="-1"></a><span class="do">##   name                       mean  sd   </span></span>
<span id="cb83-38"><a href="chapter3.html#cb83-38" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 Precision for Gaussian obs 4.509 0.591</span></span>
<span id="cb83-39"><a href="chapter3.html#cb83-39" aria-hidden="true" tabindex="-1"></a><span class="do">## 2 Precision for id.x         8.170 1.853</span></span>
<span id="cb83-40"><a href="chapter3.html#cb83-40" aria-hidden="true" tabindex="-1"></a><span class="do">## 3 Rho for id.x               0.450 0.075</span></span></code></pre></div>
<p><strong>Posterior samples for hyperparameters</strong></p>
<p>We generate <code>n.samp = 2000</code> samples (default is <span class="math inline">\(1000\)</span>) from the posterior distributions of <span class="math inline">\(1/\sigma^2_v, 1/\sigma^2_x\)</span>,and <span class="math inline">\(\phi\)</span>. Since the default option is <code>intern = FALSE</code>, these values are not in the internal <code>R-INLA</code> representations of these hyperparameters, but rather in their original representations.
Recall that the true precisions are <span class="math inline">\(5\)</span> and <span class="math inline">\(6.4\)</span>, while the true <span class="math inline">\(\phi\)</span> is <span class="math inline">\(0.6\)</span>.
The <code>inla.hyperpar.sample</code> function employs the
<em>grid integration strategy</em>,
where the joint posterior of the hyperparameters is evaluated in a regular grid of points (see <span class="citation">Rue, Martino, and Chopin (<a href="#ref-rue09" role="doc-biblioref">2009</a>)</span> and <span class="citation">Seppä et al. (<a href="#ref-seppa2019-SIM" role="doc-biblioref">2019</a>)</span>).
The histograms of these posterior samples are symmetric, as seen in Figure <a href="chapter3.html#fig:plot-hyperpar-sample">3.15</a>.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="chapter3.html#cb84-1" aria-hidden="true" tabindex="-1"></a>n.samp <span class="ot">&lt;-</span> <span class="dv">2000</span></span>
<span id="cb84-2"><a href="chapter3.html#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123457</span>)</span>
<span id="cb84-3"><a href="chapter3.html#cb84-3" aria-hidden="true" tabindex="-1"></a>ar1.level.hyperpar.samples <span class="ot">&lt;-</span></span>
<span id="cb84-4"><a href="chapter3.html#cb84-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">inla.hyperpar.sample</span>(n.samp, model.ar1.level, <span class="at">improve.marginals =</span> <span class="cn">TRUE</span>)</span>
<span id="cb84-5"><a href="chapter3.html#cb84-5" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb84-6"><a href="chapter3.html#cb84-6" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(</span>
<span id="cb84-7"><a href="chapter3.html#cb84-7" aria-hidden="true" tabindex="-1"></a>  ar1.level.hyperpar.samples[, <span class="dv">2</span>],</span>
<span id="cb84-8"><a href="chapter3.html#cb84-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="fu">expression</span>(<span class="dv">1</span><span class="sc">/</span><span class="fu">Var</span>(x[t])),</span>
<span id="cb84-9"><a href="chapter3.html#cb84-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;frequency&quot;</span>,</span>
<span id="cb84-10"><a href="chapter3.html#cb84-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb84-11"><a href="chapter3.html#cb84-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">sub =</span> <span class="st">&quot;(a)&quot;</span></span>
<span id="cb84-12"><a href="chapter3.html#cb84-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb84-13"><a href="chapter3.html#cb84-13" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(</span>
<span id="cb84-14"><a href="chapter3.html#cb84-14" aria-hidden="true" tabindex="-1"></a>  ar1.level.hyperpar.samples[, <span class="dv">3</span>],</span>
<span id="cb84-15"><a href="chapter3.html#cb84-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="fu">expression</span>(phi),</span>
<span id="cb84-16"><a href="chapter3.html#cb84-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;frequency&quot;</span>,</span>
<span id="cb84-17"><a href="chapter3.html#cb84-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb84-18"><a href="chapter3.html#cb84-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">sub =</span> <span class="st">&quot;(b)&quot;</span></span>
<span id="cb84-19"><a href="chapter3.html#cb84-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb84-20"><a href="chapter3.html#cb84-20" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(</span>
<span id="cb84-21"><a href="chapter3.html#cb84-21" aria-hidden="true" tabindex="-1"></a>  ar1.level.hyperpar.samples[, <span class="dv">1</span>],</span>
<span id="cb84-22"><a href="chapter3.html#cb84-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="fu">expression</span>(<span class="dv">1</span><span class="sc">/</span>sigma[v]<span class="sc">^</span><span class="dv">2</span>),</span>
<span id="cb84-23"><a href="chapter3.html#cb84-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;frequency&quot;</span>,</span>
<span id="cb84-24"><a href="chapter3.html#cb84-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb84-25"><a href="chapter3.html#cb84-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">sub =</span> <span class="st">&quot;(c)&quot;</span></span>
<span id="cb84-26"><a href="chapter3.html#cb84-26" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure"><span id="fig:plot-hyperpar-sample"></span>
<img src="gitbook_version_files/figure-html/plot-hyperpar-sample-1.png" alt="Histograms of samples of hyperparameters generated using the function inla.hyperpar.samples in the AR(1) with level plus noise model. Precision of state variable in (a), $\phi$ in (b), and precision of the observation error in (c)." width="672" />
<p class="caption">
FIGURE 3.15: Histograms of samples of hyperparameters generated using the function inla.hyperpar.samples in the AR(1) with level plus noise model. Precision of state variable in (a), <span class="math inline">\(\phi\)</span> in (b), and precision of the observation error in (c).
</p>
</div>
<p>Next, we generate posterior samples for the latent random effects <span class="math inline">\(x_t, t=1,\ldots,n\)</span>.
We set <code>num.threads=1</code>, and a random seed to facilitate reproducibility (see below for a discussion).</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="chapter3.html#cb85-1" aria-hidden="true" tabindex="-1"></a>ar1.level.latent_hyper.samples <span class="ot">&lt;-</span></span>
<span id="cb85-2"><a href="chapter3.html#cb85-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">inla.posterior.sample</span>(n.samp,</span>
<span id="cb85-3"><a href="chapter3.html#cb85-3" aria-hidden="true" tabindex="-1"></a>                        model.ar1.level,</span>
<span id="cb85-4"><a href="chapter3.html#cb85-4" aria-hidden="true" tabindex="-1"></a>                        <span class="at">seed =</span> <span class="dv">123457</span>,</span>
<span id="cb85-5"><a href="chapter3.html#cb85-5" aria-hidden="true" tabindex="-1"></a>                        <span class="at">num.threads =</span> <span class="dv">1</span>)</span>
<span id="cb85-6"><a href="chapter3.html#cb85-6" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(ar1.level.latent_hyper.samples)</span>
<span id="cb85-7"><a href="chapter3.html#cb85-7" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 2000</span></span>
<span id="cb85-8"><a href="chapter3.html#cb85-8" aria-hidden="true" tabindex="-1"></a>model.ar1.level<span class="sc">$</span>misc<span class="sc">$</span>configs<span class="sc">$</span>contents</span>
<span id="cb85-9"><a href="chapter3.html#cb85-9" aria-hidden="true" tabindex="-1"></a><span class="do">## $tag</span></span>
<span id="cb85-10"><a href="chapter3.html#cb85-10" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;Predictor&quot;   &quot;id.x&quot;        &quot;(Intercept)&quot;</span></span>
<span id="cb85-11"><a href="chapter3.html#cb85-11" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb85-12"><a href="chapter3.html#cb85-12" aria-hidden="true" tabindex="-1"></a><span class="do">## $start</span></span>
<span id="cb85-13"><a href="chapter3.html#cb85-13" aria-hidden="true" tabindex="-1"></a><span class="do">## [1]    1  501 1001</span></span>
<span id="cb85-14"><a href="chapter3.html#cb85-14" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb85-15"><a href="chapter3.html#cb85-15" aria-hidden="true" tabindex="-1"></a><span class="do">## $length</span></span>
<span id="cb85-16"><a href="chapter3.html#cb85-16" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 500 500   1</span></span>
<span id="cb85-17"><a href="chapter3.html#cb85-17" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(ar1.level.latent_hyper.samples[[<span class="dv">1</span>]])</span>
<span id="cb85-18"><a href="chapter3.html#cb85-18" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;hyperpar&quot; &quot;latent&quot;   &quot;logdens&quot;</span></span></code></pre></div>
<p>It is possible to look at time series plots of selected posterior <span class="math inline">\(x_t\)</span> samples; for example, samples 500, 1000, 1500, and 2000 are shown in Figure <a href="chapter3.html#fig:time-series-posterior-samples">3.16</a>.</p>
<div class="figure"><span id="fig:time-series-posterior-samples"></span>
<img src="gitbook_version_files/figure-html/time-series-posterior-samples-1.png" alt="Time series plots of selected posterior samples from the AR(1) with level plus noise model." width="672" />
<p class="caption">
FIGURE 3.16: Time series plots of selected posterior samples from the AR(1) with level plus noise model.
</p>
</div>
<p>Based on samples of size <em>n.samp = 2000</em> we can construct histograms at selected times, say at <span class="math inline">\(t=250\)</span> and time <span class="math inline">\(t=500\)</span>, as shown in Figure <a href="chapter3.html#fig:hist-post-time">3.17</a>.</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="chapter3.html#cb86-1" aria-hidden="true" tabindex="-1"></a>latent.sample.time <span class="ot">&lt;-</span> ar1.level.latent_hyper.samples <span class="sc">%&gt;%</span></span>
<span id="cb86-2"><a href="chapter3.html#cb86-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sapply</span>(<span class="cf">function</span>(x)</span>
<span id="cb86-3"><a href="chapter3.html#cb86-3" aria-hidden="true" tabindex="-1"></a>    x<span class="sc">$</span>latent[<span class="dv">501</span><span class="sc">:</span><span class="dv">1000</span>])</span>
<span id="cb86-4"><a href="chapter3.html#cb86-4" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb86-5"><a href="chapter3.html#cb86-5" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(latent.sample.time[, <span class="dv">250</span>],</span>
<span id="cb86-6"><a href="chapter3.html#cb86-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(x[<span class="dv">250</span>]),</span>
<span id="cb86-7"><a href="chapter3.html#cb86-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;frequency&quot;</span>,</span>
<span id="cb86-8"><a href="chapter3.html#cb86-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb86-9"><a href="chapter3.html#cb86-9" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(latent.sample.time[, <span class="dv">500</span>],</span>
<span id="cb86-10"><a href="chapter3.html#cb86-10" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(x[<span class="dv">500</span>]),</span>
<span id="cb86-11"><a href="chapter3.html#cb86-11" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;frequency&quot;</span>,</span>
<span id="cb86-12"><a href="chapter3.html#cb86-12" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:hist-post-time"></span>
<img src="gitbook_version_files/figure-html/hist-post-time-1.png" alt="Histograms of posterior samples of the latent state for specific time points, t = 250 and t = 500, from the AR(1) model with level plus noise model." width="672" />
<p class="caption">
FIGURE 3.17: Histograms of posterior samples of the latent state for specific time points, t = 250 and t = 500, from the AR(1) model with level plus noise model.
</p>
</div>
<p>We can obtain the predictive value <span class="math inline">\(\hat{y}_t = E(y_t|y_1,\ldots,y_n)\)</span> as follows:</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="chapter3.html#cb87-1" aria-hidden="true" tabindex="-1"></a>ar1.level.latent_hyper.samples[[<span class="dv">1</span>]]<span class="sc">$</span>latent[<span class="dv">1</span><span class="sc">:</span>n]</span></code></pre></div>
<p>These can also be computed manually using posterior samples of <span class="math inline">\(x_t\)</span> and <span class="math inline">\(\alpha\)</span>:</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="chapter3.html#cb88-1" aria-hidden="true" tabindex="-1"></a>ar1.level.latent_hyper.samples[[<span class="dv">1</span>]]<span class="sc">$</span>latent[(n <span class="sc">+</span> <span class="dv">1</span>)<span class="sc">:</span>(<span class="dv">2</span> <span class="sc">*</span> n)]</span>
<span id="cb88-2"><a href="chapter3.html#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span> <span class="fu">tail</span>(ar1.level.latent_hyper.samples[[<span class="dv">1</span>]]<span class="sc">$</span>latent, <span class="dv">1</span>)</span></code></pre></div>
<p>While the values of <span class="math inline">\(\hat{y}_t\)</span> obtained from the two methods above are close, they do not coincide, as pointed out in <span class="citation">Rue, Martino, and Chopin (<a href="#ref-rue09" role="doc-biblioref">2009</a>)</span>.</p>
<p><strong>A note on reproducibility</strong></p>
<p><code>R-INLA</code> uses the OpenMP multiple processing interface. It uses multiple cores on shared memory by default; i.e., it uses all cores available in a machine for computation. Due to machine differences, small variations can be observed while running the same code on different machines and perhaps when repeating runs on any machine, depending on available cores.
One can
specify the number of cores by using the option <code>num.threads</code> in <code>inla()</code>, higher values offering speedup.
Setting <em>num.threads = 1</em> can ensure exact reproducibility. See <span class="citation">X. Wang, Yue, and Faraway (<a href="#ref-wang2018bayesian" role="doc-biblioref">2018</a>)</span> and <code>R-INLA</code> discussion group.<a href="resources.html#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
</div>
<div id="postpred-samples" class="section level2 hasAnchor" number="3.11">
<h2><span class="header-section-number">3.11</span> Posterior predictive samples of unknown observations<a href="chapter3.html#postpred-samples" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In many time series examples, it is very useful to use the posterior samples of the latent effects and hyperparameters in order to generate samples from the <em>posterior predictive distributions</em> of unknown observations (responses) given the observed data.
The function <code>inla.posterior.sample.eval()</code> can be used to do this,
as shown in the following code.</p>
<p>The function <code>inla.posterior.sample.eval</code> calls the function <code>fun.pred()</code> in order to compute the posterior predictive samples of the holdout data (last <span class="math inline">\(n_h = 5\)</span> observations denoted as NA in the data frame).</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="chapter3.html#cb89-1" aria-hidden="true" tabindex="-1"></a>fun.pred <span class="ot">&lt;-</span> <span class="cf">function</span>(idx.pred) {</span>
<span id="cb89-2"><a href="chapter3.html#cb89-2" aria-hidden="true" tabindex="-1"></a>  m <span class="ot">&lt;-</span> <span class="fu">length</span>(idx.pred)</span>
<span id="cb89-3"><a href="chapter3.html#cb89-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span> (Predictor[idx.pred] <span class="sc">+</span> <span class="fu">rnorm</span>(m, <span class="at">mean =</span> <span class="dv">0</span>,</span>
<span id="cb89-4"><a href="chapter3.html#cb89-4" aria-hidden="true" tabindex="-1"></a>                                      <span class="at">sd =</span> <span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">/</span> theta[<span class="dv">1</span>])))</span>
<span id="cb89-5"><a href="chapter3.html#cb89-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb89-6"><a href="chapter3.html#cb89-6" aria-hidden="true" tabindex="-1"></a>pred.post <span class="ot">&lt;-</span></span>
<span id="cb89-7"><a href="chapter3.html#cb89-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">inla.posterior.sample.eval</span>(fun.pred, ar1.level.latent_hyper.samples,</span>
<span id="cb89-8"><a href="chapter3.html#cb89-8" aria-hidden="true" tabindex="-1"></a>                             <span class="at">idx.pred =</span> <span class="fu">which</span>(<span class="fu">is.na</span>(y.append)))</span></code></pre></div>
<p>In Figure <a href="chapter3.html#fig:pred-obs-ts-sample">3.18</a>, we show plots of time series of the 500-th, 1000-th, 1500-th, and 2000-th posterior predictive samples for the holdout period, together with all the observed values of the time series.</p>
<div class="figure"><span id="fig:pred-obs-ts-sample"></span>
<img src="gitbook_version_files/figure-html/pred-obs-ts-sample-1.png" alt="Comparing predictions (blue) of $n_h=5$ holdout data and observed data (red). The black vertical line splits the data into the training and test sets." width="672" />
<p class="caption">
FIGURE 3.18: Comparing predictions (blue) of <span class="math inline">\(n_h=5\)</span> holdout data and observed data (red). The black vertical line splits the data into the training and test sets.
</p>
</div>
<p>We can also look at the histograms of the posterior predictive samples at times <span class="math inline">\(t=496\)</span> and
<span class="math inline">\(t=500\)</span>; see Figure <a href="chapter3.html#fig:hist-holdout-pred">3.19</a>.</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="chapter3.html#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb90-2"><a href="chapter3.html#cb90-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(pred.post[<span class="dv">1</span>, ],</span>
<span id="cb90-3"><a href="chapter3.html#cb90-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(x[<span class="dv">496</span>]),</span>
<span id="cb90-4"><a href="chapter3.html#cb90-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;frequency&quot;</span>,</span>
<span id="cb90-5"><a href="chapter3.html#cb90-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb90-6"><a href="chapter3.html#cb90-6" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(pred.post[<span class="dv">5</span>, ],</span>
<span id="cb90-7"><a href="chapter3.html#cb90-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(x[<span class="dv">500</span>]),</span>
<span id="cb90-8"><a href="chapter3.html#cb90-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;frequency&quot;</span>,</span>
<span id="cb90-9"><a href="chapter3.html#cb90-9" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:hist-holdout-pred"></span>
<img src="gitbook_version_files/figure-html/hist-holdout-pred-1.png" alt="Histograms of posterior predictive samples for holdout time points t = 496 and t = 500 for the AR(1) with level plus noise model." width="672" />
<p class="caption">
FIGURE 3.19: Histograms of posterior predictive samples for holdout time points t = 496 and t = 500 for the AR(1) with level plus noise model.
</p>
</div>
<p>A comparison of the posterior means of the <span class="math inline">\(n_h = 5\)</span> holdout points obtained from <code>summary.fitted.values</code> and from the posterior predictive samples shows that they are very similar.</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="chapter3.html#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(pred.post)</span>
<span id="cb91-2"><a href="chapter3.html#cb91-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1]    5 2000</span></span>
<span id="cb91-3"><a href="chapter3.html#cb91-3" aria-hidden="true" tabindex="-1"></a><span class="fu">tail</span>(model.ar1.level<span class="sc">$</span>summary.fitted.values<span class="sc">$</span>mean, <span class="dv">5</span>)</span>
<span id="cb91-4"><a href="chapter3.html#cb91-4" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 1.526 1.409 1.583 1.549 1.547</span></span>
<span id="cb91-5"><a href="chapter3.html#cb91-5" aria-hidden="true" tabindex="-1"></a><span class="fu">unname</span>(<span class="fu">rowMeans</span>(pred.post))</span>
<span id="cb91-6"><a href="chapter3.html#cb91-6" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 1.519 1.408 1.589 1.537 1.538</span></span></code></pre></div>
<p>We end this chapter with Table <a href="chapter3.html#tab:explain-inla-out">3.1</a> that gives a quick reference for the correspondence between terms in <code>R-INLA</code> summaries in their output and the terms in the DLMs. As mentioned earlier, note that <em>Rho for id.x</em> denotes <span class="math inline">\(\phi\)</span> in the AR(1) model.</p>
<table class="table table-striped" style="width: auto !important; ">
<caption>
<span id="tab:explain-inla-out">TABLE 3.1: </span>Description of variables from inla() output.
</caption>
<thead>
<tr>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
Variable in INLA output
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
Math Notation
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
Description
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Precision for the Gaussian observations
</td>
<td style="text-align:left;">
<span class="math inline">\(1/\sigma^2_v\)</span>
</td>
<td style="text-align:left;">
Observation noise precision
</td>
</tr>
<tr>
<td style="text-align:left;">
Precision for id.w
</td>
<td style="text-align:left;">
<span class="math inline">\(1/\sigma^2_w\)</span>
</td>
<td style="text-align:left;">
State noise precision
</td>
</tr>
<tr>
<td style="text-align:left;">
Precision for id.x
</td>
<td style="text-align:left;">
<span class="math inline">\(1/\sigma^2_x\)</span>
</td>
<td style="text-align:left;">
State variable precision
</td>
</tr>
<tr>
<td style="text-align:left;">
Rho for id.x
</td>
<td style="text-align:left;">
<span class="math inline">\(\phi\)</span>
</td>
<td style="text-align:left;">
AR(1) coefficient
</td>
</tr>
<tr>
<td style="text-align:left;">
id.delta
</td>
<td style="text-align:left;">
<span class="math inline">\(\delta\)</span>
</td>
<td style="text-align:left;">
Drift in the state equation
</td>
</tr>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:left;">
<span class="math inline">\(\alpha\)</span>
</td>
<td style="text-align:left;">
Level in the observation equation
</td>
</tr>
</tbody>
</table>
</div>
<div id="chapter-3-appendix" class="section level2 unnumbered hasAnchor">
<h2>Chapter 3 – Appendix<a href="chapter3.html#chapter-3-appendix" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="sampling-properties-of-time-series" class="section level3 unnumbered hasAnchor">
<h3>Sampling properties of time series<a href="chapter3.html#sampling-properties-of-time-series" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let <span class="math inline">\(X_{t}\)</span> be a stationary time series.</p>
<p><strong>1. Sample autocovariance function (ACVF)</strong></p>
<p>The sample autocovariance function (ACVF) of <span class="math inline">\(X_{t}\)</span> at lag <span class="math inline">\(h\)</span> is</p>
<p><span class="math display" id="eq:acvf">\[\begin{align}
\widehat{\gamma}(h) = \dfrac{1}{n} \sum_{t=1}^{n-|h|} (x_{t+|h|}-\overline{x})(x_{t}-\overline{x}),
\hspace{0.1in} -n &lt; h &lt; n.  \tag{3.30}
\end{align}\]</span>
Then, <span class="math inline">\(\widehat{\gamma}(0)\)</span> is the sample variance of the time series.</p>
<p><strong>2. Sample autocorrelation function (ACF)</strong></p>
<p>The sample autocorrelation function (ACF) of <span class="math inline">\(X_{t}\)</span> at lag <span class="math inline">\(h\)</span> is</p>
<p><span class="math display" id="eq:acf">\[\begin{align}
\widehat{\rho}(h) = \widehat{\gamma}(h) / \widehat{\gamma}(0), \hspace{0.1in} -n &lt; h&lt;n;  \tag{3.31}
\end{align}\]</span>
<span class="math inline">\(\widehat{\rho}(0)=1\)</span> and
<span class="math inline">\(|\widehat{\rho}(h)| \le 1,~ h=\pm 1, \pm2,\ldots\)</span>.</p>
<p><strong>3. Sample spectrum-smoothed periodogram</strong></p>
<p>Let <span class="math inline">\(i =\sqrt{-1}\)</span>, and let
<span class="math inline">\(\omega_{j} = j/n\)</span>, for <span class="math inline">\(j=0,\ldots,n-1\)</span> denote the Fourier frequencies. Define the complex-valued
discrete Fourier transform (DFT) of <span class="math inline">\(X_{t}\)</span> as</p>
<p><span class="math display" id="eq:dft">\[\begin{align}
d(\omega_{j}) = \dfrac{1}{\sqrt{n}} \sum_{t=1}^{n} X_{t} \exp(-2 \pi i \omega_{j} t).   \tag{3.32}
\end{align}\]</span>
The periodogram of <span class="math inline">\(X_t\)</span> is the (real-valued) estimate of its spectral density function and is defined as</p>
<p><span class="math display" id="eq:perio">\[\begin{align}
I(\omega_{j}) = |d(\omega_{j})|^{2}.    \tag{3.33}
\end{align}\]</span>
The smoothed periodogram is a consistent estimate of the true spectrum of <span class="math inline">\(X_t\)</span> and is obtained by averaging the periodogram ordinates over a
frequency band of <span class="math inline">\(L &lt; &lt; n\)</span> contiguous Fourier frequencies centered
around <span class="math inline">\(\omega_{j}\)</span>. For example, the smoothed spectrum with
the Daniell window is defined by</p>
<p><span class="math display" id="eq:smooth-perio">\[\begin{align}
\hat{f}(\omega_{j}) = \dfrac{1}{L} \sum_{k=-m}^{m} I(\omega_{j} + \dfrac{k}{n}),   \tag{3.34}
\end{align}\]</span>
where, <span class="math inline">\(L = 2m+1\)</span>.
The modified Daniell kernel is such that the two endpoints in the averaging get half the weight that the interior points get.</p>
</div>
<div id="autoregressive-models" class="section level3 unnumbered hasAnchor">
<h3>Autoregressive models<a href="chapter3.html#autoregressive-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The AR<span class="math inline">\((p)\)</span> model is widely used in time series modeling and forecasting. Here, <span class="math inline">\(p\)</span> is an integer which denotes the order of the model. The mean form of the AR<span class="math inline">\((p)\)</span> model is defined as</p>
<p><span class="math display" id="eq:arpmn">\[\begin{align}
x_t -\mu = \phi_1 (x_{t-1} -\mu)+\phi_2 (x_{t-2} -\mu)+\ldots+\phi_p (x_{t-p} -\mu) + w_t,
\tag{3.35}
\end{align}\]</span>
while its intercept form is</p>
<p><span class="math display" id="eq:arpint">\[\begin{align}
x_t = \delta + \phi_1 x_{t-1} +\phi_2 x_{t-2} +\ldots+\phi_p x_{t-p} + w_t,
\tag{3.36}
\end{align}\]</span>
where <span class="math inline">\(\delta = (1-\phi_1 -\phi_2 -\ldots -\phi_p)\mu\)</span>.
Using the backshift operator <span class="math inline">\(B\)</span>, with <span class="math inline">\(B^r x_t = x_{t-r}\)</span>, we can write the mean form and intercept form of the AR<span class="math inline">\((p)\)</span> model in operator notation as</p>
<p><span class="math display" id="eq:arpintop" id="eq:arpmnop">\[\begin{align}
(1-\phi_1 B -\ldots -\phi_p B^p)(x_t -\mu) &amp;= w_t, \mbox{ or }\tag{3.37}\\
(1-\phi_1 B -\ldots -\phi_p B^p)x_t &amp;= \delta + w_t. \tag{3.38}
\end{align}\]</span>
The AR<span class="math inline">\((p)\)</span> process is stationary if the modulus of the roots of the AR polynomial equation</p>
<p><span class="math display" id="eq:arpolyeq">\[\begin{align}
\phi(z) = 1-\phi_{1} z -\ldots - \phi_{p} z^{p} = 0   \tag{3.39}
\end{align}\]</span>
are all greater than <span class="math inline">\(1\)</span>. Recall that
a polynomial equation of order <span class="math inline">\(p\)</span> will have <span class="math inline">\(p\)</span> roots. These roots may all be real, or some roots may be real, while other roots are conjugate complex. The modulus of a real root is its absolute value, while the modulus of a complex root <span class="math inline">\(a+ib\)</span> or <span class="math inline">\(a-ib\)</span> is <span class="math inline">\(\sqrt{a^2+b^2}\)</span>.
We can use the R function <code>polyroot()</code> to find the roots of the AR polynomial equation, and verify whether the modulus of each root is greater than <span class="math inline">\(1\)</span>. In the <code>polyroot()</code> function, an <span class="math inline">\(\ell^{th}\)</span> order polynomial must be written in the form <span class="math inline">\(p(z) = c_1 + c_2 z +\ldots+ c_{\ell+1} z^\ell\)</span>, where the
<span class="math inline">\(c_j,~j=1,\ldots,\ell+1\)</span> are constants. For example, consider the AR<span class="math inline">\((2)\)</span> process</p>
<p><span class="math display">\[\begin{align*}
(1-\phi_{1}B - \phi_{2} B^{2})x_t= w_t,
\end{align*}\]</span>
with <span class="math inline">\(\phi_1=1.5\)</span> and <span class="math inline">\(\phi_2=-0.75\)</span>.
The AR<span class="math inline">\((2)\)</span> polynomial is <span class="math inline">\(p(z) =(1-1.5 z+0.75z^2)\)</span>, and<br />
the equation <span class="math inline">\(p(z)=0\)</span> has two conjugate complex roots, i.e., <span class="math inline">\(z[1]=1+0.57735i\)</span> and <span class="math inline">\(z[2]=1-0.57735 i\)</span>, where <span class="math inline">\(i =\sqrt{-1}\)</span>.
The modulus of these roots is <span class="math inline">\(1.1547 &gt;1\)</span>; hence this AR<span class="math inline">\((2)\)</span> process is stationary.</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="chapter3.html#cb92-1" aria-hidden="true" tabindex="-1"></a>phi1 <span class="ot">&lt;-</span> <span class="fl">1.5</span></span>
<span id="cb92-2"><a href="chapter3.html#cb92-2" aria-hidden="true" tabindex="-1"></a>phi2 <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fl">0.75</span></span>
<span id="cb92-3"><a href="chapter3.html#cb92-3" aria-hidden="true" tabindex="-1"></a>u <span class="ot">&lt;-</span> <span class="fu">polyroot</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="sc">-</span>phi1,<span class="sc">-</span>phi2))</span>
<span id="cb92-4"><a href="chapter3.html#cb92-4" aria-hidden="true" tabindex="-1"></a>u[<span class="dv">1</span>]</span>
<span id="cb92-5"><a href="chapter3.html#cb92-5" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 1+0.577i</span></span>
<span id="cb92-6"><a href="chapter3.html#cb92-6" aria-hidden="true" tabindex="-1"></a>u[<span class="dv">2</span>]</span>
<span id="cb92-7"><a href="chapter3.html#cb92-7" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 1-0.577i</span></span>
<span id="cb92-8"><a href="chapter3.html#cb92-8" aria-hidden="true" tabindex="-1"></a><span class="fu">Mod</span>(u[<span class="dv">1</span>])</span>
<span id="cb92-9"><a href="chapter3.html#cb92-9" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 1.155</span></span>
<span id="cb92-10"><a href="chapter3.html#cb92-10" aria-hidden="true" tabindex="-1"></a><span class="fu">Mod</span>(u[<span class="dv">2</span>]) </span>
<span id="cb92-11"><a href="chapter3.html#cb92-11" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 1.155</span></span></code></pre></div>
<p>The stationarity region for an AR<span class="math inline">\((p)\)</span> process is a convex set <span class="math inline">\(C_p \subset \mathbb{R}^p\)</span>, and involves nonlinear constraints on
<!--$\boldsymbol{\phi}=(\phi_1,\ldots, \phi_p)'$. -->
<span class="math inline">\(\boldsymbol{\phi}=(\phi_1^p,\ldots, \phi_p^p)&#39;\)</span>
To handle this, <code>R-INLA</code> uses the partial autocorrelation function (PACF) parameterization from <span class="math inline">\(C_p\)</span> to the <span class="math inline">\(p\)</span>-dimensional hypercube <span class="math inline">\((-1,1)^p\)</span> (see <span class="citation">Barndorff-Nielsen and Schou (<a href="#ref-barndorff1973parametrization" role="doc-biblioref">1973</a>)</span> and <span class="citation">Marriott et al. (<a href="#ref-marriott1996bayesian" role="doc-biblioref">1996</a>)</span>).
The one-to-one transformation <!--was shown in \@ref(eq:pacftrans1) as -->
with partial autocorrelations
<span class="math inline">\(\boldsymbol r = (r_1, \ldots, r_p)&#39;\)</span> is</p>
<p><span class="math display">\[\begin{align*}
\phi_{k}^{(k)} &amp;= r_k \notag \\
\phi_{i}^{(k)} &amp;= \phi_{i}^{(k-1)} -r_k \phi_{k-i}^{(k-1)},~i=1,\ldots, k-1.
\end{align*}\]</span>
<span class="citation">Monahan (<a href="#ref-monahan1984note" role="doc-biblioref">1984</a>)</span> gave the inverse transformation as</p>
<p><span class="math display" id="eq:pacftrans2">\[\begin{align}
\phi_{i}^{(k-1)}=\frac{\phi_{i}^{(k)} +\phi_{k}^{(k)}\phi_{k-i}^{(k)}}
{(1-\phi_{k}^{(k)})^2},~i=1,\ldots,k-1,
\tag{3.40}
\end{align}\]</span>
with Jacobian</p>
<p><span class="math display" id="eq:pacftrans3">\[\begin{align}
J = \prod_{k=1}^p (1-r_k^2)^{\frac{(k-1)}{2}} \prod_{j=1}^{[p/2]}(1-r_{2j}).
\tag{3.41}
\end{align}\]</span>
In <code>R-INLA</code>, the partial autocorrelations of an AR<span class="math inline">\((p)\)</span> model are denoted by
<span class="math inline">\(\psi_k\)</span>, with <span class="math inline">\(|\psi_k| &lt;1\)</span> for <span class="math inline">\(k=1,\ldots,p\)</span>. In terms of the internal parameterization,
for <span class="math inline">\(k=1,\ldots,p\)</span>,</p>
<p><span class="math display">\[\begin{align*}
\psi_k = 2 \frac{\exp(\theta_{\psi,k})}{1+\exp(\theta_{\psi,k})} -1.
\end{align*}\]</span>
For an AR(2) process, these transformations are obtained as follows.</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="chapter3.html#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># phi to pacf</span></span>
<span id="cb93-2"><a href="chapter3.html#cb93-2" aria-hidden="true" tabindex="-1"></a>phi <span class="ot">&lt;-</span> <span class="fu">c</span>(phi1, phi2)</span>
<span id="cb93-3"><a href="chapter3.html#cb93-3" aria-hidden="true" tabindex="-1"></a>pacf <span class="ot">&lt;-</span> <span class="fu">inla.ar.phi2pacf</span>(phi)</span>
<span id="cb93-4"><a href="chapter3.html#cb93-4" aria-hidden="true" tabindex="-1"></a><span class="co">#pacf to phi</span></span>
<span id="cb93-5"><a href="chapter3.html#cb93-5" aria-hidden="true" tabindex="-1"></a>phi<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">inla.ar.pacf2phi</span>(pacf)</span></code></pre></div>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-barndorff1973parametrization" class="csl-entry">
Barndorff-Nielsen, Ole E., and Geert Schou. 1973. <span>“On the Parameterization of Autoregressive Models by Partial Autocorrelations.”</span> <em>Journal of Multivariate Analysis</em> 3 (4): 408–19.
</div>
<div id="ref-boehmke2016data" class="csl-entry">
Boehmke, Bradley C. 2016. <em>Data Wrangling with r</em>. Switzerland: Springer International Publishing.
</div>
<div id="ref-fuglstad2019constructing" class="csl-entry">
Fuglstad, Geir-Arne, Daniel Simpson, Finn Lindgren, and Håvard Rue. 2019. <span>“Constructing Priors That Penalize the Complexity of <span>G</span>aussian Random Fields.”</span> <em>Journal of the American Statistical Association</em> 114 (525): 445–52.
</div>
<div id="ref-GamermanLopes" class="csl-entry">
Gamerman, D., and F. H. Lopes. 2006. <em>Markov Chain Monte Carlo: Stochastic Simulation for Bayesian Inference</em>. New York: Chapman &amp; Hall/CRC.
</div>
<div id="ref-gomez2020bayesian" class="csl-entry">
Gómez-Rubio, Virgilio. 2020. <em>Bayesian <span>I</span>nference with <span>INLA</span></em>. Boca Raton, Florida: CRC Press.
</div>
<div id="ref-gomez2018markov" class="csl-entry">
Gómez-Rubio, Virgilio, and Håvard Rue. 2018. <span>“Markov Chain <span>M</span>onte <span>C</span>arlo with the Integrated Nested <span>L</span>aplace Approximation.”</span> <em>Statistics and Computing</em> 28 (5): 1033–51.
</div>
<div id="ref-kalman1960" class="csl-entry">
Kalman, Rudolph Emil. 1960. <span>“A New Approach to Linear Filtering and Prediction Problems.”</span> <em>Trans. ASME J. Basic Engineering</em> 83.
</div>
<div id="ref-marriott1996bayesian" class="csl-entry">
Marriott, John, Nalini Ravishanker, Alan E. Gelfand, and Jeffrey S. Pai. 1996. <span>“Bayesian Analysis of <span>ARMA</span> Processes: Complete Sampling-Based Inference Under Exact Likelihoods.”</span> <em>Bayesian Analysis in Statistics and Econometrics</em>, 243–56.
</div>
<div id="ref-monahan1984note" class="csl-entry">
Monahan, John F. 1984. <span>“A Note on Enforcing Stationarity in Autoregressive-Moving Average Models.”</span> <em>Biometrika</em> 71 (2): 403–4.
</div>
<div id="ref-rue2005gaussian" class="csl-entry">
Rue, Håvard, and Leonhard Held. 2005. <em>Gaussian Markov Random Fields: Theory and Applications</em>. Boca Raton, Florida: Chapman &amp; Hall/CRC.
</div>
<div id="ref-rue09" class="csl-entry">
Rue, Håvard, Sara Martino, and Nicholas Chopin. 2009. <span>“Approximate <span>B</span>ayesian Inference for Latent <span>G</span>aussian Models Using Integrated Nested <span>L</span>aplace Approximations (with Discussion).”</span> <em>Journal of the Royal Statistical Society, Series B</em> 71: 319–92.
</div>
<div id="ref-ruiz2012direct" class="csl-entry">
Ruiz-Cárdenas, Ramiro, Elias T. Krainski, and Håvard Rue. 2012. <span>“Direct Fitting of Dynamic Models Using Integrated Nested <span>L</span>aplace Approximations—<span>INLA</span>.”</span> <em>Computational Statistics &amp; Data Analysis</em> 56 (6): 1808–28.
</div>
<div id="ref-seppa2019-SIM" class="csl-entry">
Seppä, Karri, Håvard Rue, Timo Hakulinen, Esa Läärä, Mikko J. Sillanpää, and Janne Pitkäniemi. 2019. <span>“Estimating Multilevel Regional Variation in Excess Mortality of Cancer Patients Using Integrated Nested <span>L</span>aplace Approximation.”</span> <em>Statistics in Medicine</em> 38 (5): 778–91.
</div>
<div id="ref-ss2017" class="csl-entry">
Shumway, Robert H., and David S. Stoffer. 2017. <em>Time Series Analysis and Its Applications: With r Examples</em>. Springer Texts in Statistics. New York: Springer International Publishing.
</div>
<div id="ref-wang2018bayesian" class="csl-entry">
Wang, Xiaofeng, Yuryan Yue, and Julian J. Faraway. 2018. <em><span>B</span>ayesian <span>R</span>egression <span>M</span>odeling with <span>INLA</span></em>. New York: Chapman; Hall/CRC.
</div>
<div id="ref-ggplot2wick" class="csl-entry">
Wickham, Hadley. 2016. <em>Ggplot2: Elegant Graphics for Data Analysis</em>. New York: Springer-Verlag. <a href="https://ggplot2.tidyverse.org">https://ggplot2.tidyverse.org</a>.
</div>
<div id="ref-tidy17" class="csl-entry">
Wickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. <span>“Welcome to the <span class="nocase">tidyverse</span>.”</span> <em>Journal of Open Source Software</em> 4 (43): 1686. <a href="https://doi.org/10.21105/joss.01686">https://doi.org/10.21105/joss.01686</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter2.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapter4.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"split_by": "chapter",
"split_bib": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
